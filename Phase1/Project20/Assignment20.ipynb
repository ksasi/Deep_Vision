{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ksasi/EVA/blob/master/Project20/Assignment20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVeAL_b01JaU"
   },
   "source": [
    "# Transfer Learning for CIFAR10 Using ImageNet Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "qOepNhcgQ_0i",
    "outputId": "047f7983-77fb-4ee6-90de-d7802b139b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 28 08:42:47 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Obtain GPU details\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Z2yr-i2CnGjD",
    "outputId": "3d8964ce-4f69-4451-f701-802be27e5e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
      "\u001b[K     |████████████████████████████████| 380.8MB 43kB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
      "Collecting tensorboard<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 37.6MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 64.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.6.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
      "  Found existing installation: google-auth 1.4.2\n",
      "    Uninstalling google-auth-1.4.2:\n",
      "      Successfully uninstalled google-auth-1.4.2\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "Successfully installed google-auth-1.7.1 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install Tensorflow 2.0 GPU version\n",
    "\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EAR1cclbnV6G",
    "outputId": "c4131109-fbf0-4b2a-cb6f-b2919ae4d42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# Import all the necessary libraties i.e. numpy, matplotlib, tensorflow\n",
    "# Print tensorflow and tf.keras versions\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import eval\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qy-EvHKy_yIz"
   },
   "outputs": [],
   "source": [
    "# Number of classes for CIFAR100 set as 100\n",
    "\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cFzdEjglnaYA",
    "outputId": "a763466d-a23f-40fa-cc4c-40aea8ef05c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain train and test dataset for CIFAR100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "tCY1ozNkt8Q3",
    "outputId": "4caaa0e0-fd66-4901-9ac1-c684d2b40af4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAC0CAYAAAD2H3egAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzC1o8mkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show few images from training dataset of CIFAR100\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = features_idx[img_num]\n",
    "    #ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Du63rMvj-554"
   },
   "outputs": [],
   "source": [
    "# Convert labels into one-hot vectors\n",
    "\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "q0mikukA_vCl",
    "outputId": "709b3271-2046-481a-952e-56ce5514749a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa0f48f2be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADDCAYAAAAyYdXtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample image from train dataset\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "plt.imshow(x_train[1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pukeE7e0WykC",
    "outputId": "feedd449-9c7c-4468-9bae-3fcf560f4bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display shape of x_train\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmlyzuxW6n47"
   },
   "outputs": [],
   "source": [
    "# Image Augmenters\n",
    "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop)\n",
    "\n",
    "def CustomImageDataGen(input_img):\n",
    "    seq = Compose([PadIfNeeded(40,40, p=1),\n",
    "                   RandomCrop(32,32, p=1),\n",
    "                   HorizontalFlip(p=0.5),\n",
    "                   Cutout(num_holes=1, max_h_size=8, max_w_size=8, p=0.5)\n",
    "                  ], p=1)\n",
    "    output_img = seq(image = input_img)['image']\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sygkk7og6QD"
   },
   "outputs": [],
   "source": [
    "# Create image data generators for train and validation/test datasets seperately\n",
    "# Fit the image data generators to train dataset to obtain mean and standard deviations, so that image standardization can be performed.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    preprocessing_function = CustomImageDataGen,\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "datagen_val = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0)\n",
    "\n",
    "datagen_val.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_9E2ijtUg6Yf",
    "outputId": "f2bf9088-eb60-4b67-950e-e5f51b9de798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[129.30386 124.06987 112.43356]]]\n",
      "[[[68.1702  65.39176 70.41806]]]\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation of pixel values\n",
    "\n",
    "print(datagen.mean)\n",
    "print(datagen.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kc5mY1GOswSv",
    "outputId": "edd56740-6bde-4ebc-cee3-057f4fc7efe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[129.30386, 124.06987, 112.43356]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBncxZGlhYCq"
   },
   "outputs": [],
   "source": [
    "# Set the mean and std of both the image data generators to ImageNet mean & std. These values are then used for image standardization.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "datagen.mean = np.array([[[0.485, 0.456, 0.406]]], dtype = np.float32)\n",
    "datagen.std = np.array([[[0.229, 0.224, 0.225]]], dtype = np.float32)\n",
    "\n",
    "\n",
    "datagen_val.mean = np.array([[[0.485, 0.456, 0.406]]], dtype = np.float32)\n",
    "datagen_val.std = np.array([[[0.229, 0.224, 0.225]]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FeSYMGFhtJCn",
    "outputId": "ce8843f5-a6ed-4b3b-9dc7-16e7a5cf14fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.485 0.456 0.406]]]\n",
      "[[[0.485 0.456 0.406]]]\n"
     ]
    }
   ],
   "source": [
    "# Display updated mean and std values\n",
    "\n",
    "print(datagen.mean)\n",
    "print(datagen_val.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfqLupKXvowB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZotxHfmzxaQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JPyQ9kQOl4u"
   },
   "source": [
    "#### Classification models Zoo - Keras (and TensorFlow Keras) - https://github.com/qubvel/classification_models, forked and modified to https://github.com/ksasi/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "YBMKHh5iOnVT",
    "outputId": "589d7d62-5d91-4427-966c-9585244f5fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ksasi/classification_models.git\n",
      "  Cloning https://github.com/ksasi/classification_models.git to /tmp/pip-req-build-q79dadno\n",
      "  Running command git clone -q https://github.com/ksasi/classification_models.git /tmp/pip-req-build-q79dadno\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from image-classifiers==1.0.0) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.17.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.12.0)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=19952 sha256=050bb9479f7da749a3a3e3db010434dbba43df568ad1740cdf7438e2a0c782ff\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zr1duq24/wheels/a1/d5/94/e536af3b04571f3b182a50e31622b3d9d1c24b7c172b086ae4\n",
      "Successfully built image-classifiers\n",
      "Installing collected packages: image-classifiers\n",
      "Successfully installed image-classifiers-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install the below repo. This repo is forked as above and ResNet18 is modified to remove Initial maxpool and set the strides of initial 7x7 to stride of 1\n",
    "\n",
    "!pip install git+https://github.com/ksasi/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NQncC49S3q0j",
    "outputId": "3f94c931-4460-497a-f4dd-314fb0d5976a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5\n",
      "44924928/44920640 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain ResNet18 pre-trained model with ImageNet weights without the classification head\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "base_model_cifar = ResNet18((32, 32, 3), weights='imagenet', include_top=False)\n",
    "base_model_cifar.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Tw6uEkx09R0l",
    "outputId": "bfecc3cd-35cc-4987-a58d-ac25ed433e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 32, 32, 3)    9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)    0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 32, 32, 64)   9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 32, 32, 64)   256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 32, 32, 64)   0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 34, 34, 64)   0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 34, 34, 64)   256         zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 34, 34, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 36, 36, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 34, 34, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 34, 34, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 34, 34, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 36, 36, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 34, 34, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 34, 34, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 34, 34, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 34, 34, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 34, 34, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 36, 36, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 34, 34, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 34, 34, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 34, 34, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 36, 36, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 34, 34, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 34, 34, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 34, 34, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 34, 34, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 36, 36, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 17, 17, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 17, 17, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 17, 17, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 19, 19, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 17, 17, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 17, 17, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 17, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 17, 17, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 17, 17, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 19, 19, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 17, 17, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 17, 17, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 17, 17, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 19, 19, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 17, 17, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 17, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 17, 17, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 17, 17, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 19, 19, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 9, 9, 256)    294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 9, 9, 256)    1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 9, 9, 256)    0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 11, 11, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 9, 9, 256)    589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 9, 9, 256)    32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9, 9, 256)    0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 9, 9, 256)    1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 9, 9, 256)    0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 11, 11, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 9, 9, 256)    589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 9, 9, 256)    1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 9, 9, 256)    0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 11, 11, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 9, 9, 256)    589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 9, 9, 256)    0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 9, 9, 256)    1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 9, 9, 256)    0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 11, 11, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 5, 5, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 5, 5, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 5, 5, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 7, 7, 512)    0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 5, 5, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 5, 5, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 5, 5, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 5, 5, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 5, 5, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 7, 7, 512)    0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 5, 5, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 5, 5, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 5, 5, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 7, 7, 512)    0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 5, 5, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 5, 5, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 5, 5, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 5, 5, 512)    0           bn1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 11,186,889\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,186,889\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "\n",
    "base_model_cifar.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FDZatept3gI"
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJVFzHLVStZU"
   },
   "outputs": [],
   "source": [
    "# Define layers to be used in classification head\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "point_wise_conv2d_layer = tf.keras.layers.Conv2D(filters = 100, kernel_size = 1, use_bias = False)\n",
    "dense_layer = tf.keras.layers.Dense(100)\n",
    "softmax_layer = tf.keras.layers.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNyyedeNNQeM"
   },
   "outputs": [],
   "source": [
    "# Define the model where custom classification head is attached to previously obtained pre-trained ResNet18\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model_cifar,\n",
    "  point_wise_conv2d_layer,\n",
    "  global_average_layer,\n",
    "  dense_layer,\n",
    "  softmax_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcQ7iV6Bvfee"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ucgzpaH9vq9y",
    "outputId": "491da423-794d-4330-809f-a700e60af56d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 5, 5, 512)         11186889  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 100)         51200     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 11,248,189\n",
      "Trainable params: 61,300\n",
      "Non-trainable params: 11,186,889\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-uJF5d6UXefX",
    "outputId": "712d3330-b47e-4594-d07c-e8530e135951"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "84Elbtpu7xAD",
    "outputId": "2e994e62-daf2-49d3-ce70-f433c473d81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.training.Model object at 0x7fa00e09dfd0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9ff77a27f0> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9ff77a2a20> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fa061d0dfd0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x7fa061d0da20> True\n"
     ]
    }
   ],
   "source": [
    "# Display layers and trainable status. The convolution layers are frozen and classification layers were set as Trainable.\n",
    "\n",
    "for i in model.layers:\n",
    "  print(i, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "yn50CmXCEUPB",
    "outputId": "266aefa6-8c1e-46a4-e642-eed0ec97e6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive to colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2MzDz-L4ikX2",
    "outputId": "d85d8cb0-6341-42a3-d692-9bd8604826c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.2666 - categorical_accuracy: 0.0703\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.11610, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 54s 548ms/step - loss: 4.2628 - categorical_accuracy: 0.0707 - val_loss: 3.8434 - val_categorical_accuracy: 0.1161\n",
      "Epoch 2/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.8766 - categorical_accuracy: 0.1141\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.11610 to 0.15340, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 47s 476ms/step - loss: 3.8747 - categorical_accuracy: 0.1142 - val_loss: 3.6693 - val_categorical_accuracy: 0.1534\n",
      "Epoch 3/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.7573 - categorical_accuracy: 0.1359\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.15340 to 0.15360, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 473ms/step - loss: 3.7574 - categorical_accuracy: 0.1356 - val_loss: 3.6774 - val_categorical_accuracy: 0.1536\n",
      "Epoch 4/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.7204 - categorical_accuracy: 0.1397\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.15360 to 0.17070, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 47s 475ms/step - loss: 3.7210 - categorical_accuracy: 0.1399 - val_loss: 3.5471 - val_categorical_accuracy: 0.1707\n",
      "Epoch 5/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.6451 - categorical_accuracy: 0.1543\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.17070\n",
      "98/98 [==============================] - 45s 464ms/step - loss: 3.6461 - categorical_accuracy: 0.1541 - val_loss: 3.5851 - val_categorical_accuracy: 0.1651\n",
      "Epoch 6/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.6195 - categorical_accuracy: 0.1590\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.17070 to 0.19090, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 47s 475ms/step - loss: 3.6176 - categorical_accuracy: 0.1595 - val_loss: 3.4509 - val_categorical_accuracy: 0.1909\n",
      "Epoch 7/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5861 - categorical_accuracy: 0.1627\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.19090\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 3.5869 - categorical_accuracy: 0.1627 - val_loss: 3.5834 - val_categorical_accuracy: 0.1680\n",
      "Epoch 8/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5513 - categorical_accuracy: 0.1707\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.19090 to 0.19330, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 472ms/step - loss: 3.5503 - categorical_accuracy: 0.1710 - val_loss: 3.4294 - val_categorical_accuracy: 0.1933\n",
      "Epoch 9/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5510 - categorical_accuracy: 0.1682\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.19330 to 0.19690, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 471ms/step - loss: 3.5504 - categorical_accuracy: 0.1681 - val_loss: 3.4065 - val_categorical_accuracy: 0.1969\n",
      "Epoch 10/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5060 - categorical_accuracy: 0.1775\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.19690\n",
      "98/98 [==============================] - 45s 461ms/step - loss: 3.5063 - categorical_accuracy: 0.1775 - val_loss: 3.4075 - val_categorical_accuracy: 0.1965\n",
      "Epoch 11/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5248 - categorical_accuracy: 0.1750\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.19690\n",
      "98/98 [==============================] - 45s 464ms/step - loss: 3.5259 - categorical_accuracy: 0.1747 - val_loss: 3.4207 - val_categorical_accuracy: 0.1942\n",
      "Epoch 12/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4870 - categorical_accuracy: 0.1804\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.19690 to 0.20170, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 471ms/step - loss: 3.4880 - categorical_accuracy: 0.1805 - val_loss: 3.3778 - val_categorical_accuracy: 0.2017\n",
      "Epoch 13/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4813 - categorical_accuracy: 0.1829\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.20170 to 0.20520, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 3.4810 - categorical_accuracy: 0.1831 - val_loss: 3.3515 - val_categorical_accuracy: 0.2052\n",
      "Epoch 14/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4710 - categorical_accuracy: 0.1823\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.20520\n",
      "98/98 [==============================] - 45s 461ms/step - loss: 3.4706 - categorical_accuracy: 0.1825 - val_loss: 3.3676 - val_categorical_accuracy: 0.2012\n",
      "Epoch 15/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4295 - categorical_accuracy: 0.1903\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.20520\n",
      "98/98 [==============================] - 45s 463ms/step - loss: 3.4302 - categorical_accuracy: 0.1906 - val_loss: 3.4739 - val_categorical_accuracy: 0.1973\n",
      "Epoch 16/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4523 - categorical_accuracy: 0.1879\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.20520 to 0.20650, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 3.4531 - categorical_accuracy: 0.1877 - val_loss: 3.3494 - val_categorical_accuracy: 0.2065\n",
      "Epoch 17/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4499 - categorical_accuracy: 0.1861\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.20650 to 0.21480, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 3.4493 - categorical_accuracy: 0.1862 - val_loss: 3.3263 - val_categorical_accuracy: 0.2148\n",
      "Epoch 18/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4289 - categorical_accuracy: 0.1913\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.21480\n",
      "98/98 [==============================] - 45s 457ms/step - loss: 3.4284 - categorical_accuracy: 0.1914 - val_loss: 3.3114 - val_categorical_accuracy: 0.2112\n",
      "Epoch 19/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4229 - categorical_accuracy: 0.1926\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.21480\n",
      "98/98 [==============================] - 45s 459ms/step - loss: 3.4224 - categorical_accuracy: 0.1925 - val_loss: 3.3335 - val_categorical_accuracy: 0.2117\n",
      "Epoch 20/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4048 - categorical_accuracy: 0.1936\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.21480\n",
      "98/98 [==============================] - 45s 459ms/step - loss: 3.4046 - categorical_accuracy: 0.1937 - val_loss: 3.3238 - val_categorical_accuracy: 0.2143\n",
      "Epoch 21/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4076 - categorical_accuracy: 0.1945\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.21480 to 0.21780, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 3.4078 - categorical_accuracy: 0.1944 - val_loss: 3.2942 - val_categorical_accuracy: 0.2178\n",
      "Epoch 22/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3966 - categorical_accuracy: 0.1972\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.21780 to 0.22550, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 3.3956 - categorical_accuracy: 0.1974 - val_loss: 3.2394 - val_categorical_accuracy: 0.2255\n",
      "Epoch 23/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3945 - categorical_accuracy: 0.1961\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.22550 to 0.22690, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 3.3946 - categorical_accuracy: 0.1961 - val_loss: 3.2786 - val_categorical_accuracy: 0.2269\n",
      "Epoch 24/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3839 - categorical_accuracy: 0.1993\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.22690\n",
      "98/98 [==============================] - 45s 458ms/step - loss: 3.3831 - categorical_accuracy: 0.1996 - val_loss: 3.3453 - val_categorical_accuracy: 0.2064\n",
      "Epoch 25/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3815 - categorical_accuracy: 0.1993\n",
      "Epoch 00025: val_categorical_accuracy improved from 0.22690 to 0.22910, saving model to /content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 3.3820 - categorical_accuracy: 0.1989 - val_loss: 3.2465 - val_categorical_accuracy: 0.2291\n",
      "Epoch 26/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3673 - categorical_accuracy: 0.1993\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.22910\n",
      "98/98 [==============================] - 45s 459ms/step - loss: 3.3688 - categorical_accuracy: 0.1991 - val_loss: 3.3261 - val_categorical_accuracy: 0.2134\n",
      "Epoch 27/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3598 - categorical_accuracy: 0.2034\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.22910\n",
      "98/98 [==============================] - 45s 457ms/step - loss: 3.3622 - categorical_accuracy: 0.2030 - val_loss: 3.2674 - val_categorical_accuracy: 0.2254\n",
      "Epoch 28/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3676 - categorical_accuracy: 0.2022\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.22910\n",
      "98/98 [==============================] - 45s 458ms/step - loss: 3.3668 - categorical_accuracy: 0.2024 - val_loss: 3.2995 - val_categorical_accuracy: 0.2244\n",
      "Epoch 29/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3498 - categorical_accuracy: 0.2033\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.22910\n",
      "98/98 [==============================] - 45s 461ms/step - loss: 3.3500 - categorical_accuracy: 0.2034 - val_loss: 3.2534 - val_categorical_accuracy: 0.2227\n",
      "Epoch 30/30\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3683 - categorical_accuracy: 0.2014\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.22910\n",
      "98/98 [==============================] - 45s 461ms/step - loss: 3.3695 - categorical_accuracy: 0.2009 - val_loss: 3.2596 - val_categorical_accuracy: 0.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ff6df21d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define checkpoint and train the model. This is transfer learning.\n",
    "\n",
    "from math import ceil\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\"/content/drive/My Drive/models/resnet18_cifar100_transfer_learn.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size), steps_per_epoch=ceil(len(x_train)/batch_size), epochs = 30, validation_data = datagen_val.flow(x_test,y_test, batch_size=batch_size), validation_steps=ceil(len(x_test)/batch_size), callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tl-GYPPyihCD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VX5b_UsiihLS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAhM0SPPhXBu"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBTQV6JxuAjS"
   },
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIZUc-ZBsZ7X"
   },
   "outputs": [],
   "source": [
    "# Define learning rate scheduler. Step learning rate is being used.\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
    "def scheduler(epoch):\n",
    "    if epoch < 30:\n",
    "        return 0.1\n",
    "    if 30 <= epoch < 60:\n",
    "        return 0.02\n",
    "    if 60 <= epoch < 80:\n",
    "        return 0.004\n",
    "    if epoch >= 80 :\n",
    "        return 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "OgkCKcCBdXs1",
    "outputId": "1d04371a-17a9-424e-dfeb-d152cebd1660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 5, 5, 512)         11186889  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 100)         51200     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 11,248,189\n",
      "Trainable params: 61,300\n",
      "Non-trainable params: 11,186,889\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yIrlCfpmWIq"
   },
   "outputs": [],
   "source": [
    "base_model_cifar.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8dtfvNfjmZ8D",
    "outputId": "ac8a0036-5f3c-46c4-cd34-e95cbea84dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model_cifar.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q4K67ZfzmaD2",
    "outputId": "d85d4df4-b6b2-44d4-9514-c362a13067fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "fine_tune_at = len(base_model_cifar.layers) - 17\n",
    "print(fine_tune_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5mCPFvumaAC"
   },
   "outputs": [],
   "source": [
    "# Set last few convolution layers are trainable and remaining layers frozen\n",
    "\n",
    "for layer in base_model_cifar.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xj7n2vVVVbk-"
   },
   "outputs": [],
   "source": [
    "# Ensure all BN layers are trainable. Reference https://twitter.com/jeremyphoward/status/1182062808206213120?s=12\n",
    "\n",
    "for layer in base_model_cifar.layers:\n",
    "  if \"BatchNormalization\" in str(layer):\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mclBYtvNm946",
    "outputId": "d4c3b0d1-c765-4e26-ef9d-e217da7b7b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa061d0d780> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa061cafbe0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa050513f60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0798ecf28> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0504cde10> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa050466940> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0504666d8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0503dbda0> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0503ec5c0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa050366ac8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503669e8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050374dd8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa050341da0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0503816a0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503817b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503b0eb8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa050309518> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050309eb8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05030e630> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0502d8f28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05030e5f8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa05028df98> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0501fa978> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05021f9b0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05021fac8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa0501a87f0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0501a8da0> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0501b1898> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05012ddd8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05012dcf8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050139f98> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05013c9e8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0500a7978> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05013cac8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0501b1828> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa0500d37f0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0500d3da0> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05005b898> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05005b828> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05003cef0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e5783c8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e5820b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e54fc18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e578d68> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e4fbac8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e4fba58> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e567c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e47df28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e47ddd8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e4a43c8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e42e0b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e3f7c18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e4a4d68> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e508b00> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e3a8ac8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e3a8a58> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e412c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e3b7b00> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e3b7b38> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e33d668> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e33def0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e33deb8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e346048> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e2c2d68> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e2c2cf8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e2d0e10> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e25c358> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e25cdd8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e1eb668> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e1ebef0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e1ebeb8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e1f0048> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e2d0da0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e170d68> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e170cf8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e17fe10> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e15da58> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e17fdd8> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e109908> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e114208> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e0d5e48> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e1142e8> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e08dd68> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa05043e0b8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e09df28> True\n"
     ]
    }
   ],
   "source": [
    "# Check trainable status for all layers\n",
    "\n",
    "for i in base_model_cifar.layers:\n",
    "  print(i, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OnS_0NgPnON0",
    "outputId": "eb8f9e30-399b-4dae-bd02-6fff492cce85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.training.Model object at 0x7fa00e09dfd0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9ff77a27f0> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9ff77a2a20> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fa061d0dfd0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x7fa061d0da20> True\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "  print(i, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhL4hLASpEDK"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "jvzIkZj6pEAs",
    "outputId": "4273bedd-60c8-4d83-c9de-f6fcb710d93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 5, 5, 512)         11186889  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 100)         51200     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 11,248,189\n",
      "Trainable params: 7,274,356\n",
      "Non-trainable params: 3,973,833\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ijnzcrTnpD-C",
    "outputId": "2147872c-7fe4-4fd7-ba6d-0f50535c1fb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RFF1D0bn4Bfz",
    "outputId": "cca37b25-7c7c-477e-9eb9-47288efd7f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 10.2637 - categorical_accuracy: 0.0263\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.01150, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 10.2129 - categorical_accuracy: 0.0263 - val_loss: 14.1322 - val_categorical_accuracy: 0.0115\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.8279 - categorical_accuracy: 0.0359\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.01150 to 0.03200, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 482ms/step - loss: 4.8302 - categorical_accuracy: 0.0360 - val_loss: 9.7318 - val_categorical_accuracy: 0.0320\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.3599 - categorical_accuracy: 0.0838\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.03200 to 0.09160, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 484ms/step - loss: 4.3554 - categorical_accuracy: 0.0841 - val_loss: 4.1095 - val_categorical_accuracy: 0.0916\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.8420 - categorical_accuracy: 0.1379\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.09160\n",
      "98/98 [==============================] - 46s 470ms/step - loss: 3.8535 - categorical_accuracy: 0.1373 - val_loss: 11.7177 - val_categorical_accuracy: 0.0232\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.4047 - categorical_accuracy: 0.1026\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.09160\n",
      "98/98 [==============================] - 46s 474ms/step - loss: 4.4025 - categorical_accuracy: 0.1029 - val_loss: 4.2736 - val_categorical_accuracy: 0.0908\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.9229 - categorical_accuracy: 0.1405\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.09160 to 0.12730, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 3.9224 - categorical_accuracy: 0.1405 - val_loss: 3.8078 - val_categorical_accuracy: 0.1273\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5219 - categorical_accuracy: 0.1830\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.12730 to 0.18250, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 482ms/step - loss: 3.5202 - categorical_accuracy: 0.1831 - val_loss: 3.4591 - val_categorical_accuracy: 0.1825\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5129 - categorical_accuracy: 0.1871\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.18250\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 3.5130 - categorical_accuracy: 0.1872 - val_loss: 3.6744 - val_categorical_accuracy: 0.1627\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.2965 - categorical_accuracy: 0.2201\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.18250 to 0.23950, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 481ms/step - loss: 3.2949 - categorical_accuracy: 0.2202 - val_loss: 3.1517 - val_categorical_accuracy: 0.2395\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 10/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3805 - categorical_accuracy: 0.2225\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.23950\n",
      "98/98 [==============================] - 46s 471ms/step - loss: 3.3800 - categorical_accuracy: 0.2223 - val_loss: 3.5593 - val_categorical_accuracy: 0.2124\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 11/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.1739 - categorical_accuracy: 0.2428\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.23950 to 0.26660, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 481ms/step - loss: 3.1728 - categorical_accuracy: 0.2428 - val_loss: 2.9872 - val_categorical_accuracy: 0.2666\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 12/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.0614 - categorical_accuracy: 0.2593\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.26660 to 0.28670, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 481ms/step - loss: 3.0627 - categorical_accuracy: 0.2593 - val_loss: 2.9133 - val_categorical_accuracy: 0.2867\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 13/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.9542 - categorical_accuracy: 0.2749\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.28670\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 2.9557 - categorical_accuracy: 0.2747 - val_loss: 3.1187 - val_categorical_accuracy: 0.2441\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 14/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.9104 - categorical_accuracy: 0.2798\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.28670 to 0.30070, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 477ms/step - loss: 2.9086 - categorical_accuracy: 0.2800 - val_loss: 2.7638 - val_categorical_accuracy: 0.3007\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 15/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.7683 - categorical_accuracy: 0.3047\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.30070 to 0.31290, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 2.7681 - categorical_accuracy: 0.3046 - val_loss: 2.6859 - val_categorical_accuracy: 0.3129\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 16/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.7006 - categorical_accuracy: 0.3143\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.31290 to 0.33280, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 2.7004 - categorical_accuracy: 0.3145 - val_loss: 2.6385 - val_categorical_accuracy: 0.3328\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 17/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.6524 - categorical_accuracy: 0.3250\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.33280\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 2.6505 - categorical_accuracy: 0.3252 - val_loss: 2.8988 - val_categorical_accuracy: 0.2915\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 18/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.6231 - categorical_accuracy: 0.3320\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.33280\n",
      "98/98 [==============================] - 46s 471ms/step - loss: 2.6225 - categorical_accuracy: 0.3321 - val_loss: 2.6727 - val_categorical_accuracy: 0.3184\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 19/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5852 - categorical_accuracy: 0.3390\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.33280 to 0.33450, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 2.5832 - categorical_accuracy: 0.3397 - val_loss: 2.6289 - val_categorical_accuracy: 0.3345\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 20/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5432 - categorical_accuracy: 0.3499\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.33450 to 0.33660, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 476ms/step - loss: 2.5430 - categorical_accuracy: 0.3499 - val_loss: 2.6444 - val_categorical_accuracy: 0.3366\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 21/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5035 - categorical_accuracy: 0.3578\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.33660\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 2.5040 - categorical_accuracy: 0.3578 - val_loss: 2.6853 - val_categorical_accuracy: 0.3202\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 22/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5163 - categorical_accuracy: 0.3523\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.33660\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 2.5170 - categorical_accuracy: 0.3522 - val_loss: 2.6788 - val_categorical_accuracy: 0.3357\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 23/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.4281 - categorical_accuracy: 0.3726\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.33660 to 0.35850, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 2.4285 - categorical_accuracy: 0.3723 - val_loss: 2.5462 - val_categorical_accuracy: 0.3585\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 24/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3995 - categorical_accuracy: 0.3781\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.35850\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 2.3995 - categorical_accuracy: 0.3781 - val_loss: 2.5831 - val_categorical_accuracy: 0.3514\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 25/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3751 - categorical_accuracy: 0.3838\n",
      "Epoch 00025: val_categorical_accuracy improved from 0.35850 to 0.37750, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 2.3752 - categorical_accuracy: 0.3839 - val_loss: 2.4163 - val_categorical_accuracy: 0.3775\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 26/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3377 - categorical_accuracy: 0.3905\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.37750\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 2.3380 - categorical_accuracy: 0.3905 - val_loss: 2.4584 - val_categorical_accuracy: 0.3748\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 27/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3131 - categorical_accuracy: 0.3965\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.37750\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 2.3133 - categorical_accuracy: 0.3966 - val_loss: 2.5473 - val_categorical_accuracy: 0.3589\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 28/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2847 - categorical_accuracy: 0.4010\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.37750\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 2.2843 - categorical_accuracy: 0.4011 - val_loss: 2.5008 - val_categorical_accuracy: 0.3673\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 29/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2624 - categorical_accuracy: 0.4072\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.37750\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 2.2625 - categorical_accuracy: 0.4071 - val_loss: 2.5335 - val_categorical_accuracy: 0.3673\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 30/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2439 - categorical_accuracy: 0.4119\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.37750 to 0.38700, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 477ms/step - loss: 2.2455 - categorical_accuracy: 0.4116 - val_loss: 2.3676 - val_categorical_accuracy: 0.3870\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 31/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.1376 - categorical_accuracy: 0.4366\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.38700 to 0.41560, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 476ms/step - loss: 2.1366 - categorical_accuracy: 0.4366 - val_loss: 2.2496 - val_categorical_accuracy: 0.4156\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 32/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0688 - categorical_accuracy: 0.4497\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.41560 to 0.42190, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 479ms/step - loss: 2.0688 - categorical_accuracy: 0.4498 - val_loss: 2.2415 - val_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 33/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0511 - categorical_accuracy: 0.4557\n",
      "Epoch 00033: val_categorical_accuracy improved from 0.42190 to 0.42670, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 479ms/step - loss: 2.0517 - categorical_accuracy: 0.4556 - val_loss: 2.2432 - val_categorical_accuracy: 0.4267\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 34/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0385 - categorical_accuracy: 0.4565\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.42670\n",
      "98/98 [==============================] - 46s 470ms/step - loss: 2.0388 - categorical_accuracy: 0.4564 - val_loss: 2.2511 - val_categorical_accuracy: 0.4250\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 35/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0182 - categorical_accuracy: 0.4614\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.42670\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 2.0173 - categorical_accuracy: 0.4616 - val_loss: 2.2427 - val_categorical_accuracy: 0.4260\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 36/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0072 - categorical_accuracy: 0.4633\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.42670\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 2.0086 - categorical_accuracy: 0.4632 - val_loss: 2.2364 - val_categorical_accuracy: 0.4216\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 37/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9964 - categorical_accuracy: 0.4665\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.42670\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.9977 - categorical_accuracy: 0.4665 - val_loss: 2.2532 - val_categorical_accuracy: 0.4235\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 38/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9911 - categorical_accuracy: 0.4668\n",
      "Epoch 00038: val_categorical_accuracy improved from 0.42670 to 0.43990, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 1.9904 - categorical_accuracy: 0.4670 - val_loss: 2.2104 - val_categorical_accuracy: 0.4399\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 39/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9808 - categorical_accuracy: 0.4666\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.9810 - categorical_accuracy: 0.4667 - val_loss: 2.2492 - val_categorical_accuracy: 0.4292\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 40/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9697 - categorical_accuracy: 0.4708\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 470ms/step - loss: 1.9698 - categorical_accuracy: 0.4706 - val_loss: 2.2481 - val_categorical_accuracy: 0.4260\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 41/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9661 - categorical_accuracy: 0.4745\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.9651 - categorical_accuracy: 0.4744 - val_loss: 2.2565 - val_categorical_accuracy: 0.4238\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 42/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9488 - categorical_accuracy: 0.4767\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.9482 - categorical_accuracy: 0.4770 - val_loss: 2.2346 - val_categorical_accuracy: 0.4289\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 43/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9401 - categorical_accuracy: 0.4787\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 1.9403 - categorical_accuracy: 0.4786 - val_loss: 2.2131 - val_categorical_accuracy: 0.4304\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 44/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9297 - categorical_accuracy: 0.4825\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 1.9297 - categorical_accuracy: 0.4827 - val_loss: 2.2482 - val_categorical_accuracy: 0.4325\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 45/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9221 - categorical_accuracy: 0.4826\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 1.9223 - categorical_accuracy: 0.4825 - val_loss: 2.2272 - val_categorical_accuracy: 0.4334\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 46/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9110 - categorical_accuracy: 0.4842\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.9112 - categorical_accuracy: 0.4845 - val_loss: 2.2225 - val_categorical_accuracy: 0.4321\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 47/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9062 - categorical_accuracy: 0.4859\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.9061 - categorical_accuracy: 0.4858 - val_loss: 2.2157 - val_categorical_accuracy: 0.4355\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 48/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8886 - categorical_accuracy: 0.4916\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.8890 - categorical_accuracy: 0.4916 - val_loss: 2.2935 - val_categorical_accuracy: 0.4206\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 49/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8849 - categorical_accuracy: 0.4921\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.8851 - categorical_accuracy: 0.4922 - val_loss: 2.2875 - val_categorical_accuracy: 0.4260\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 50/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8808 - categorical_accuracy: 0.4919\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 1.8805 - categorical_accuracy: 0.4916 - val_loss: 2.2489 - val_categorical_accuracy: 0.4309\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 51/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8621 - categorical_accuracy: 0.4963\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.8616 - categorical_accuracy: 0.4964 - val_loss: 2.2742 - val_categorical_accuracy: 0.4311\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 52/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8550 - categorical_accuracy: 0.4972\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.8559 - categorical_accuracy: 0.4970 - val_loss: 2.2505 - val_categorical_accuracy: 0.4321\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 53/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8459 - categorical_accuracy: 0.5008\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.43990\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.8453 - categorical_accuracy: 0.5011 - val_loss: 2.3131 - val_categorical_accuracy: 0.4182\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 54/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8367 - categorical_accuracy: 0.5053\n",
      "Epoch 00054: val_categorical_accuracy improved from 0.43990 to 0.44290, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 47s 478ms/step - loss: 1.8359 - categorical_accuracy: 0.5054 - val_loss: 2.2098 - val_categorical_accuracy: 0.4429\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 55/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8232 - categorical_accuracy: 0.5028\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 466ms/step - loss: 1.8226 - categorical_accuracy: 0.5029 - val_loss: 2.2872 - val_categorical_accuracy: 0.4323\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 56/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8195 - categorical_accuracy: 0.5070\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.8192 - categorical_accuracy: 0.5071 - val_loss: 2.2962 - val_categorical_accuracy: 0.4264\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 57/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8119 - categorical_accuracy: 0.5061\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 1.8121 - categorical_accuracy: 0.5059 - val_loss: 2.2439 - val_categorical_accuracy: 0.4347\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 58/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8039 - categorical_accuracy: 0.5097\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 469ms/step - loss: 1.8047 - categorical_accuracy: 0.5096 - val_loss: 2.2270 - val_categorical_accuracy: 0.4342\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 59/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7854 - categorical_accuracy: 0.5145\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 468ms/step - loss: 1.7859 - categorical_accuracy: 0.5142 - val_loss: 2.2622 - val_categorical_accuracy: 0.4345\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 60/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7699 - categorical_accuracy: 0.5178\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.44290\n",
      "98/98 [==============================] - 46s 467ms/step - loss: 1.7692 - categorical_accuracy: 0.5179 - val_loss: 2.2670 - val_categorical_accuracy: 0.4332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ff627c198>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for 60 epochs with step learning rate\n",
    "\n",
    "from math import ceil\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\"/content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size), steps_per_epoch=ceil(len(x_train)/batch_size), epochs = 60, validation_data = datagen_val.flow(x_test,y_test, batch_size=batch_size), validation_steps=ceil(len(x_test)/batch_size), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vHX7Jf8J5qK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzQHP5-Iul1l"
   },
   "source": [
    "### Further Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ETh9-yH_nwmO",
    "outputId": "bbe400cd-2b87-4533-a656-dcf21e9c5abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "fine_tune_at = len(base_model_cifar.layers) - 20\n",
    "print(fine_tune_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbN0eknsn3mh"
   },
   "outputs": [],
   "source": [
    "# Set more convolutional layers as trainable.\n",
    "\n",
    "for layer in base_model_cifar.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "briV6Ln6n43M",
    "outputId": "21d4e99e-e0e4-4a37-e6b6-be9e64a16738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa061d0d780> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa061cafbe0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa050513f60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0798ecf28> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0504cde10> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa050466940> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0504666d8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0503dbda0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0503ec5c0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa050366ac8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503669e8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050374dd8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa050341da0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0503816a0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503817b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0503b0eb8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa050309518> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050309eb8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05030e630> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0502d8f28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05030e5f8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa05028df98> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0501fa978> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05021f9b0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05021fac8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa0501a87f0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0501a8da0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa0501b1898> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05012ddd8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05012dcf8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa050139f98> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05013c9e8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa0500a7978> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05013cac8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa0501b1828> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa0500d37f0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa0500d3da0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa05005b898> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa05005b828> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa05003cef0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e5783c8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e5820b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e54fc18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e578d68> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e4fbac8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e4fba58> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e567c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e47df28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e47ddd8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e4a43c8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e42e0b8> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e3f7c18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e4a4d68> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e508b00> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e3a8ac8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e3a8a58> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e412c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e3b7b00> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e3b7b38> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e33d668> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e33def0> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e33deb8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e346048> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e2c2d68> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e2c2cf8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e2d0e10> False\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e25c358> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e25cdd8> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e1eb668> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e1ebef0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e1ebeb8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e1f0048> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e2d0da0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e170d68> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e170cf8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e17fe10> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e15da58> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e17fdd8> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa00e109908> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e114208> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa00e0d5e48> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa00e1142e8> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7fa00e08dd68> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa05043e0b8> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7fa00e09df28> True\n"
     ]
    }
   ],
   "source": [
    "# Display layers and trainable status\n",
    "\n",
    "for i in base_model_cifar.layers:\n",
    "  print(i, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2FU4SJXohQy"
   },
   "outputs": [],
   "source": [
    "# Ensure all BN layers are trainable. Reference https://twitter.com/jeremyphoward/status/1182062808206213120?s=12\n",
    "\n",
    "for layer in base_model_cifar.layers:\n",
    "  if \"BatchNormalization\" in str(layer):\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Wa9MlS8ln4p8",
    "outputId": "1936ddda-bfb5-4b1c-ac8f-4d37b057d736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.training.Model object at 0x7fa00e09dfd0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9ff77a27f0> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f9ff77a2a20> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fa061d0dfd0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x7fa061d0da20> True\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "  print(i, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ux-b7OkQoBgw"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "b2q5gAlfoBfA",
    "outputId": "e80dcfc7-925f-4b8f-e06f-3d36f41da858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 5, 5, 512)         11186889  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 100)         51200     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 11,248,189\n",
      "Trainable params: 7,278,199\n",
      "Non-trainable params: 3,969,990\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AWL5k_mMoBZB",
    "outputId": "500a32b7-ce08-4c71-d8ed-5e0400e08de4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uGnMOr8-oL-n",
    "outputId": "a1ffb5b5-af20-4e32-f6f0-99895053416b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.4277 - categorical_accuracy: 0.3913\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.19080, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 523ms/step - loss: 2.4215 - categorical_accuracy: 0.3924 - val_loss: 5.9445 - val_categorical_accuracy: 0.1908\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6493 - categorical_accuracy: 0.5350\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.19080 to 0.44420, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.6493 - categorical_accuracy: 0.5350 - val_loss: 2.2661 - val_categorical_accuracy: 0.4442\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4478 - categorical_accuracy: 0.5834\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.44420 to 0.51460, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 1.4474 - categorical_accuracy: 0.5835 - val_loss: 1.8524 - val_categorical_accuracy: 0.5146\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.3205 - categorical_accuracy: 0.6184\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.51460 to 0.57320, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.3214 - categorical_accuracy: 0.6182 - val_loss: 1.5428 - val_categorical_accuracy: 0.5732\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2219 - categorical_accuracy: 0.6425\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.57320 to 0.58310, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.2229 - categorical_accuracy: 0.6421 - val_loss: 1.4752 - val_categorical_accuracy: 0.5831\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1462 - categorical_accuracy: 0.6652\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.58310 to 0.61180, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.1454 - categorical_accuracy: 0.6655 - val_loss: 1.3897 - val_categorical_accuracy: 0.6118\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0707 - categorical_accuracy: 0.6807\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.61180\n",
      "98/98 [==============================] - 50s 507ms/step - loss: 1.0713 - categorical_accuracy: 0.6809 - val_loss: 1.4455 - val_categorical_accuracy: 0.6097\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0178 - categorical_accuracy: 0.6958\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.61180 to 0.62300, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.0178 - categorical_accuracy: 0.6959 - val_loss: 1.3592 - val_categorical_accuracy: 0.6230\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9529 - categorical_accuracy: 0.7147\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.62300 to 0.62690, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 0.9536 - categorical_accuracy: 0.7145 - val_loss: 1.3427 - val_categorical_accuracy: 0.6269\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 10/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8966 - categorical_accuracy: 0.7283\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.62690 to 0.63550, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 0.8984 - categorical_accuracy: 0.7281 - val_loss: 1.3630 - val_categorical_accuracy: 0.6355\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 11/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8536 - categorical_accuracy: 0.7409\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.63550 to 0.64100, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 0.8533 - categorical_accuracy: 0.7409 - val_loss: 1.3218 - val_categorical_accuracy: 0.6410\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 12/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8024 - categorical_accuracy: 0.7548\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.64100 to 0.65180, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 0.8034 - categorical_accuracy: 0.7543 - val_loss: 1.2967 - val_categorical_accuracy: 0.6518\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 13/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7585 - categorical_accuracy: 0.7658\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.65180\n",
      "98/98 [==============================] - 50s 510ms/step - loss: 0.7587 - categorical_accuracy: 0.7657 - val_loss: 1.4199 - val_categorical_accuracy: 0.6396\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 14/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7167 - categorical_accuracy: 0.7782\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.65180\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.7176 - categorical_accuracy: 0.7779 - val_loss: 1.3852 - val_categorical_accuracy: 0.6446\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 15/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6809 - categorical_accuracy: 0.7892\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.65180\n",
      "98/98 [==============================] - 50s 506ms/step - loss: 0.6808 - categorical_accuracy: 0.7893 - val_loss: 1.4414 - val_categorical_accuracy: 0.6488\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 16/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6399 - categorical_accuracy: 0.8017\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.65180 to 0.66390, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 0.6398 - categorical_accuracy: 0.8015 - val_loss: 1.3624 - val_categorical_accuracy: 0.6639\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 17/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6142 - categorical_accuracy: 0.8076\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.66390\n",
      "98/98 [==============================] - 50s 508ms/step - loss: 0.6146 - categorical_accuracy: 0.8074 - val_loss: 1.4337 - val_categorical_accuracy: 0.6551\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 18/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5784 - categorical_accuracy: 0.8191\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.66390\n",
      "98/98 [==============================] - 50s 506ms/step - loss: 0.5789 - categorical_accuracy: 0.8190 - val_loss: 1.3689 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 19/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5406 - categorical_accuracy: 0.8288\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.66390\n",
      "98/98 [==============================] - 50s 506ms/step - loss: 0.5405 - categorical_accuracy: 0.8288 - val_loss: 1.4522 - val_categorical_accuracy: 0.6598\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 20/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5148 - categorical_accuracy: 0.8359\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.66390\n",
      "98/98 [==============================] - 50s 506ms/step - loss: 0.5153 - categorical_accuracy: 0.8357 - val_loss: 1.4598 - val_categorical_accuracy: 0.6615\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 21/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4914 - categorical_accuracy: 0.8440\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.66390 to 0.66720, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 0.4911 - categorical_accuracy: 0.8442 - val_loss: 1.4837 - val_categorical_accuracy: 0.6672\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 22/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4576 - categorical_accuracy: 0.8531\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 50s 506ms/step - loss: 0.4580 - categorical_accuracy: 0.8529 - val_loss: 1.5498 - val_categorical_accuracy: 0.6570\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 23/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4359 - categorical_accuracy: 0.8600\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 50s 510ms/step - loss: 0.4369 - categorical_accuracy: 0.8598 - val_loss: 1.7087 - val_categorical_accuracy: 0.6432\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 24/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.8676\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.4131 - categorical_accuracy: 0.8675 - val_loss: 1.6286 - val_categorical_accuracy: 0.6492\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 25/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3953 - categorical_accuracy: 0.8731\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.3954 - categorical_accuracy: 0.8731 - val_loss: 1.5384 - val_categorical_accuracy: 0.6599\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 26/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3681 - categorical_accuracy: 0.8817\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 50s 505ms/step - loss: 0.3691 - categorical_accuracy: 0.8813 - val_loss: 1.5902 - val_categorical_accuracy: 0.6604\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 27/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3564 - categorical_accuracy: 0.8847\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.3564 - categorical_accuracy: 0.8847 - val_loss: 1.6964 - val_categorical_accuracy: 0.6547\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 28/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.8904\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 50s 507ms/step - loss: 0.3448 - categorical_accuracy: 0.8903 - val_loss: 1.6213 - val_categorical_accuracy: 0.6601\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 29/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3198 - categorical_accuracy: 0.8976\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.66720\n",
      "98/98 [==============================] - 50s 507ms/step - loss: 0.3201 - categorical_accuracy: 0.8975 - val_loss: 1.6366 - val_categorical_accuracy: 0.6616\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 30/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3121 - categorical_accuracy: 0.9000\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.66720 to 0.67130, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 0.3123 - categorical_accuracy: 0.8997 - val_loss: 1.6350 - val_categorical_accuracy: 0.6713\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 31/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.2458 - categorical_accuracy: 0.9223\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.67130 to 0.71020, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 0.2456 - categorical_accuracy: 0.9224 - val_loss: 1.3566 - val_categorical_accuracy: 0.7102\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 32/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1973 - categorical_accuracy: 0.9397\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.71020 to 0.71200, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 0.1975 - categorical_accuracy: 0.9397 - val_loss: 1.3413 - val_categorical_accuracy: 0.7120\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 33/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1799 - categorical_accuracy: 0.9461\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.71200\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1802 - categorical_accuracy: 0.9462 - val_loss: 1.3569 - val_categorical_accuracy: 0.7101\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 34/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1642 - categorical_accuracy: 0.9517\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.71200\n",
      "98/98 [==============================] - 49s 505ms/step - loss: 0.1642 - categorical_accuracy: 0.9516 - val_loss: 1.3979 - val_categorical_accuracy: 0.7116\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 35/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1573 - categorical_accuracy: 0.9532\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.71200\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1571 - categorical_accuracy: 0.9532 - val_loss: 1.3909 - val_categorical_accuracy: 0.7095\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 36/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1526 - categorical_accuracy: 0.9547\n",
      "Epoch 00036: val_categorical_accuracy improved from 0.71200 to 0.71270, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 515ms/step - loss: 0.1525 - categorical_accuracy: 0.9546 - val_loss: 1.3642 - val_categorical_accuracy: 0.7127\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 37/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1456 - categorical_accuracy: 0.9567\n",
      "Epoch 00037: val_categorical_accuracy improved from 0.71270 to 0.71310, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 513ms/step - loss: 0.1458 - categorical_accuracy: 0.9566 - val_loss: 1.3879 - val_categorical_accuracy: 0.7131\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 38/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1435 - categorical_accuracy: 0.9575\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.71310\n",
      "98/98 [==============================] - 49s 502ms/step - loss: 0.1435 - categorical_accuracy: 0.9576 - val_loss: 1.4004 - val_categorical_accuracy: 0.7118\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 39/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1390 - categorical_accuracy: 0.9582\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.71310\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1390 - categorical_accuracy: 0.9581 - val_loss: 1.4182 - val_categorical_accuracy: 0.7129\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 40/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.9597\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.71310\n",
      "98/98 [==============================] - 49s 501ms/step - loss: 0.1337 - categorical_accuracy: 0.9598 - val_loss: 1.4298 - val_categorical_accuracy: 0.7109\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 41/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1326 - categorical_accuracy: 0.9591\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.71310\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1327 - categorical_accuracy: 0.9590 - val_loss: 1.4255 - val_categorical_accuracy: 0.7123\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 42/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1282 - categorical_accuracy: 0.9614\n",
      "Epoch 00042: val_categorical_accuracy improved from 0.71310 to 0.71470, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 0.1284 - categorical_accuracy: 0.9615 - val_loss: 1.4307 - val_categorical_accuracy: 0.7147\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 43/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1281 - categorical_accuracy: 0.9623\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.71470\n",
      "98/98 [==============================] - 49s 502ms/step - loss: 0.1280 - categorical_accuracy: 0.9623 - val_loss: 1.4561 - val_categorical_accuracy: 0.7132\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 44/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.9610\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.71470\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1256 - categorical_accuracy: 0.9611 - val_loss: 1.4641 - val_categorical_accuracy: 0.7129\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 45/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.9620\n",
      "Epoch 00045: val_categorical_accuracy improved from 0.71470 to 0.71580, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 511ms/step - loss: 0.1237 - categorical_accuracy: 0.9620 - val_loss: 1.4670 - val_categorical_accuracy: 0.7158\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 46/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.9645\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.1208 - categorical_accuracy: 0.9646 - val_loss: 1.4561 - val_categorical_accuracy: 0.7145\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 47/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1153 - categorical_accuracy: 0.9661\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1153 - categorical_accuracy: 0.9661 - val_loss: 1.4771 - val_categorical_accuracy: 0.7117\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 48/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1185 - categorical_accuracy: 0.9648\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 50s 505ms/step - loss: 0.1183 - categorical_accuracy: 0.9648 - val_loss: 1.4829 - val_categorical_accuracy: 0.7114\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 49/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1105 - categorical_accuracy: 0.9670\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1106 - categorical_accuracy: 0.9669 - val_loss: 1.4755 - val_categorical_accuracy: 0.7134\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 50/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.9662\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1114 - categorical_accuracy: 0.9663 - val_loss: 1.5061 - val_categorical_accuracy: 0.7091\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 51/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1090 - categorical_accuracy: 0.9668\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 502ms/step - loss: 0.1087 - categorical_accuracy: 0.9669 - val_loss: 1.4961 - val_categorical_accuracy: 0.7155\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 52/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1101 - categorical_accuracy: 0.9676\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.1100 - categorical_accuracy: 0.9676 - val_loss: 1.4978 - val_categorical_accuracy: 0.7132\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 53/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1066 - categorical_accuracy: 0.9681\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 502ms/step - loss: 0.1067 - categorical_accuracy: 0.9681 - val_loss: 1.5230 - val_categorical_accuracy: 0.7120\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 54/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1039 - categorical_accuracy: 0.9690\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 505ms/step - loss: 0.1036 - categorical_accuracy: 0.9692 - val_loss: 1.4919 - val_categorical_accuracy: 0.7138\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 55/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1024 - categorical_accuracy: 0.9700\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 504ms/step - loss: 0.1020 - categorical_accuracy: 0.9701 - val_loss: 1.5328 - val_categorical_accuracy: 0.7116\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 56/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1017 - categorical_accuracy: 0.9695\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.71580\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.1022 - categorical_accuracy: 0.9695 - val_loss: 1.5495 - val_categorical_accuracy: 0.7104\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 57/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0991 - categorical_accuracy: 0.9704\n",
      "Epoch 00057: val_categorical_accuracy improved from 0.71580 to 0.71600, saving model to /content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\n",
      "98/98 [==============================] - 50s 513ms/step - loss: 0.0991 - categorical_accuracy: 0.9704 - val_loss: 1.5182 - val_categorical_accuracy: 0.7160\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 58/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.1014 - categorical_accuracy: 0.9699\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.71600\n",
      "98/98 [==============================] - 49s 500ms/step - loss: 0.1011 - categorical_accuracy: 0.9701 - val_loss: 1.5564 - val_categorical_accuracy: 0.7090\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 59/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0974 - categorical_accuracy: 0.9706\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.71600\n",
      "98/98 [==============================] - 49s 502ms/step - loss: 0.0974 - categorical_accuracy: 0.9706 - val_loss: 1.5658 - val_categorical_accuracy: 0.7069\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 60/60\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0987 - categorical_accuracy: 0.9701\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.71600\n",
      "98/98 [==============================] - 49s 503ms/step - loss: 0.0986 - categorical_accuracy: 0.9701 - val_loss: 1.5500 - val_categorical_accuracy: 0.7104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ff6559f28>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model i.e. perform further fine tuning\n",
    "\n",
    "from math import ceil\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\"/content/drive/My Drive/models/resnet18_cifar100_fine_tuned.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size), steps_per_epoch=ceil(len(x_train)/batch_size), epochs = 60, validation_data = datagen_val.flow(x_test,y_test, batch_size=batch_size), validation_steps=ceil(len(x_test)/batch_size), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmwHJWY6oL9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFL3JnAD0uWL"
   },
   "source": [
    "## **Observations :**\n",
    "\n",
    "\n",
    "\n",
    "*   Transfer learning + Fine tuning is carried out for total of 150 epochs\n",
    "*   Final validation accuracy obtained is 71.60%\n",
    "*   ResNet18 model is modified so that it can be used with CIFAR100 dataset where image size is 32x32\n",
    "*   ResNet18 modifications - Removed Initial MaxPool layer. Reduced the stride of 7x7 Convolutional layer from Stride 2 to Stride 1. This helps with retaining the channel size(>2x2) after the last Convolutional layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpuLNgLP02QB"
   },
   "source": [
    "## References & Attributions :\n",
    "\n",
    "\n",
    "\n",
    "*   https://twitter.com/jeremyphoward/status/1182062808206213120?s=12\n",
    "*   https://github.com/qubvel/classification_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_ZhTrRvxhJ6"
   },
   "source": [
    "###### Disclaimer: The contents of this notebook are used for educational purposes i.e. for learning and research."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Assignment20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
