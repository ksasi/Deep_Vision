{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ksasi/EVA/blob/master/Project13/Assignment13.ipynb)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KkwXnw9OfHZl",
    "outputId": "1fcb1890-2350-4e21-babc-b18e3330a570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import numpy, time, matplotlib, Keras models, backend, layers and utils\n",
    "# set random seed using random.seed from numpy\n",
    "\n",
    "from keras import backend as K\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate, Add\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NHpnoCHZfO8g",
    "outputId": "3f482a11-66a7-4563-d1b4-3a3b4c6e9026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import cifar10 from keras datasets\n",
    "# Load CIFAR10 dataset from Keras datasets module seperately as train and test datasets\n",
    "# Obtain number of training and testing examples, image dimensions and number of classes\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "num_train, img_rows, img_cols,img_channels =  train_features.shape\n",
    "num_test, _, _, _ =  test_features.shape\n",
    "num_classes = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2R9KHV8A19cw",
    "outputId": "b676a7b2-99b3-475a-e3d4-9e96cdbdeaaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "50000\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print (num_classes)\n",
    "print (num_train)\n",
    "print (train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "14HyBUXdfS6G",
    "outputId": "30c688c1-6cb7-4bb2-f70d-6470c480edcb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAADECAYAAAAvbXA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAMDAwMDg3PA/IAaGBgYGBicA/8XX+JaT2U4UocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display images corresponding to each class from training dataset\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(train_labels[:]==i)[0]\n",
    "    features_idx = train_features[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = features_idx[img_num]\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmfsk76-fadV"
   },
   "outputs": [],
   "source": [
    "# Define function to plot summarize history for accuracy and loss\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJMT4rjgfdZz"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate accuracy\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5c5nDvxm6zR"
   },
   "outputs": [],
   "source": [
    "train_features = train_features.astype('float32')/255\n",
    "test_features = test_features.astype('float32')/255\n",
    "# convert class labels to binary class labels\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "9upyHvwj3JhG",
    "outputId": "e9c964c0-346c-4b55-a535-cd37cd86a7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7Fw8Z54IheE"
   },
   "source": [
    "## Image Normalization using values of: (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "e5U2c0unqgdP",
    "outputId": "8afb88b6-55b2-48d2-c2c4-3d52cec64976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=120.708 (64.150), test=121.529 (64.061)\n",
      "(128, 32, 32, 3) 604.6387 321.22253\n",
      "(50000, 32, 32, 3) 598.4765 319.27414\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "\n",
    "\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "# calculate the mean on the training dataset, this is irrelevant as we are manually using different values of mean and standard deviations for CIFAR10 dataset\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# Manually set the mean and standard deviation for datagen as below. These are mean and std obtained by calculating \"mean of the std/mean for the channel per image\"\n",
    "datagen.mean = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32).reshape((1,1,3))\n",
    "datagen.std = np.array([0.2023, 0.1994, 0.2010], dtype=np.float32).reshape((1,1,3))\n",
    "\n",
    "\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=128)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wUbVtDtRC-y3",
    "outputId": "21fbfebe-3953-4425-da8c-aa4cda798944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uetv1X9bDDiD",
    "outputId": "e8c28c01-2636-4ccd-82d6-16d06a27ae76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10110.10585027962\n",
      "0.2022021170055924\n"
     ]
    }
   ],
   "source": [
    "# Use Normalization values of: (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "# Calculation of above values as \"mean of the std for the channel per image\"\n",
    "\n",
    "std = 0\n",
    "for i in range(trainX.shape[0]):\n",
    "  std = std + np.std(trainX[i,:,:,0]/255)\n",
    "\n",
    "print(std)\n",
    "print(std/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "806B2YR8nH9L",
    "outputId": "189b5062-c073-4b10-9121-93e2fe018429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.2023 0.1994 0.201 ]]]\n",
      "[[[0.4914 0.4822 0.4465]]]\n"
     ]
    }
   ],
   "source": [
    "print(datagen.std)\n",
    "print(datagen.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-eJt3EDq1g5"
   },
   "outputs": [],
   "source": [
    "# Obtain train and test dataset after applying image standardization\n",
    "\n",
    "iterator1 = datagen.flow(testX, testy, batch_size=len(testX), shuffle=False)\n",
    "batch_testX, batch_testy = iterator1.next()\n",
    "\n",
    "X_train = batchX\n",
    "X_test = batch_testX\n",
    "\n",
    "y_train=batchy\n",
    "y_test=batch_testy\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "av2re-bNrBnY"
   },
   "outputs": [],
   "source": [
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IJQVuvrSppH"
   },
   "source": [
    "### With Cutout / Random Erasing\n",
    "\n",
    "- https://github.com/yu4u/cutout-random-erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Dlcvln8FSooc",
    "outputId": "7b2154b4-809d-413a-e752-221553672f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './random_eraser'...\n",
      "remote: Enumerating objects: 23, done.\u001b[K\n",
      "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
      "Unpacking objects: 100% (23/23), done.\n"
     ]
    }
   ],
   "source": [
    "# Import Cutout / Random Erasing implementation, especially for ImageDataGenerator in Keras from Github (https://github.com/yu4u/cutout-random-erasing)\n",
    "\n",
    "!git clone https://github.com/ksasi/cutout-random-erasing ./random_eraser                                                   \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/content/random_eraser/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hO3sHH0tz5Ku"
   },
   "source": [
    "### Random Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDwCt2Npcj9d"
   },
   "outputs": [],
   "source": [
    "# Use albumentations to perform data augmentations i.e. increase image size to 40x40 and perform random crop to 32x32. Perform Horizontal and Vertical flip with probability of 0.5\n",
    "# https://albumentations.readthedocs.io\n",
    "\n",
    "#!pip install albumentations\n",
    "import cv2\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    RandomCrop,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomBrightnessContrast,    \n",
    "    RandomGamma\n",
    ")\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([              \n",
    "              PadIfNeeded(p=1, min_height=40, min_width=40, border_mode = cv2.BORDER_REFLECT),\n",
    "              RandomCrop(32, 32),\n",
    "              HorizontalFlip(p=0.5),\n",
    "              VerticalFlip(p=0.5)\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjX7VXN8umM-"
   },
   "outputs": [],
   "source": [
    "# Buld CIFAR10Sequence so that this can be passed in fit_generator for augmentations. The below class handles all augmentations and random eraser/cutout\n",
    "\n",
    "from keras.utils import Sequence\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations, pre_process):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.preprocess = pre_process\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.stack([self.preprocess(self.augment(image=x)[\"image\"]) for x in batch_x], axis=0), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6INVjywLdLw"
   },
   "source": [
    "## Define ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oy7KXXyvVw4h"
   },
   "outputs": [],
   "source": [
    "# Resnet Block\n",
    "def add_resblock(input, num_filter = 12, dropout_rate = 0.2, l = 2, dim_reduce = False, dilation_rate=(1, 1), wd = 1e-4):\n",
    "    temp = input\n",
    "    for i in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        if dim_reduce == True and i == 0:\n",
    "          Conv2D_3_3 = Conv2D(num_filter, (3,3), strides=(2, 2), use_bias=False ,padding='same', dilation_rate=(1, 1), kernel_initializer='he_normal', kernel_regularizer=l2(wd))(relu)\n",
    "        else:\n",
    "          Conv2D_3_3 = Conv2D(num_filter, (3,3), use_bias=False ,padding='same', dilation_rate=(1, 1), kernel_initializer='he_normal', kernel_regularizer=l2(wd))(relu)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        temp = Conv2D_3_3\n",
    "        \n",
    "    if dim_reduce == False:\n",
    "      Conv2D_1_1 = Conv2D(num_filter, (1,1), strides=(1, 1), use_bias=False ,padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(wd))(input)\n",
    "      concat = Concatenate(axis=-1)([input,temp])\n",
    "      add = Add()([Conv2D_1_1,temp])\n",
    "    else:\n",
    "      Conv2D_1_1 = Conv2D(num_filter, (1,1), strides=(2, 2), use_bias=False ,padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(wd))(input)\n",
    "      concat = Concatenate(axis=-1)([Conv2D_1_1,temp])\n",
    "      add = Add()([Conv2D_1_1,temp])\n",
    "      \n",
    "    #return concat\n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bV3YYl20vB8w"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    #flat = Flatten()(AvgPooling)\n",
    "    flat = GlobalAveragePooling2D()(relu)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGLI0PIfpIs-"
   },
   "outputs": [],
   "source": [
    "# Define ResNet18 model\n",
    "# Removed the strided from 7x7 convolution. So 7x7 convolutions are with stride 1. The thinking is there is already a MaxPool after 7x7 convolution , hence we don't need to start with Stride 2 convolution.\n",
    "# Stride 2 is removed from the last Resnet block (4th block). Stride 2 can result in loss of information. We want to preserve as much information as possible before Softmax/GAP.\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "num_classes = 10\n",
    "channel = 3\n",
    "\n",
    "input = Input(shape=(32, 32, channel,))\n",
    "First_Conv2D = Conv2D(64, (7,7), strides=(1, 1), use_bias=False ,padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input)\n",
    "BatchNorm = BatchNormalization()(First_Conv2D)\n",
    "relu = Activation('relu')(BatchNorm)\n",
    "MaxPool = MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='same')(relu)\n",
    "\n",
    "r18_layers = [2, 2, 2, 2]\n",
    "\n",
    "Block = MaxPool\n",
    "for n,k in enumerate(r18_layers):\n",
    "  if n in [0, 3]:\n",
    "    for j in range(k):\n",
    "      Block = add_resblock(Block, num_filter = 64*(2**n), dropout_rate = 0.1, l = 2, dim_reduce = False, dilation_rate=(1, 1), wd = 1e-4)\n",
    "  else:\n",
    "    for j in range(k):\n",
    "      if j in [0]:\n",
    "        Block = add_resblock(Block, num_filter = 64*(2**n), dropout_rate = 0.1, l = 2, dim_reduce = True, dilation_rate=(1, 1), wd = 1e-4)\n",
    "      else:\n",
    "        Block = add_resblock(Block, num_filter = 64*(2**n), dropout_rate = 0.1, l = 2, dim_reduce = False, dilation_rate=(1, 1), wd = 1e-4)\n",
    "        \n",
    "output = output_layer(Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-htMgBFPpI29",
    "outputId": "1f2088bd-9963-4e0d-ae0d-ce6928ea02f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 64)   9408        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 32, 64)   256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 32, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 64)   36864       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 64)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 64)   256         dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 64)   36864       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 64)   4096        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 64)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 16, 16, 64)   0           conv2d_79[0][0]                  \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 64)   256         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 64)   36864       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 64)   0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 64)   256         dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 64)   36864       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 64)   4096        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 64)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 64)   0           conv2d_82[0][0]                  \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 64)   256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 128)    73728       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 128)    0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 128)    512         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 128)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 128)    147456      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 128)    8192        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 128)    0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 128)    0           conv2d_85[0][0]                  \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 128)    512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 128)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 128)    147456      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 128)    0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 128)    147456      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 128)    16384       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 128)    0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 128)    0           conv2d_88[0][0]                  \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 128)    512         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 256)    294912      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 4, 4, 256)    0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 256)    1024        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 256)    589824      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 256)    32768       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 4, 4, 256)    0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 4, 4, 256)    0           conv2d_91[0][0]                  \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 256)    1024        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 256)    589824      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 4, 4, 256)    0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 256)    1024        dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 256)    589824      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 256)    65536       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 4, 4, 256)    0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 4, 4, 256)    0           conv2d_94[0][0]                  \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 4, 256)    1024        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 4, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 512)    1179648     activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 4, 4, 512)    0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 4, 4, 512)    2048        dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 4, 4, 512)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 512)    2359296     activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 512)    131072      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 4, 4, 512)    0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 4, 4, 512)    0           conv2d_97[0][0]                  \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 4, 4, 512)    2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 4, 4, 512)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 512)    2359296     activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 4, 4, 512)    0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 512)    2048        dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 4, 4, 512)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 512)    2359296     activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 512)    262144      add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 4, 4, 512)    0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 4, 4, 512)    0           conv2d_100[0][0]                 \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 4, 4, 512)    2048        add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 4, 4, 512)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 512)          0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           5130        global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,540,170\n",
      "Trainable params: 11,532,234\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model and display model summary\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nJyUsfljpsB"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dzKHBIxpVDt"
   },
   "outputs": [],
   "source": [
    "# LR Finder class\n",
    "\n",
    "class LR_Finder(Callback):\n",
    "    \n",
    "    def __init__(self, start_lr=1e-5, end_lr=10, step_size=None, beta=.98):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.start_lr = start_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.step_size = step_size\n",
    "        self.beta = beta\n",
    "        self.lr_mult = (end_lr/start_lr)**(1/step_size)\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_loss = 1e9\n",
    "        self.avg_loss = 0\n",
    "        self.losses, self.smoothed_losses, self.lrs, self.iterations = [], [], [], []\n",
    "        self.iteration = 0\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.start_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        self.iteration += 1\n",
    "        \n",
    "        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * loss\n",
    "        smoothed_loss = self.avg_loss / (1 - self.beta**self.iteration)\n",
    "        \n",
    "        # Check if the loss is not exploding\n",
    "        if self.iteration>1 and smoothed_loss > self.best_loss * 4:\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        if smoothed_loss < self.best_loss or self.iteration==1:\n",
    "            self.best_loss = smoothed_loss\n",
    "        \n",
    "        lr = self.start_lr * (self.lr_mult**self.iteration)\n",
    "        \n",
    "        self.losses.append(loss)\n",
    "        self.smoothed_losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "        self.iterations.append(self.iteration)\n",
    "        \n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, lr)  \n",
    "        \n",
    "    def plot_lr(self):\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Learning rate')\n",
    "        plt.plot(self.iterations, self.lrs)\n",
    "        \n",
    "    def plot(self, n_skip=10):\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Learning rate (log scale)')\n",
    "        plt.plot(self.lrs[n_skip:-5], self.losses[n_skip:-5])\n",
    "        plt.xscale('log')\n",
    "        \n",
    "    def plot_smoothed_loss(self, n_skip=10):\n",
    "        plt.ylabel('Smoothed Losses')\n",
    "        plt.xlabel('Learning rate (log scale)')\n",
    "        plt.plot(self.lrs[n_skip:-5], self.smoothed_losses[n_skip:-5])\n",
    "        plt.xscale('log')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.ylabel('Losses')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.plot(self.iterations[10:], self.losses[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBP_lOfkpVMQ"
   },
   "outputs": [],
   "source": [
    "# Create LR finder instance to find the optimum learning rate\n",
    "\n",
    "lr_finder = LR_Finder(start_lr=1e-5, end_lr=100, step_size=np.ceil(X_train.shape[0]/(128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Iq79PD8ZpVTY",
    "outputId": "8c8c6c65-34b4-40c9-aba5-0128ed5a536b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<__main__...., validation_data=(array([[[..., verbose=1, callbacks=[<__main__..., steps_per_epoch=390, epochs=1)`\n",
      "  \n",
      "W0803 13:36:39.743660 140461181249408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 4.7540 - acc: 0.1656 - val_loss: 14.5142 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbeed81b160>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random_eraser import get_random_eraser\n",
    "\n",
    "# Use pixel_level = True in random_eraser as below\n",
    "\n",
    "eraser = get_random_eraser(v_l=0, v_h=1, pixel_level=True) \n",
    "\n",
    "train_gen = CIFAR10Sequence(X_train, Y_train, batch_size = 128, augmentations = AUGMENTATIONS_TRAIN, pre_process = eraser)\n",
    "\n",
    "# Ensure that number of epochs = 1 when calling fit()\n",
    "model.fit_generator(train_gen,samples_per_epoch = X_train.shape[0], nb_epoch = 1, validation_data = (X_test, Y_test), verbose=1, callbacks=[lr_finder] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "YclN0vJUpVZo",
    "outputId": "3bba0a6c-2f19-4ec9-9cd9-eb7e451b12d2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "5R72JpoSp5mh",
    "outputId": "152cdc5e-d015-444d-fc6a-096e0e639a05"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6pGIwi8HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "zDrI4OjMp5ug",
    "outputId": "68bdfcb4-7137-408a-a373-25e2fdc2118b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcZHV57/HPU1VdvS/TMz0LDLOy\niBJxaQiKGqPojQlXjRqVRCNqRPNKVGLMjV7Njck1N+rN6vVeIxojRiUJKkaJogREBQWcEYZFYJiV\n6WGW7ul9q+qqeu4f5/RQNL1UL1WnTvX3/XrVq0+dOnV+T5/pqad+y/n9zN0REZHVKxF1ACIiEi0l\nAhGRVU6JQERklVMiEBFZ5ZQIRERWOSUCEZFVTolARGSVUyIQEVnllAhERFY5JQIRkVUuFXUApVi3\nbp1v27Yt6jBERGJl9+7dfe7etdBxsUgE27ZtY9euXVGHISISK2Z2uJTjytY0ZGafN7OTZvZA0b5O\nM7vZzB4Nf64pV/kiIlKacvYRfAH4lRn7PgDc4u7nALeEz0VEJEJlSwTu/kOgf8buVwHXhtvXAq8u\nV/kiIlKaSo8a2uDux8Lt48CGuQ40s6vMbJeZ7ert7a1MdCIiq1Bkw0c9WBFnzlVx3P0ad+929+6u\nrgU7vUVEZIkqnQhOmNkmgPDnyQqXLyIiM1Q6EXwTeEu4/Rbg3ytcvohILPSOZPjug8cZz+bKXlY5\nh49eB/wEOM/Meszs7cDHgJeZ2aPAZeFzERGZ4daHT/DOf95Nz8BE2csq2w1l7n7FHC+9tFxliojU\nih892seGtnrOWd9S9rI015CISJUpFJwf7z/FpWevw8zKXp4SgYhIlfn5sWH6x7K88Jx1FSlPiUBE\npMr88NHg3qlLz1YiEBFZlW5/tI+nbWxlfWtDRcpTIhARqSIT2Ty7Dg3wggrVBkCJQESkqtx9qJ9s\nvsALKtQ/AEoEIiJV5fZHe0knE/zi9rUVK1OJQESkityx7xTP2dpBYzpZsTKVCEREqsTgeJaHjg/z\n/J2VaxYCJQIRkapx18F+3OGSHZVrFgIlAhGRqnHngVM01CW48Kz2iparRCAiUiXuPNDPc7euoT5V\nuf4BUCIQEakKg+NZHj4+zCUVHC00TYlARKQKTPcPPG+nEoGIyKr04319NNYleebmjoqXrUQgIlIF\n7th/iou3d5JOVf5jWYlARCRix4cm2XdytKLzCxVTIhARidgd+/oAeP7Zle8fACUCEZHI3bG/j87m\nNOdvbIukfCUCEZEIuTt37Ovj+TvXkkiUf1nK2USSCMzsvWb2gJk9aGZXRxGDiEg1OHRqnBPDmUiG\njU6reCIwswuAdwAXAxcCl5vZ2ZWOQ0SkGuw61A/ARds6I4shihrB+cBd7j7u7jngB8BrIohDRCRy\nuw8P0NaQ4uyulshiiCIRPAC80MzWmlkT8KvAWRHEISISuV2HB3ju1jWR9Q9ABInA3R8CPg58D7gJ\nuBfIzzzOzK4ys11mtqu3t7fCUYqIlN/AWJZ9J0fpjrBZCCLqLHb3f3T357r7i4ABYO8sx1zj7t3u\n3t3V1VX5IEVEymz34QEAureuiTSOVBSFmtl6dz9pZlsI+gcuiSIOEZEo7To8QF3SuPCsys8vVCyS\nRAB8zczWAlPA77n7YERxiIhEZvfhfp5xRjsNdZVdf2CmSBKBu78winJFRKpFJpdnT88Qv33J1qhD\n0Z3FIiJReODoMNlcge5t0fYPgBKBiEgkdh8ObiR77tZoRwyBEoGISCT2HBli85pGulrrow5FiUBE\nJAp7ega5MILVyGajRCAiUmGnRjP0DEzwzM3tUYcCKBGIiFTc/UeHACJZn3g2SgQiIhV2X88QZvAL\nqhGIiKxO9/UMsrOrhZb6qO7pfTIlAhGRCnJ39vQM8cwzq6M2AEoEIiIVdXx4kt6RTNV0FIMSgYhI\nRe05EnYURzzRXDElAhGRCrqvZ5BUwnj6praoQzlNiUBEpILu6xnivI2tkc84WkyJQESkQtyd+3oG\nq+b+gWlKBCIiFfJY/zjDk7mq6igGJQIRkYqZvqP4F6po6CgoEYiIVMz9R4dIJxOcu6E16lCeRIlA\nRKRCHjgadBSnU9X10Vtd0YiI1Ch354Gjw1xQZc1CoEQgIlIRR/onGJqYqrr+AVAiEBGpiPuODgLV\n11EMESUCM/sDM3vQzB4ws+vMrCGKOEREKuWBo8PUJY1zN7ZEHcpTVDwRmNmZwHuAbne/AEgCb6x0\nHCIilfTI8WF2drVQn6qeO4qnRdU0lAIazSwFNAGPRxSHiEhF7D0xynkbq2vY6LSKJwJ3Pwr8FfAY\ncAwYcvfvVToOEZFKGZmc4ujgRNXdPzAtiqahNcCrgO3AGUCzmb1pluOuMrNdZrart7e30mGKiKyY\nvSdGATgvronAzC41s+Zw+01m9jdmtnUZZV4GHHT3XnefAr4OPH/mQe5+jbt3u3t3V1fXMooTEYnW\n3hMjALFuGvo0MG5mFwJ/COwHvriMMh8DLjGzJjMz4KXAQ8s4n4hIVXvk+AhN6SRndjRGHcqsSkkE\nOXd3guacT7n7/wWWnNbc/S7gq8DPgPvDGK5Z6vlERKrd3hMjnLOhlUTCog5lVqkSjhkxsw8CbwZe\naGYJoG45hbr7nwJ/upxziIjExd4TI7zkaeujDmNOpdQI3gBkgLe5+3FgM/C/yxqViEiN6BvN0Dea\nrdoRQ1BCIgg//L8G1Ie7+oAbyhmUiEitqPaOYiht1NA7CNr0PxPuOhP4RjmDEhGpFXuPh4kgzjUC\n4PeAS4FhAHd/FKjexi4RkSryyIlROprq6GqtX/jgiJSSCDLunp1+Ek4L4eULSUSkduw9McK5G1oJ\nRstXp1ISwQ/M7L8TzA30MuB64FvlDUtEJP7cnb3HR6q6WQhKSwQfAHoJxvy/E/g28OFyBiUiUguO\nDU0ykslxbhV3FEMJ9xG4ewH4LPBZM+sENoc3mImIyDweOVH9HcVQ2qih28ysLUwCuwkSwt+WPzQR\nkXibHjF07obqW4ymWClNQ+3uPgy8Bviiu/8iwfxAIiIyj0dOjLChrZ6OpnTUocyrlESQMrNNwOuB\nG8scj4hIzZgeMVTtSkkEfw58F9jn7j81sx3Ao+UNS0Qk3vIF59ETo1XfPwCldRZfTzBkdPr5AeC1\n5QxKRCTuHusfJ5MrVP2IISits/gTYWdxnZndYma9s60oJiIiT3gkBlNLTCulaejlYWfx5cAh4Gzg\nj8oZlIhI3E1PNndOlY8YghI7i8OfvwZc7+5DZYxHRKQmPHJihC2dTTSlS1n2JVqlRHijmT0MTAC/\na2ZdwGR5wxIRibe9x+MxYghKW4/gAwSLy3eHi82PESxbKSIis8jk8hzsG+NpMegohhJqBGZWB7wJ\neFE4e94PgH8oc1wiIrF1sG+MXMFjMWIISmsa+jTBGsX/L3z+5nDf75QrKBGROIvTiCEoLRFc5O4X\nFj2/1cz2lCsgEZG4e+T4CKmEsX1dc9ShlKSUUUN5M9s5/SS8szi/1ALN7Dwzu7foMWxmVy/1fCIi\n1WbviRF2dDWTTpXyERu9UmoEfwR838wOAAZsBd661ALd/RHgWQBmlgSOAjcs9XwiItXmkRMjXLi5\nI+owSlbKFBO3mNk5wHnhrtMf5CvgpcB+dz+8QucTEYnUWCbHkf4JXv/cs6IOpWQl3eng7hngvunn\nZnY9sGUFyn8jcN1sL5jZVcBVAFu2rERRIiLl9+jJUYDYjBiC0voIZrPsVZjNLA28kqIJ7Yq5+zXu\n3u3u3V1dXcstTkSkIvbGbMQQLD0RrMRSla8AfubuJ1bgXCIiVeGREyM01CU4q7Mp6lBKNmfTkJl9\ni9k/8A1YuwJlX8EczUIiInG198QI56xvJZlYdsNJxczXR/BXS3xtQWbWDLwMeOdyziMiUm0eOT7C\nC8+JV3P2nInA3X9QrkLdfYyVqVWIiFSNwfEsJ0cyVb9Y/UzxuNtBRCQG9oUjhuKwBkExJQIRkRUy\nnQjO7orPiCFQIhARWTH7e0dJpxKcuaYx6lAWZSmjhgBw91eWJSIRkZjad3KUHeuaYzViCEobNfQa\nYCPwpfD5FYDG/ouIzLCvdzRWcwxNW3DUkJn9tbt3F730LTPbVfbIRERiZHIqT8/ABK99zuaoQ1m0\nUvoImsOppwEws+1APCbZFhGpkP29o7jD2evjNWIISpt07g+A22ZMQ60bwUREiuzvHQNgZ1cNJgJ3\nvymchvpp4a6Hw9lIRUQktO/kKAkjNquSFVuwacjMmggWp/l9d98DbDGzy8semYhIjOw/OcpZnU00\n1CWjDmXRSukj+CcgCzwvfH4U+GjZIhIRiaEDfWPsiGFtAEpLBDvd/RPAFIC7j7MC6xGIiNSKQsE5\n2DfKjhj2D0BpiSBrZo2EN5eFC9mrj0BEJHR8eJLJqUIs+wegtFFDfwrcBJxlZl8GLgWuLGdQIiJx\ncrAvGDG0o6tGE4G732xmPwMuIWgSeq+795U9MhGRmDjQG0w2t2NdPJuGSlq8HmgABsLjn25muPsP\nyxeWiEh8HOgboymdZENbfdShLMmCicDMPg68AXgQKIS7HVAiEBEhaBravq4Zs3iOoymlRvBq4Dzd\nRCYiMrsDvWM8c3N71GEsWSmjhg4AdeUOREQkjjK5PD0D47G9hwDmX4/g/xA0AY0D95rZLRQNG3X3\n95Q/PBGR6nakf5yCE9t7CGD+pqHpqaZ3A9+c8dqcC9aUwsw6gM8BF4Tnepu7/2Q55xQRicL0ZHNx\nvYcA5l+P4FoAM3uvu/998Wtm9t5llvv3wE3u/jozSwNNyzyfiEgkpu8h2B7TewigtD6Ct8yy78ql\nFmhm7cCLgH8EcPesuw8u9XwiIlE62DvGupZ62hri25U6Xx/BFcBvAtvNrLhpqA3oX0aZ24Fe4J/M\n7EKCpqf3uvvYMs4pIhKJA32jse4ohvn7CH4MHAPWAX9dtH8EuG+ZZT4HeLe732Vmfw98APiT4oPM\n7CrgKoAtW7YsozgRkfI52DfGZedviDqMZZmzacjdD7v7be7+POBhoDV89Lh7bhll9oTnuCt8/lWC\nxDCz/Gvcvdvdu7u6upZRnIhIeQxNTNE3mo11RzGUtjDNbwB3A78BvB64y8xet9QC3f04cMTMzgt3\nvRT4+VLPJyISlScmm4vv0FEo7c7iDwMXuftJADPrAv6T4Jv8Ur0b+HI4YugA8NZlnEtEJBIH+4LJ\n5uJeIyglESSmk0DoFKWNNpqTu98LdC/nHCIiUTvYO0YyYWzpjPcI+FISwU1m9l3guvD5G4Bvly8k\nEZF42N83xllrGkmnlvXdOHKlrEfwR2b2GuAF4a5r3P2G8oYlIlL9DvaOxb5ZCEpfj+AOgjWLnaDj\nWERkVXN3DvaNccmOtVGHsmyljBp6PcGH/+tYgVFDIiK14MRwhompfKynlphWSo3gQ6z8qCERkVg7\nPXS0BpqGSunhWPFRQyIicTedCLbVQCJY6qih75QvJBGR6newb5T6VIJNbQ1Rh7JspY4aei1wabhL\no4ZEZNU72DfOtrXNJBLxXKe4WEmjhtz9a2Z28/TxZtbp7suZgVREJNYO9o1yzvrWqMNYEaWMGnqn\nmR0nmHF0F8G00bvmf5eISO3K5Qs81j9eE/0DUFqN4P3ABe7eV+5gRETi4PHBSabyXhMjhqC00T/7\nCRawFxERgsVooDZGDEFpNYIPAj82s7uAzPROd39P2aISEalih/riv2B9sVISwWeAW4H7gUJ5wxER\nqX4H+8ZoqU+xriUddSgropREUOfu7yt7JCIiMXGgL5hsziz+Q0ehtD6C75jZVWa2ycw6px9lj0xE\npEodOjVWM/0DUFqN4Irw5weL9jmwY+XDERGpbplcnqMDE/z6szdHHcqKKeXO4u2VCEREJA6O9I9T\ncNi+Lt6rkhWbs2nIzC4ys41Fz3/bzP7dzD6ppiERWa0O9E6PGIr3gvXF5usj+AyQBTCzFwEfA74I\nDAHXlD80EZHq81h/cFvV1pivU1xsvqahZNF8Qm8gmGzua8DXzOze8ocmIlJ9egYmaKlP0dFUF3Uo\nK2beRGBmKXfPAS8FrirxfQsys0PACJAHcu7evZzziYhUypH+cTavaayZoaMw/wf6dcAPzKwPmAB+\nBGBmZxM0Dy3XL2v+IhGJm56BCc6qoWYhmCcRuPtfmNktwCbge+7u4UsJ4N2VCE5EpJq4O0cGxnn+\n2fFfsL7YvE087n7nLPv2rkC5DnzPzBz4jLur81lEqt7A+BTj2Tyb16ySGkGZvcDdj5rZeuBmM3vY\n3X9YfICZXUXYL7Fly5YoYhQReZKegWDE0OY1jRFHsrIiWYTe3Y+GP08CNwAXz3LMNe7e7e7dXV1d\nlQ5RROQpjvRPAHBWjdUIKp4IzKzZzFqnt4GXAw9UOg4RkcWarhGcWWM1giiahjYAN4RDr1LAV9z9\npgjiEBFZlJ6BCdoaUrQ31s49BBBBInD3A8CFlS5XRGS5jgyM19zQUYioj0BEJI56BiZqrqMYlAhE\nREri7vQMjNdcRzEoEYiIlKRvNMvkVEE1AhGR1eqJewhUIxARWZWODIT3EKizWERkdarVu4pBiUBE\npCRH+ifobE7TXB/VzDzlo0QgIlKCnoHxmqwNgBKBiEhJjtboPQSgRCAisqBCwYMFaWpwxBAoEYiI\nLKh3NEM2X5v3EIASgYjIgmr5HgJQIhARWdDpdQg6VSMQEVmVTq9D0KEagYjIqnSkf4J1LfU0ppNR\nh1IWSgQiIgvoGazdewhAiUBEZEG1ug7BNCUCEZF55AvO44MTNTnZ3DQlAhGReZwYnmQq76oRiIis\nVkf6gxFDtXpXMSgRiIjMqydch0A1gjIws6SZ3WNmN0YVg4jIQqYTwRkdSgTl8F7goQjLFxFZ0JGB\ncTa01dNQV5v3EEBEicDMNgO/BnwuivJFREoVrENQu/0DEF2N4O+A/wYU5jrAzK4ys11mtqu3t7dy\nkYmIFKn1ewgggkRgZpcDJ91993zHufs17t7t7t1dXV0Vik5E5Am5fIFjQ5M1PWIIoqkRXAq80swO\nAf8CvMTMvhRBHCIi8zo2NEm+UNv3EEAEicDdP+jum919G/BG4FZ3f1Ol4xARWciRcNbRWr6rGHQf\ngYjInFbDPQQAqSgLd/fbgNuijEFEZC49AxOYwab22k4EqhGIiMyhp3+cTW0NpFO1/VFZ27+diMgy\nBENHa7t/AJQIRETmdGRgnM01uk5xMSUCEZFZZHMFjg9PqkYgIrJa7Trcjzucv7E16lDKLtJRQ9XA\n3RnP5pmYyjOVLzCVc7L5AtlcIXieL5DNF5jKO1O5J55ncwVyBSedTFBfl8AwzCBhkEwkqEsa6VSC\ndDKB2fRrhgHJhNFQl6ChLkljXZLGdJKGVJJEwqK+HCIS+taeYzSlk7z4vPVRh1J2NZ0IPvLNB7nr\nYD9tDSkK7oxM5hiZzJHJ5ckXnHzBmcwFH+rVoD6VoDEdJoe6ZJAo0jO3E2HySNHeWEdHUx2tDSma\n0yma0kma65/8symdIqkEI7IoE9k8377/GJedv4HGdO3OOjqtphNBe2MdZ3Y0MDQxRSqRYEtnEy0N\nKRrqkiTNSCaM+lSCjqY0zfVJ0skEdckEdakE6aQF28kE6VT4M5mgLmWnt1NJI5srkAkTiTunE0xx\nraLgjgM4FDx4PZMrMDGVZ3Iqz0RYI5mYyjOZzZ+uoUyG+8azOU6NZZ907Hg2x1TeS7oO9akEzfUp\nGuuStNSnaGsMkkh7Yzr8WUd7Y4r2pjo6GtO0nd4XPGp96JzITDfcc5ShiSnedMnWqEOpiJpOBH/w\nsnOjDqFs3J3JqQKDE1lGJ3OMZfOMZXKMZXJMTOUZywTJYiyTZ3wqx3gmz1g2eH1oYoqjg5M8dGyE\noYkpRjO5ectqSidPJ4XiJNHRWMea5jRrm9N0NqdZ21LPupZgu6U+hZlqIhI/faMZ/vY/93Lh5nYu\n2rYm6nAqoqYTQS0zs6CpKN0I7cs711S+wPDEFEOzPcaf2B4Mfx7pH+eBiSkGx6eYmMrPes50KsHa\n5jRrW9Ksba4/vd3ZXM+apqBJq62xjjVNada31rOmKa0+kogUCs49RwY5MTzJ6GSOkUyOfKFA32iW\nU6NZWuqDLwIb2xvZvKaRpnTydG25NWx2zeYKNKaTrG+N981XhYLz/uv3MDQxxRffdvGq+TKjRCDU\nJROsbalnbUv9ot87OZXn1FiW/tEsfWMZ+keznBrLcGo0y6mxLKdGM/SPZdl3cpRTYxkmp2bvj6lL\nWpAwWoLEsLG9kY1tDWxqb2Bj+xM/WxvqlvvrSmgsk+Nff3qEL915mAN9Y095vT5M5mPZPMOTU3hp\nLZF0Ngf/huvbGljfWs+GtnrWtzbQ1pjijPZGdq5vobMKE3++4PzPG3/ObY/08uevegbnb2qLOqSK\nUSKQZWmoS3JmRyNnlrie61gmF9QsxqcYnMgyMDbFyZFJTgxnODWa4dRYlhPDk9x/dIi+0exT3t9S\nn2JjewMb256cIDa1N7CxrZFN7Q10NNWtmm9yS3XvkUF+90u7OTY0ybO3dPA3r7+Qp5/RRkt9ipb6\nFKlkguZ08vR1zBec48OTHB2YIJMLRthlpgqMTOZIJoIRcuPZHMeHMqf/PXtHJtl7fITe0Qz5wpOz\nSF3SaEqnGM3kaKxLhjXHNFs6m3jGGe2cs6GFszqbaE6nqEsah06NM5UvYAS14Zb6FJ3NadY011Gf\nWn5nbr7gvOXzd3P7vj7edul23rxK+gamKRFIRTXXp2iuT5WUODK5PCeHMxwbmuT48CTHhyaC7aFJ\njg1NcvujfZwcmWTGZwzN6SSb1zSxeU0jZ3Q0cuaaoEljet/a5vSqThS7Dw/wls/fzZrmOr76rufR\nva1zwfckE7aohF+sUHBOjWUZmZzi0KkxjvQH/47j2Rwt9SkmpwqcGsvQO5LhroP9fOPexxd1/s7m\nNFvXNjGWydHeWMf6tgaSZoxmcqcHSrSEo+haG+o4c00jWzqb2NLZxJrwS8ON9z3O7fv6+PCvnc/b\nX7B91f19KBFI1apPJTmrs2neueBz+QK9o5nTCeLxwQmODk5wpD/4efehfkYmn9wZ3liXZOvaJnZ2\ntbB9XTPb1zWzo6uZHetaaG+q7aanT9+2n7+9eS9ndDRw3VWXVGRWzUTC6Gqtp6u1nh1dLQsef2o0\nw/7eMY4OjjORLTA5lQ9rB0mcYOTdWCZ3ukny8aEJDvaNsa6lmeGJKX7++DAFd1rqU2RzhWAQRTiY\nIjfjW0NLfTCC7ujgBOduaOGtl66+JABKBBJzqWSCTe2N836gDU9OcXRggp6BCY4OjHNkIPjg+Pmx\nYW568PiTmi06m9NsX9fMuRtaOH9TGxdu7uDcDa2xHkvu7uw6PMDXf9bDdXcf4RUXbOTPX3UBXa2L\n7xOqhCf6qxauqSzG9M2jRwcnOHxqnMf6xznSP87AeJbf3LCF1z5n86q958a81B6gCHV3d/uuXbui\nDkNq0FS+wGP94xzsHeNg3xgH+sbY3zvK3hMjDI5PnT6uvbGOTe0NbF7TyNa1zadrEtvWNbOpraHq\nOj6nPfj4EJ/70UFuuOcoqYTxpku28ieXP33VfuCtNma22927FzpONQJZ1eqSCXZ2tbBzRpOFu/P4\n0CT3PjbIoVNjp/slegbGuX1f35NGP9WnEqxvq6ejMU1HU93pO77XNKXpaErT1VpPa32KRMJoSCVo\nSqdoDO/NWNNURyq59OGWp0YzjGZy9I9lOTmS4eRI0NY+kc2xv3eMWx8+SSph/P4vn83vvHA7HU3p\nJZcltUuJQGQWZnN3jhYKzomRSQ72jXGob5yDfaP0jWYZHM8yOBE0Qw1OTDE4nn1KR/Zs2hrCzsz6\nFM3pJ6YTaQqbo/IFJ5kwkokEPQPjTGTzJMzoH8tyfHhyltihIRWMxHnPS87m7S/YUfN9H7I8SgQi\ni5RI2Ol+iefvnPu4QsEZnpzi5EiGsUwumNtqqsB4Nrj7e2hiilNhApnuzJwIpxHpH8vSMxDcrJdK\nGLmCM5UvsKGtga7OegoO521s5RlntNHRlKazuY71rcG4/c7m9LJqGbL6KBGIlEkiYXSEzUMi1azi\nXxvMrMHM7jazPWb2oJn9WaVjEBGRJ0RRI8gAL3H3UTOrA243s++4+50RxCIisupVPBF4MF51NHxa\nFz6qfwyriEiNiqRHycySZnYvcBK42d3viiIOERGJKBG4e97dnwVsBi42swtmHmNmV5nZLjPb1dvb\nW/kgRURWiUjHmLn7IPB94Fdmee0ad+929+6urq7KByciskpEMWqoy8w6wu1G4GXAw5WOQ0REAlGM\nGtoEXGtmSYJE9G/ufmMEcYiICDGZdM7MeoHDBIsyDhX9XAf0LeGU0+9fzOsL7Zv5+sxYi19fStxL\niXm+uGZ7Ptt2tV/raol5tv261uWJebb9pVzr2fbV+rXe6u4Lt627e2wewDUzfu5aznkW8/pC+2a+\nPkusxccuOu6lxDxfXAv9DnG51tUSs6519V/rOfatmms93yNuE5J8a8bP5Z5nMa8vtG/m6zNjjSLm\n2fbP93y27Wq/1tUS82z7da0XVslrPd//18WK47WeUyyahuZiZru8hLm2q00c41bMlRPHuOMYM8Qz\n7nLEHLcawUzXRB3AEsUxbsVcOXGMO44xQzzjXvGYY10jEBGR5Yt7jUBERJZJiUBEZJVTIhARWeVq\nNhGY2YvN7Edm9g9m9uKo4ymVmTWHk+1dHnUspTKz88Pr/FUz+92o4ymFmb3azD5rZv9qZi+POp5S\nmdkOM/tHM/tq1LHMJ/w7vja8xr8VdTylisv1LbYSf8tVmQjM7PNmdtLMHpix/1fM7BEz22dmH1jg\nNNPrHjQAPeWKtSi2lYgZ4I+BfytPlE+1EnG7+0Pu/i7g9cCl5Yw3jG0lYv6Gu78DeBfwhnLGWxTf\nSsR9wN3fXt5IZ7fI+F8DfDW8xq+seLBFFhN3lNd3RmyLiXn5f8srfYfaSjyAFwHPAR4o2pcE9gM7\ngDSwB3g68AvAjTMe64FE+L4NwJdjEvPLgDcCVwKXx+Vah+95JfAd4DfjEnP4vr8GnhOnax2+76uV\niHkZ8X8QeFZ4zFcqHetS445lzBcMAAAGz0lEQVTy+q5AzEv+W67Kxevd/Ydmtm3G7ouBfe5+AMDM\n/gV4lbv/JTBfM8oAUF+OOIutRMxhE1YzwX+kCTP7trsXqj3u8DzfBL5pZv8BfKV8Ea/YtTbgY8B3\n3P1n5Yx32gr/XVfcYuInqIVvBu4l+unuFxP3zysb3ewWE7OZPcQy/5arsmloDmcCR4qe94T7ZmVm\nrzGzzwD/DHyqzLHNZVExu/uH3P1qgg/Sz5Y7Ccxjsdf6xWb2yfB6f7vcwc1hUTED7wYuA15nZu8q\nZ2ALWOy1Xmtm/wA828w+WO7gSjBX/F8HXmtmn6aMUyMsw6xxV+H1LTbXtV7233JV1ghWgrt/neCP\nMXbc/QtRx7AY7n4bcFvEYSyKu38S+GTUcSyWu58iaAuuau4+Brw16jgWKy7Xt9hK/C3HqUZwFDir\n6PnmcF81i2PMEM+44xgzxDfuaXGNP45xly3mOCWCnwLnmNl2M0sTdKp+M+KYFhLHmCGecccxZohv\n3NPiGn8c4y5fzFH2jM/TY34dcAyYImgHe3u4/1eBvQQ95x+KOs64xxzXuOMYc5zjjnv8cYy70jFr\n0jkRkVUuTk1DIiJSBkoEIiKrnBKBiMgqp0QgIrLKKRGIiKxySgQiIqucEoGsKDMbrXB5nzOzp1e4\nzKvNrGkJ7/s7M3tRuH2bmXWvfHSLZ2YfMbP3L3DM75vZ2yoVk1SWEoFUNTObdz4sd/8dd1/RGSMt\nMN//jauBRSUCM1sLXOLuP1xWcNH5PMHkZlKDlAik7Mysy8y+ZmY/DR+XhvsvNrOfmNk9ZvZjMzsv\n3H+lmX3TzG4FbglnN73NghXQHjazL4fTSD/pm7WZjZrZX5jZHjO708w2hPt3hs/vN7OPzlZrMbNt\n4YIfXwQeAM4ys09bsFrcg2b2Z+Fx7wHOAL5vZt8P9708/D1+ZmbXm1nLLJfhtcBNc1yfK8LYHjCz\njxftf7uZ7TWzuy1Ygeops+ia2S+Z2b3h4x4zaw33/3F4zj1m9rFw3zvC678n/Pd4SjILr9VNZrbb\nghX+ngbg7uPAITO7eLbfQWIu6lup9aitBzA6y76vAC8It7cAD4XbbUAq3L4M+Fq4fSXBbfWd4fMX\nA0MEk2wlgJ8Une82oDvcduC/htufAD4cbt8IXBFuv2uOGLcBBYJv7dP7pstPhuU8M3x+CFgXbq8D\nfgg0h8//GPgfs5z/2unYiuMmSCqPAV0EswHfCrw63H8I6ATqgB8Bn5rlvN8CLg23W8JzvAL4MdA0\n4/dYW/S+jwLvDrc/Arw/3L4FOCfc/kXg1qL3fAj4w6j/xvRY+UfNTkMtVeUy4Onhl3iAtvBbcztw\nrZmdQ/AhXlf0npvdvb/o+d3u3gNgZvcSfHDfPqOcLMGHPsBughXfAJ5H8OEKQVL6qzniPOzudxY9\nf72ZXUXw4bqJYMGg+2a855Jw/x3h75cmSFQzbQJ6Z9l/EXCbu/eGv9uXCVanAvjB9DUws+uBc2d5\n/x3A34Tv+7q795jZZcA/efAtnqLreIGZfRToIEga3y0+Ufhv8nzg+qJ/q+JFnU4CT5slBok5JQKp\nhATBN+3J4p1hU8f33f3XLViN6bail8dmnCNTtJ1n9r/dKXf3BY6Zz+kyzWw78H7gIncfMLMvEKx/\nPZMRJK0rFjj3xBzvXxZ3/5gFq8L9KkEy+i/zHP4F4NXuvsfMriSoaRVLAIPu/qw53t9A8HtIjVEf\ngVTC9yjqaDSz6Q+adp6YT/3KMpZ/J0EbPQRT95aijSAxDIV9Da8oem0EaC0696VmdjaAmTWb2Wzf\n3B8Czp5l/93AL5nZOjNLAlcAPyCYcviXzGxN2GH+2lnei5ntdPf73f3j4XueBtwMvHW6D8DMOsPD\nW4FjZlYH/NbMc7n7MHDQzH4jfJ+Z2YVFh5xL0H8iNUaJQFZak5n1FD3eB7wH6Daz+8zs5zyxAtQn\ngL80s3sob+30auB9ZnYfwYfx0EJvcPc9wD3AwwTNSXcUvXwNcJOZfT9s0rkSuC48/0+YvfnkP3jq\nN3Dc/RjwAeD7BIuR73b3f3f3o8D/IkgUdxD0F8wW99VhJ/N9BFMWf8fdbyKYp35X2Iw2PTT0T4C7\nwvM9PMev/lvA281sD/AgwTq+0y4lSDJSYzQNtdS88JvxhLu7mb2RoOP4VQu9rwxx3A5c7u6DJR7f\n4u6jYY3gBuDz7n5DWYOcO5ZnA+9z9zdHUb6Ul/oIZDV4LvCpcMjpIBDVjVF/SDBqqqREAHwk7Pht\nIGhe+0a5AivBOoIahdQg1QhERFY59RGIiKxySgQiIqucEoGIyCqnRCAissopEYiIrHJKBCIiq9z/\nB0g86U/0XLfRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_smoothed_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "m0S0RzD9p-S-",
    "outputId": "3499ee30-2e8e-4738-ddc5-05092b634cb4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4QKNrBPTkRmD"
   },
   "source": [
    "### Finding a good learning rate & training with OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "luY9dNAg2mh-",
    "outputId": "88cf8046-2d37-4f4e-8f65-3b0dc76a0472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './clr'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects:  33% (1/3)   \u001b[K\r",
      "remote: Counting objects:  66% (2/3)   \u001b[K\r",
      "remote: Counting objects: 100% (3/3)   \u001b[K\r",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 211 (delta 0), reused 1 (delta 0), pack-reused 208\u001b[K\n",
      "Receiving objects: 100% (211/211), 3.19 MiB | 1.51 MiB/s, done.\n",
      "Resolving deltas: 100% (82/82), done.\n"
     ]
    }
   ],
   "source": [
    "# Import One-Cycle Learning rate policy (Keras) (https://github.com/prateekgulati/keras-one-cycle)\n",
    "\n",
    "!git clone https://github.com/prateekgulati/keras-one-cycle ./clr\n",
    "  \n",
    "import sys\n",
    "sys.path.append(\"/content/clr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v8jeLptjdhJe",
    "outputId": "0a857172-094e-43cb-dae2-353a9888176f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<__main__...., verbose=1, callbacks=[<clr.LRFi..., steps_per_epoch=390, epochs=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  1/390 [..............................] - ETA: 16:25 - loss: 3.5209 - acc: 0.1094 - LRFinder: val_loss: 3.5679 - lr = 0.00001042 \n",
      "  2/390 [..............................] - ETA: 11:14 - loss: 3.5569 - acc: 0.1094 - LRFinder: val_loss: 3.5506 - lr = 0.00001086 \n",
      "  3/390 [..............................] - ETA: 7:54 - loss: 3.5908 - acc: 0.1068  - LRFinder: val_loss: 3.5622 - lr = 0.00001132 \n",
      "  4/390 [..............................] - ETA: 6:10 - loss: 3.5689 - acc: 0.1230 - LRFinder: val_loss: 3.5429 - lr = 0.00001180 \n",
      "  5/390 [..............................] - ETA: 5:08 - loss: 3.5722 - acc: 0.1203 - LRFinder: val_loss: 3.5615 - lr = 0.00001230 \n",
      "  6/390 [..............................] - ETA: 4:26 - loss: 3.5828 - acc: 0.1185 - LRFinder: val_loss: 3.5807 - lr = 0.00001281 \n",
      "  7/390 [..............................] - ETA: 3:57 - loss: 3.5893 - acc: 0.1150 - LRFinder: val_loss: 3.5893 - lr = 0.00001335 \n",
      "  8/390 [..............................] - ETA: 3:34 - loss: 3.5908 - acc: 0.1211 - LRFinder: val_loss: 3.5815 - lr = 0.00001392 \n",
      "  9/390 [..............................] - ETA: 3:17 - loss: 3.5962 - acc: 0.1172 - LRFinder: val_loss: 3.5489 - lr = 0.00001451 \n",
      " 10/390 [..............................] - ETA: 3:03 - loss: 3.5938 - acc: 0.1195 - LRFinder: val_loss: 3.5853 - lr = 0.00001512 \n",
      " 11/390 [..............................] - ETA: 2:51 - loss: 3.5902 - acc: 0.1214 - LRFinder: val_loss: 3.5948 - lr = 0.00001576 \n",
      " 12/390 [..............................] - ETA: 2:41 - loss: 3.5879 - acc: 0.1230 - LRFinder: val_loss: 3.6184 - lr = 0.00001642 \n",
      " 13/390 [>.............................] - ETA: 2:33 - loss: 3.5884 - acc: 0.1214 - LRFinder: val_loss: 3.5778 - lr = 0.00001711 \n",
      " 14/390 [>.............................] - ETA: 2:26 - loss: 3.5901 - acc: 0.1222 - LRFinder: val_loss: 3.5849 - lr = 0.00001784 \n",
      " 15/390 [>.............................] - ETA: 2:20 - loss: 3.5858 - acc: 0.1240 - LRFinder: val_loss: 3.5507 - lr = 0.00001859 \n",
      " 16/390 [>.............................] - ETA: 2:15 - loss: 3.5925 - acc: 0.1235 - LRFinder: val_loss: 3.5553 - lr = 0.00001937 \n",
      " 17/390 [>.............................] - ETA: 2:10 - loss: 3.5909 - acc: 0.1250 - LRFinder: val_loss: 3.6286 - lr = 0.00002019 \n",
      " 18/390 [>.............................] - ETA: 2:06 - loss: 3.5907 - acc: 0.1224 - LRFinder: val_loss: 3.5788 - lr = 0.00002104 \n",
      " 19/390 [>.............................] - ETA: 2:02 - loss: 3.5958 - acc: 0.1217 - LRFinder: val_loss: 3.5904 - lr = 0.00002193 \n",
      " 20/390 [>.............................] - ETA: 1:59 - loss: 3.6014 - acc: 0.1191 - LRFinder: val_loss: 3.5696 - lr = 0.00002285 \n",
      " 21/390 [>.............................] - ETA: 1:56 - loss: 3.5970 - acc: 0.1205 - LRFinder: val_loss: 3.5321 - lr = 0.00002382 \n",
      " 22/390 [>.............................] - ETA: 1:53 - loss: 3.5962 - acc: 0.1204 - LRFinder: val_loss: 3.5668 - lr = 0.00002482 \n",
      " 23/390 [>.............................] - ETA: 1:50 - loss: 3.5969 - acc: 0.1206 - LRFinder: val_loss: 3.5981 - lr = 0.00002587 \n",
      " 24/390 [>.............................] - ETA: 1:48 - loss: 3.5988 - acc: 0.1201 - LRFinder: val_loss: 3.5520 - lr = 0.00002696 \n",
      " 25/390 [>.............................] - ETA: 1:46 - loss: 3.5992 - acc: 0.1222 - LRFinder: val_loss: 3.5933 - lr = 0.00002810 \n",
      " 26/390 [=>............................] - ETA: 1:43 - loss: 3.5986 - acc: 0.1223 - LRFinder: val_loss: 3.6047 - lr = 0.00002929 \n",
      " 27/390 [=>............................] - ETA: 1:42 - loss: 3.5986 - acc: 0.1215 - LRFinder: val_loss: 3.5679 - lr = 0.00003052 \n",
      " 28/390 [=>............................] - ETA: 1:40 - loss: 3.5993 - acc: 0.1208 - LRFinder: val_loss: 3.5366 - lr = 0.00003181 \n",
      " 29/390 [=>............................] - ETA: 1:38 - loss: 3.5987 - acc: 0.1204 - LRFinder: val_loss: 3.5225 - lr = 0.00003315 \n",
      " 30/390 [=>............................] - ETA: 1:36 - loss: 3.5984 - acc: 0.1203 - LRFinder: val_loss: 3.6005 - lr = 0.00003455 \n",
      " 31/390 [=>............................] - ETA: 1:35 - loss: 3.5967 - acc: 0.1200 - LRFinder: val_loss: 3.5666 - lr = 0.00003601 \n",
      " 32/390 [=>............................] - ETA: 1:34 - loss: 3.5968 - acc: 0.1211 - LRFinder: val_loss: 3.5488 - lr = 0.00003753 \n",
      " 33/390 [=>............................] - ETA: 1:32 - loss: 3.5985 - acc: 0.1217 - LRFinder: val_loss: 3.5502 - lr = 0.00003911 \n",
      " 34/390 [=>............................] - ETA: 1:31 - loss: 3.6001 - acc: 0.1213 - LRFinder: val_loss: 3.5968 - lr = 0.00004076 \n",
      " 35/390 [=>............................] - ETA: 1:30 - loss: 3.6014 - acc: 0.1212 - LRFinder: val_loss: 3.6012 - lr = 0.00004248 \n",
      " 36/390 [=>............................] - ETA: 1:29 - loss: 3.6018 - acc: 0.1207 - LRFinder: val_loss: 3.5716 - lr = 0.00004427 \n",
      " 37/390 [=>............................] - ETA: 1:28 - loss: 3.6024 - acc: 0.1212 - LRFinder: val_loss: 3.5995 - lr = 0.00004614 \n",
      " 38/390 [=>............................] - ETA: 1:27 - loss: 3.6019 - acc: 0.1215 - LRFinder: val_loss: 3.5495 - lr = 0.00004809 \n",
      " 39/390 [==>...........................] - ETA: 1:26 - loss: 3.6029 - acc: 0.1204 - LRFinder: val_loss: 3.6003 - lr = 0.00005012 \n",
      " 40/390 [==>...........................] - ETA: 1:25 - loss: 3.6007 - acc: 0.1203 - LRFinder: val_loss: 3.5414 - lr = 0.00005223 \n",
      " 41/390 [==>...........................] - ETA: 1:24 - loss: 3.6006 - acc: 0.1204 - LRFinder: val_loss: 3.5743 - lr = 0.00005444 \n",
      " 42/390 [==>...........................] - ETA: 1:23 - loss: 3.6005 - acc: 0.1215 - LRFinder: val_loss: 3.5803 - lr = 0.00005673 \n",
      " 43/390 [==>...........................] - ETA: 1:22 - loss: 3.5986 - acc: 0.1215 - LRFinder: val_loss: 3.5430 - lr = 0.00005913 \n",
      " 44/390 [==>...........................] - ETA: 1:21 - loss: 3.5970 - acc: 0.1238 - LRFinder: val_loss: 3.5757 - lr = 0.00006162 \n",
      " 45/390 [==>...........................] - ETA: 1:20 - loss: 3.5975 - acc: 0.1238 - LRFinder: val_loss: 3.5104 - lr = 0.00006422 \n",
      " 46/390 [==>...........................] - ETA: 1:20 - loss: 3.5964 - acc: 0.1235 - LRFinder: val_loss: 3.5094 - lr = 0.00006693 \n",
      " 47/390 [==>...........................] - ETA: 1:19 - loss: 3.5956 - acc: 0.1224 - LRFinder: val_loss: 3.5417 - lr = 0.00006976 \n",
      " 48/390 [==>...........................] - ETA: 1:18 - loss: 3.5962 - acc: 0.1218 - LRFinder: val_loss: 3.5348 - lr = 0.00007270 \n",
      " 49/390 [==>...........................] - ETA: 1:17 - loss: 3.5958 - acc: 0.1217 - LRFinder: val_loss: 3.5708 - lr = 0.00007577 \n",
      " 50/390 [==>...........................] - ETA: 1:17 - loss: 3.5955 - acc: 0.1217 - LRFinder: val_loss: 3.5275 - lr = 0.00007897 \n",
      " 51/390 [==>...........................] - ETA: 1:16 - loss: 3.5934 - acc: 0.1223 - LRFinder: val_loss: 3.5125 - lr = 0.00008230 \n",
      " 52/390 [===>..........................] - ETA: 1:16 - loss: 3.5919 - acc: 0.1227 - LRFinder: val_loss: 3.4988 - lr = 0.00008577 \n",
      " 53/390 [===>..........................] - ETA: 1:15 - loss: 3.5911 - acc: 0.1230 - LRFinder: val_loss: 3.5712 - lr = 0.00008939 \n",
      " 54/390 [===>..........................] - ETA: 1:14 - loss: 3.5908 - acc: 0.1228 - LRFinder: val_loss: 3.5192 - lr = 0.00009316 \n",
      " 55/390 [===>..........................] - ETA: 1:14 - loss: 3.5910 - acc: 0.1220 - LRFinder: val_loss: 3.5267 - lr = 0.00009709 \n",
      " 56/390 [===>..........................] - ETA: 1:13 - loss: 3.5907 - acc: 0.1215 - LRFinder: val_loss: 3.5439 - lr = 0.00010119 \n",
      " 57/390 [===>..........................] - ETA: 1:13 - loss: 3.5896 - acc: 0.1217 - LRFinder: val_loss: 3.5517 - lr = 0.00010546 \n",
      " 58/390 [===>..........................] - ETA: 1:12 - loss: 3.5894 - acc: 0.1213 - LRFinder: val_loss: 3.5067 - lr = 0.00010991 \n",
      " 59/390 [===>..........................] - ETA: 1:12 - loss: 3.5904 - acc: 0.1204 - LRFinder: val_loss: 3.4980 - lr = 0.00011454 \n",
      " 60/390 [===>..........................] - ETA: 1:11 - loss: 3.5897 - acc: 0.1203 - LRFinder: val_loss: 3.5221 - lr = 0.00011938 \n",
      " 61/390 [===>..........................] - ETA: 1:11 - loss: 3.5887 - acc: 0.1206 - LRFinder: val_loss: 3.5370 - lr = 0.00012441 \n",
      " 62/390 [===>..........................] - ETA: 1:10 - loss: 3.5868 - acc: 0.1209 - LRFinder: val_loss: 3.5329 - lr = 0.00012966 \n",
      " 63/390 [===>..........................] - ETA: 1:10 - loss: 3.5861 - acc: 0.1210 - LRFinder: val_loss: 3.5336 - lr = 0.00013514 \n",
      " 64/390 [===>..........................] - ETA: 1:09 - loss: 3.5856 - acc: 0.1215 - LRFinder: val_loss: 3.5121 - lr = 0.00014084 \n",
      " 65/390 [====>.........................] - ETA: 1:09 - loss: 3.5845 - acc: 0.1218 - LRFinder: val_loss: 3.5332 - lr = 0.00014678 \n",
      " 66/390 [====>.........................] - ETA: 1:08 - loss: 3.5834 - acc: 0.1210 - LRFinder: val_loss: 3.5221 - lr = 0.00015297 \n",
      " 67/390 [====>.........................] - ETA: 1:08 - loss: 3.5836 - acc: 0.1208 - LRFinder: val_loss: 3.5013 - lr = 0.00015943 \n",
      " 68/390 [====>.........................] - ETA: 1:07 - loss: 3.5820 - acc: 0.1215 - LRFinder: val_loss: 3.4886 - lr = 0.00016615 \n",
      " 69/390 [====>.........................] - ETA: 1:07 - loss: 3.5824 - acc: 0.1209 - LRFinder: val_loss: 3.4726 - lr = 0.00017317 \n",
      " 70/390 [====>.........................] - ETA: 1:07 - loss: 3.5821 - acc: 0.1207 - LRFinder: val_loss: 3.5040 - lr = 0.00018047 \n",
      " 71/390 [====>.........................] - ETA: 1:06 - loss: 3.5808 - acc: 0.1202 - LRFinder: val_loss: 3.5071 - lr = 0.00018809 \n",
      " 72/390 [====>.........................] - ETA: 1:06 - loss: 3.5802 - acc: 0.1204 - LRFinder: val_loss: 3.4890 - lr = 0.00019602 \n",
      " 73/390 [====>.........................] - ETA: 1:05 - loss: 3.5792 - acc: 0.1207 - LRFinder: val_loss: 3.5067 - lr = 0.00020429 \n",
      " 74/390 [====>.........................] - ETA: 1:05 - loss: 3.5785 - acc: 0.1205 - LRFinder: val_loss: 3.4903 - lr = 0.00021291 \n",
      " 75/390 [====>.........................] - ETA: 1:04 - loss: 3.5772 - acc: 0.1209 - LRFinder: val_loss: 3.5128 - lr = 0.00022190 \n",
      " 76/390 [====>.........................] - ETA: 1:04 - loss: 3.5768 - acc: 0.1208 - LRFinder: val_loss: 3.4781 - lr = 0.00023126 \n",
      " 77/390 [====>.........................] - ETA: 1:04 - loss: 3.5763 - acc: 0.1205 - LRFinder: val_loss: 3.4820 - lr = 0.00024102 \n",
      " 78/390 [=====>........................] - ETA: 1:03 - loss: 3.5749 - acc: 0.1208 - LRFinder: val_loss: 3.4761 - lr = 0.00025119 \n",
      " 79/390 [=====>........................] - ETA: 1:03 - loss: 3.5745 - acc: 0.1205 - LRFinder: val_loss: 3.4870 - lr = 0.00026179 \n",
      " 80/390 [=====>........................] - ETA: 1:03 - loss: 3.5731 - acc: 0.1210 - LRFinder: val_loss: 3.4716 - lr = 0.00027283 \n",
      " 81/390 [=====>........................] - ETA: 1:02 - loss: 3.5716 - acc: 0.1212 - LRFinder: val_loss: 3.4907 - lr = 0.00028435 \n",
      " 82/390 [=====>........................] - ETA: 1:02 - loss: 3.5714 - acc: 0.1213 - LRFinder: val_loss: 3.4802 - lr = 0.00029634 \n",
      " 83/390 [=====>........................] - ETA: 1:02 - loss: 3.5700 - acc: 0.1221 - LRFinder: val_loss: 3.4631 - lr = 0.00030885 \n",
      " 84/390 [=====>........................] - ETA: 1:01 - loss: 3.5684 - acc: 0.1230 - LRFinder: val_loss: 3.4588 - lr = 0.00032188 \n",
      " 85/390 [=====>........................] - ETA: 1:01 - loss: 3.5668 - acc: 0.1241 - LRFinder: val_loss: 3.4797 - lr = 0.00033546 \n",
      " 86/390 [=====>........................] - ETA: 1:01 - loss: 3.5670 - acc: 0.1239 - LRFinder: val_loss: 3.4871 - lr = 0.00034961 \n",
      " 87/390 [=====>........................] - ETA: 1:00 - loss: 3.5656 - acc: 0.1240 - LRFinder: val_loss: 3.4583 - lr = 0.00036437 \n",
      " 88/390 [=====>........................] - ETA: 1:00 - loss: 3.5651 - acc: 0.1236 - LRFinder: val_loss: 3.4542 - lr = 0.00037974 \n",
      " 89/390 [=====>........................] - ETA: 1:00 - loss: 3.5644 - acc: 0.1235 - LRFinder: val_loss: 3.4300 - lr = 0.00039576 \n",
      " 90/390 [=====>........................] - ETA: 59s - loss: 3.5636 - acc: 0.1234  - LRFinder: val_loss: 3.4300 - lr = 0.00041246 \n",
      " 91/390 [======>.......................] - ETA: 59s - loss: 3.5629 - acc: 0.1234 - LRFinder: val_loss: 3.4408 - lr = 0.00042987 \n",
      " 92/390 [======>.......................] - ETA: 59s - loss: 3.5615 - acc: 0.1238 - LRFinder: val_loss: 3.4243 - lr = 0.00044800 \n",
      " 93/390 [======>.......................] - ETA: 58s - loss: 3.5598 - acc: 0.1247 - LRFinder: val_loss: 3.4444 - lr = 0.00046691 \n",
      " 94/390 [======>.......................] - ETA: 58s - loss: 3.5586 - acc: 0.1242 - LRFinder: val_loss: 3.4343 - lr = 0.00048661 \n",
      " 95/390 [======>.......................] - ETA: 58s - loss: 3.5570 - acc: 0.1246 - LRFinder: val_loss: 3.4127 - lr = 0.00050714 \n",
      " 96/390 [======>.......................] - ETA: 57s - loss: 3.5553 - acc: 0.1250 - LRFinder: val_loss: 3.4186 - lr = 0.00052854 \n",
      " 97/390 [======>.......................] - ETA: 57s - loss: 3.5542 - acc: 0.1253 - LRFinder: val_loss: 3.4176 - lr = 0.00055084 \n",
      " 98/390 [======>.......................] - ETA: 57s - loss: 3.5524 - acc: 0.1258 - LRFinder: val_loss: 3.3933 - lr = 0.00057408 \n",
      " 99/390 [======>.......................] - ETA: 57s - loss: 3.5511 - acc: 0.1259 - LRFinder: val_loss: 3.3973 - lr = 0.00059831 \n",
      "100/390 [======>.......................] - ETA: 56s - loss: 3.5500 - acc: 0.1258 - LRFinder: val_loss: 3.4024 - lr = 0.00062355 \n",
      "101/390 [======>.......................] - ETA: 56s - loss: 3.5486 - acc: 0.1259 - LRFinder: val_loss: 3.4010 - lr = 0.00064986 \n",
      "102/390 [======>.......................] - ETA: 56s - loss: 3.5469 - acc: 0.1267 - LRFinder: val_loss: 3.4033 - lr = 0.00067728 \n",
      "103/390 [======>.......................] - ETA: 56s - loss: 3.5460 - acc: 0.1268 - LRFinder: val_loss: 3.3835 - lr = 0.00070586 \n",
      "104/390 [=======>......................] - ETA: 55s - loss: 3.5448 - acc: 0.1268 - LRFinder: val_loss: 3.3864 - lr = 0.00073564 \n",
      "105/390 [=======>......................] - ETA: 55s - loss: 3.5438 - acc: 0.1270 - LRFinder: val_loss: 3.3684 - lr = 0.00076668 \n",
      "106/390 [=======>......................] - ETA: 55s - loss: 3.5422 - acc: 0.1273 - LRFinder: val_loss: 3.3850 - lr = 0.00079903 \n",
      "107/390 [=======>......................] - ETA: 54s - loss: 3.5411 - acc: 0.1272 - LRFinder: val_loss: 3.3819 - lr = 0.00083275 \n",
      "108/390 [=======>......................] - ETA: 54s - loss: 3.5397 - acc: 0.1274 - LRFinder: val_loss: 3.3595 - lr = 0.00086788 \n",
      "109/390 [=======>......................] - ETA: 54s - loss: 3.5384 - acc: 0.1276 - LRFinder: val_loss: 3.3827 - lr = 0.00090450 \n",
      "110/390 [=======>......................] - ETA: 54s - loss: 3.5370 - acc: 0.1279 - LRFinder: val_loss: 3.3611 - lr = 0.00094267 \n",
      "111/390 [=======>......................] - ETA: 53s - loss: 3.5353 - acc: 0.1287 - LRFinder: val_loss: 3.3876 - lr = 0.00098244 \n",
      "112/390 [=======>......................] - ETA: 53s - loss: 3.5340 - acc: 0.1291 - LRFinder: val_loss: 3.3557 - lr = 0.00102390 \n",
      "113/390 [=======>......................] - ETA: 53s - loss: 3.5326 - acc: 0.1293 - LRFinder: val_loss: 3.3616 - lr = 0.00106710 \n",
      "114/390 [=======>......................] - ETA: 53s - loss: 3.5312 - acc: 0.1297 - LRFinder: val_loss: 3.3980 - lr = 0.00111213 \n",
      "115/390 [=======>......................] - ETA: 52s - loss: 3.5302 - acc: 0.1299 - LRFinder: val_loss: 3.3611 - lr = 0.00115905 \n",
      "116/390 [=======>......................] - ETA: 52s - loss: 3.5288 - acc: 0.1303 - LRFinder: val_loss: 3.3285 - lr = 0.00120796 \n",
      "117/390 [========>.....................] - ETA: 52s - loss: 3.5273 - acc: 0.1309 - LRFinder: val_loss: 3.3895 - lr = 0.00125893 \n",
      "118/390 [========>.....................] - ETA: 52s - loss: 3.5257 - acc: 0.1319 - LRFinder: val_loss: 3.3594 - lr = 0.00131204 \n",
      "119/390 [========>.....................] - ETA: 51s - loss: 3.5247 - acc: 0.1319 - LRFinder: val_loss: 3.3433 - lr = 0.00136741 \n",
      "120/390 [========>.....................] - ETA: 51s - loss: 3.5234 - acc: 0.1325 - LRFinder: val_loss: 3.3257 - lr = 0.00142510 \n",
      "121/390 [========>.....................] - ETA: 51s - loss: 3.5220 - acc: 0.1330 - LRFinder: val_loss: 3.3295 - lr = 0.00148523 \n",
      "122/390 [========>.....................] - ETA: 51s - loss: 3.5205 - acc: 0.1336 - LRFinder: val_loss: 3.3191 - lr = 0.00154790 \n",
      "123/390 [========>.....................] - ETA: 50s - loss: 3.5193 - acc: 0.1341 - LRFinder: val_loss: 3.3398 - lr = 0.00161321 \n",
      "124/390 [========>.....................] - ETA: 50s - loss: 3.5182 - acc: 0.1339 - LRFinder: val_loss: 3.3314 - lr = 0.00168128 \n",
      "125/390 [========>.....................] - ETA: 50s - loss: 3.5168 - acc: 0.1347 - LRFinder: val_loss: 3.3316 - lr = 0.00175222 \n",
      "126/390 [========>.....................] - ETA: 50s - loss: 3.5153 - acc: 0.1354 - LRFinder: val_loss: 3.3246 - lr = 0.00182616 \n",
      "127/390 [========>.....................] - ETA: 49s - loss: 3.5141 - acc: 0.1354 - LRFinder: val_loss: 3.3260 - lr = 0.00190321 \n",
      "128/390 [========>.....................] - ETA: 49s - loss: 3.5126 - acc: 0.1357 - LRFinder: val_loss: 3.3427 - lr = 0.00198352 \n",
      "129/390 [========>.....................] - ETA: 49s - loss: 3.5109 - acc: 0.1364 - LRFinder: val_loss: 3.3302 - lr = 0.00206721 \n",
      "130/390 [=========>....................] - ETA: 49s - loss: 3.5094 - acc: 0.1368 - LRFinder: val_loss: 3.3503 - lr = 0.00215443 \n",
      "131/390 [=========>....................] - ETA: 48s - loss: 3.5079 - acc: 0.1371 - LRFinder: val_loss: 3.2979 - lr = 0.00224534 \n",
      "132/390 [=========>....................] - ETA: 48s - loss: 3.5063 - acc: 0.1375 - LRFinder: val_loss: 3.3097 - lr = 0.00234008 \n",
      "133/390 [=========>....................] - ETA: 48s - loss: 3.5045 - acc: 0.1384 - LRFinder: val_loss: 3.3258 - lr = 0.00243882 \n",
      "134/390 [=========>....................] - ETA: 48s - loss: 3.5030 - acc: 0.1386 - LRFinder: val_loss: 3.3503 - lr = 0.00254172 \n",
      "135/390 [=========>....................] - ETA: 48s - loss: 3.5012 - acc: 0.1392 - LRFinder: val_loss: 3.3232 - lr = 0.00264897 \n",
      "136/390 [=========>....................] - ETA: 47s - loss: 3.4995 - acc: 0.1395 - LRFinder: val_loss: 3.3224 - lr = 0.00276074 \n",
      "137/390 [=========>....................] - ETA: 47s - loss: 3.4980 - acc: 0.1403 - LRFinder: val_loss: 3.3010 - lr = 0.00287723 \n",
      "138/390 [=========>....................] - ETA: 47s - loss: 3.4963 - acc: 0.1410 - LRFinder: val_loss: 3.3072 - lr = 0.00299863 \n",
      "139/390 [=========>....................] - ETA: 47s - loss: 3.4947 - acc: 0.1418 - LRFinder: val_loss: 3.2798 - lr = 0.00312516 \n",
      "140/390 [=========>....................] - ETA: 46s - loss: 3.4932 - acc: 0.1424 - LRFinder: val_loss: 3.3424 - lr = 0.00325702 \n",
      "141/390 [=========>....................] - ETA: 46s - loss: 3.4918 - acc: 0.1428 - LRFinder: val_loss: 3.2489 - lr = 0.00339445 \n",
      "142/390 [=========>....................] - ETA: 46s - loss: 3.4899 - acc: 0.1434 - LRFinder: val_loss: 3.2609 - lr = 0.00353767 \n",
      "143/390 [==========>...................] - ETA: 46s - loss: 3.4882 - acc: 0.1441 - LRFinder: val_loss: 3.2824 - lr = 0.00368694 \n",
      "144/390 [==========>...................] - ETA: 46s - loss: 3.4869 - acc: 0.1445 - LRFinder: val_loss: 3.2551 - lr = 0.00384251 \n",
      "145/390 [==========>...................] - ETA: 45s - loss: 3.4850 - acc: 0.1453 - LRFinder: val_loss: 3.3577 - lr = 0.00400465 \n",
      "146/390 [==========>...................] - ETA: 45s - loss: 3.4831 - acc: 0.1460 - LRFinder: val_loss: 3.3061 - lr = 0.00417362 \n",
      "147/390 [==========>...................] - ETA: 45s - loss: 3.4813 - acc: 0.1468 - LRFinder: val_loss: 3.3577 - lr = 0.00434972 \n",
      "148/390 [==========>...................] - ETA: 45s - loss: 3.4795 - acc: 0.1474 - LRFinder: val_loss: 3.2603 - lr = 0.00453326 \n",
      "149/390 [==========>...................] - ETA: 44s - loss: 3.4777 - acc: 0.1481 - LRFinder: val_loss: 3.3131 - lr = 0.00472453 \n",
      "150/390 [==========>...................] - ETA: 44s - loss: 3.4763 - acc: 0.1487 - LRFinder: val_loss: 3.3054 - lr = 0.00492388 \n",
      "151/390 [==========>...................] - ETA: 44s - loss: 3.4752 - acc: 0.1489 - LRFinder: val_loss: 3.3085 - lr = 0.00513164 \n",
      "152/390 [==========>...................] - ETA: 44s - loss: 3.4741 - acc: 0.1491 - LRFinder: val_loss: 3.3674 - lr = 0.00534817 \n",
      "153/390 [==========>...................] - ETA: 44s - loss: 3.4719 - acc: 0.1502 - LRFinder: val_loss: 3.2924 - lr = 0.00557383 \n",
      "154/390 [==========>...................] - ETA: 43s - loss: 3.4702 - acc: 0.1505 - LRFinder: val_loss: 3.2560 - lr = 0.00580902 \n",
      "155/390 [==========>...................] - ETA: 43s - loss: 3.4687 - acc: 0.1509 - LRFinder: val_loss: 3.2633 - lr = 0.00605412 \n",
      "156/390 [===========>..................] - ETA: 43s - loss: 3.4671 - acc: 0.1514 - LRFinder: val_loss: 3.2796 - lr = 0.00630957 \n",
      "157/390 [===========>..................] - ETA: 43s - loss: 3.4656 - acc: 0.1517 - LRFinder: val_loss: 3.2826 - lr = 0.00657580 \n",
      "158/390 [===========>..................] - ETA: 42s - loss: 3.4639 - acc: 0.1521 - LRFinder: val_loss: 3.3118 - lr = 0.00685326 \n",
      "159/390 [===========>..................] - ETA: 42s - loss: 3.4627 - acc: 0.1524 - LRFinder: val_loss: 3.2836 - lr = 0.00714243 \n",
      "160/390 [===========>..................] - ETA: 42s - loss: 3.4607 - acc: 0.1530 - LRFinder: val_loss: 3.2678 - lr = 0.00744380 \n",
      "161/390 [===========>..................] - ETA: 42s - loss: 3.4589 - acc: 0.1536 - LRFinder: val_loss: 3.3114 - lr = 0.00775789 \n",
      "162/390 [===========>..................] - ETA: 42s - loss: 3.4577 - acc: 0.1538 - LRFinder: val_loss: 3.2235 - lr = 0.00808523 \n",
      "163/390 [===========>..................] - ETA: 41s - loss: 3.4564 - acc: 0.1545 - LRFinder: val_loss: 3.1971 - lr = 0.00842638 \n",
      "164/390 [===========>..................] - ETA: 41s - loss: 3.4547 - acc: 0.1552 - LRFinder: val_loss: 3.1786 - lr = 0.00878193 \n",
      "165/390 [===========>..................] - ETA: 41s - loss: 3.4532 - acc: 0.1557 - LRFinder: val_loss: 3.2264 - lr = 0.00915247 \n",
      "166/390 [===========>..................] - ETA: 41s - loss: 3.4517 - acc: 0.1557 - LRFinder: val_loss: 3.2597 - lr = 0.00953866 \n",
      "167/390 [===========>..................] - ETA: 41s - loss: 3.4504 - acc: 0.1559 - LRFinder: val_loss: 3.2216 - lr = 0.00994113 \n",
      "168/390 [===========>..................] - ETA: 40s - loss: 3.4485 - acc: 0.1565 - LRFinder: val_loss: 3.2638 - lr = 0.01036059 \n",
      "169/390 [============>.................] - ETA: 40s - loss: 3.4470 - acc: 0.1568 - LRFinder: val_loss: 3.3232 - lr = 0.01079775 \n",
      "170/390 [============>.................] - ETA: 40s - loss: 3.4455 - acc: 0.1576 - LRFinder: val_loss: 3.4228 - lr = 0.01125336 \n",
      "171/390 [============>.................] - ETA: 40s - loss: 3.4434 - acc: 0.1582 - LRFinder: val_loss: 3.4649 - lr = 0.01172818 \n",
      "172/390 [============>.................] - ETA: 40s - loss: 3.4416 - acc: 0.1586 - LRFinder: val_loss: 3.5358 - lr = 0.01222305 \n",
      "173/390 [============>.................] - ETA: 39s - loss: 3.4401 - acc: 0.1591 - LRFinder: val_loss: 3.4259 - lr = 0.01273879 \n",
      "174/390 [============>.................] - ETA: 39s - loss: 3.4389 - acc: 0.1594 - LRFinder: val_loss: 3.4023 - lr = 0.01327629 \n",
      "175/390 [============>.................] - ETA: 39s - loss: 3.4370 - acc: 0.1603 - LRFinder: val_loss: 3.3608 - lr = 0.01383648 \n",
      "176/390 [============>.................] - ETA: 39s - loss: 3.4351 - acc: 0.1612 - LRFinder: val_loss: 3.2585 - lr = 0.01442030 \n",
      "177/390 [============>.................] - ETA: 39s - loss: 3.4343 - acc: 0.1615 - LRFinder: val_loss: 3.1886 - lr = 0.01502876 \n",
      "178/390 [============>.................] - ETA: 38s - loss: 3.4326 - acc: 0.1617 - LRFinder: val_loss: 3.2826 - lr = 0.01566288 \n",
      "179/390 [============>.................] - ETA: 38s - loss: 3.4315 - acc: 0.1621 - LRFinder: val_loss: 3.4136 - lr = 0.01632377 \n",
      "180/390 [============>.................] - ETA: 38s - loss: 3.4296 - acc: 0.1627 - LRFinder: val_loss: 3.2422 - lr = 0.01701254 \n",
      "181/390 [============>.................] - ETA: 38s - loss: 3.4275 - acc: 0.1635 - LRFinder: val_loss: 3.2528 - lr = 0.01773037 \n",
      "182/390 [=============>................] - ETA: 38s - loss: 3.4260 - acc: 0.1642 - LRFinder: val_loss: 3.1796 - lr = 0.01847850 \n",
      "183/390 [=============>................] - ETA: 37s - loss: 3.4243 - acc: 0.1650 - LRFinder: val_loss: 3.2043 - lr = 0.01925818 \n",
      "184/390 [=============>................] - ETA: 37s - loss: 3.4226 - acc: 0.1658 - LRFinder: val_loss: 3.2777 - lr = 0.02007077 \n",
      "185/390 [=============>................] - ETA: 37s - loss: 3.4208 - acc: 0.1668 - LRFinder: val_loss: 3.2323 - lr = 0.02091764 \n",
      "186/390 [=============>................] - ETA: 37s - loss: 3.4187 - acc: 0.1674 - LRFinder: val_loss: 3.2085 - lr = 0.02180025 \n",
      "187/390 [=============>................] - ETA: 37s - loss: 3.4168 - acc: 0.1678 - LRFinder: val_loss: 3.3706 - lr = 0.02272010 \n",
      "188/390 [=============>................] - ETA: 36s - loss: 3.4154 - acc: 0.1682 - LRFinder: val_loss: 3.3105 - lr = 0.02367876 \n",
      "189/390 [=============>................] - ETA: 36s - loss: 3.4143 - acc: 0.1685 - LRFinder: val_loss: 3.3334 - lr = 0.02467787 \n",
      "190/390 [=============>................] - ETA: 36s - loss: 3.4131 - acc: 0.1691 - LRFinder: val_loss: 3.2518 - lr = 0.02571914 \n",
      "191/390 [=============>................] - ETA: 36s - loss: 3.4112 - acc: 0.1696 - LRFinder: val_loss: 3.3828 - lr = 0.02680434 \n",
      "192/390 [=============>................] - ETA: 36s - loss: 3.4101 - acc: 0.1700 - LRFinder: val_loss: 3.3883 - lr = 0.02793533 \n",
      "193/390 [=============>................] - ETA: 35s - loss: 3.4082 - acc: 0.1709 - LRFinder: val_loss: 3.3685 - lr = 0.02911405 \n",
      "194/390 [=============>................] - ETA: 35s - loss: 3.4067 - acc: 0.1712 - LRFinder: val_loss: 3.4276 - lr = 0.03034249 \n",
      "195/390 [==============>...............] - ETA: 35s - loss: 3.4052 - acc: 0.1719 - LRFinder: val_loss: 3.2716 - lr = 0.03162278 \n",
      "196/390 [==============>...............] - ETA: 35s - loss: 3.4034 - acc: 0.1724 - LRFinder: val_loss: 3.1871 - lr = 0.03295708 \n",
      "197/390 [==============>...............] - ETA: 35s - loss: 3.4026 - acc: 0.1729 - LRFinder: val_loss: 3.2525 - lr = 0.03434768 \n",
      "198/390 [==============>...............] - ETA: 34s - loss: 3.4008 - acc: 0.1734 - LRFinder: val_loss: 3.1034 - lr = 0.03579696 \n",
      "199/390 [==============>...............] - ETA: 34s - loss: 3.3991 - acc: 0.1743 - LRFinder: val_loss: 3.1674 - lr = 0.03730739 \n",
      "200/390 [==============>...............] - ETA: 34s - loss: 3.3971 - acc: 0.1751 - LRFinder: val_loss: 3.2590 - lr = 0.03888155 \n",
      "201/390 [==============>...............] - ETA: 34s - loss: 3.3954 - acc: 0.1758 - LRFinder: val_loss: 3.1580 - lr = 0.04052213 \n",
      "202/390 [==============>...............] - ETA: 34s - loss: 3.3931 - acc: 0.1765 - LRFinder: val_loss: 3.3350 - lr = 0.04223194 \n",
      "203/390 [==============>...............] - ETA: 33s - loss: 3.3922 - acc: 0.1771 - LRFinder: val_loss: 3.3834 - lr = 0.04401389 \n",
      "204/390 [==============>...............] - ETA: 33s - loss: 3.3909 - acc: 0.1774 - LRFinder: val_loss: 3.3569 - lr = 0.04587102 \n",
      "205/390 [==============>...............] - ETA: 33s - loss: 3.3895 - acc: 0.1777 - LRFinder: val_loss: 3.7112 - lr = 0.04780652 \n",
      "206/390 [==============>...............] - ETA: 33s - loss: 3.3877 - acc: 0.1781 - LRFinder: val_loss: 4.2130 - lr = 0.04982369 \n",
      "207/390 [==============>...............] - ETA: 33s - loss: 3.3866 - acc: 0.1782 - LRFinder: val_loss: 4.1318 - lr = 0.05192596 \n",
      "208/390 [===============>..............] - ETA: 32s - loss: 3.3846 - acc: 0.1789 - LRFinder: val_loss: 3.8659 - lr = 0.05411695 \n",
      "209/390 [===============>..............] - ETA: 32s - loss: 3.3824 - acc: 0.1799 - LRFinder: val_loss: 4.6979 - lr = 0.05640038 \n",
      "210/390 [===============>..............] - ETA: 32s - loss: 3.3810 - acc: 0.1801 - LRFinder: val_loss: 5.1249 - lr = 0.05878016 \n",
      "211/390 [===============>..............] - ETA: 32s - loss: 3.3802 - acc: 0.1804 - LRFinder: val_loss: 5.7995 - lr = 0.06126035 \n",
      "212/390 [===============>..............] - ETA: 32s - loss: 3.3788 - acc: 0.1811 - LRFinder: val_loss: 6.2796 - lr = 0.06384519 \n",
      "213/390 [===============>..............] - ETA: 31s - loss: 3.3773 - acc: 0.1817 - LRFinder: val_loss: 4.3493 - lr = 0.06653909 \n",
      "214/390 [===============>..............] - ETA: 31s - loss: 3.3760 - acc: 0.1822 - LRFinder: val_loss: 5.7255 - lr = 0.06934667 \n",
      "215/390 [===============>..............] - ETA: 31s - loss: 3.3749 - acc: 0.1824 - LRFinder: val_loss: 5.1071 - lr = 0.07227270 \n",
      "216/390 [===============>..............] - ETA: 31s - loss: 3.3741 - acc: 0.1825 - LRFinder: val_loss: 4.0325 - lr = 0.07532220 \n",
      "217/390 [===============>..............] - ETA: 31s - loss: 3.3729 - acc: 0.1832 - LRFinder: val_loss: 5.6898 - lr = 0.07850038 \n",
      "218/390 [===============>..............] - ETA: 31s - loss: 3.3721 - acc: 0.1835 - LRFinder: val_loss: 5.3791 - lr = 0.08181265 \n",
      "219/390 [===============>..............] - ETA: 30s - loss: 3.3711 - acc: 0.1841 - LRFinder: val_loss: 5.0174 - lr = 0.08526468 \n",
      "220/390 [===============>..............] - ETA: 30s - loss: 3.3700 - acc: 0.1843 - LRFinder: val_loss: 5.4978 - lr = 0.08886237 \n",
      "221/390 [================>.............] - ETA: 30s - loss: 3.3691 - acc: 0.1847 - LRFinder: val_loss: 5.6990 - lr = 0.09261187 \n",
      "222/390 [================>.............] - ETA: 30s - loss: 3.3677 - acc: 0.1851 - LRFinder: val_loss: 4.6128 - lr = 0.09651956 \n",
      "223/390 [================>.............] - ETA: 30s - loss: 3.3664 - acc: 0.1854 - LRFinder: val_loss: 4.0246 - lr = 0.10059214 \n",
      "224/390 [================>.............] - ETA: 29s - loss: 3.3660 - acc: 0.1857 - LRFinder: val_loss: 3.8928 - lr = 0.10483656 \n",
      "225/390 [================>.............] - ETA: 29s - loss: 3.3646 - acc: 0.1860 - LRFinder: val_loss: 4.3492 - lr = 0.10926008 \n",
      "226/390 [================>.............] - ETA: 29s - loss: 3.3642 - acc: 0.1862 - LRFinder: val_loss: 9.2307 - lr = 0.11387024 \n",
      "227/390 [================>.............] - ETA: 29s - loss: 3.3626 - acc: 0.1867 - LRFinder: val_loss: 9.6359 - lr = 0.11867492 \n",
      "228/390 [================>.............] - ETA: 29s - loss: 3.3620 - acc: 0.1869 - LRFinder: val_loss: 8.0063 - lr = 0.12368233 \n",
      "229/390 [================>.............] - ETA: 28s - loss: 3.3614 - acc: 0.1875 - LRFinder: val_loss: 8.4983 - lr = 0.12890102 \n",
      "230/390 [================>.............] - ETA: 28s - loss: 3.3605 - acc: 0.1876 - LRFinder: val_loss: 12.2271 - lr = 0.13433992 \n",
      "231/390 [================>.............] - ETA: 28s - loss: 3.3603 - acc: 0.1878 - LRFinder: val_loss: 7.7456 - lr = 0.14000830 \n",
      "232/390 [================>.............] - ETA: 28s - loss: 3.3622 - acc: 0.1876 - LRFinder: val_loss: 10.0794 - lr = 0.14591586 \n",
      "233/390 [================>.............] - ETA: 28s - loss: 3.3618 - acc: 0.1878 - LRFinder: val_loss: 12.2400 - lr = 0.15207269 \n",
      "234/390 [=================>............] - ETA: 28s - loss: 3.3613 - acc: 0.1882 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "235/390 [=================>............] - ETA: 27s - loss: 3.3626 - acc: 0.1880 - LRFinder: val_loss: 11.4740 - lr = 0.15848931 \n",
      "236/390 [=================>............] - ETA: 27s - loss: 3.3624 - acc: 0.1882 - LRFinder: val_loss: 12.2909 - lr = 0.16517666 \n",
      "237/390 [=================>............] - ETA: 27s - loss: 3.3627 - acc: 0.1881 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "238/390 [=================>............] - ETA: 27s - loss: 3.3635 - acc: 0.1883 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "239/390 [=================>............] - ETA: 27s - loss: 3.3633 - acc: 0.1885 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "240/390 [=================>............] - ETA: 26s - loss: 3.3625 - acc: 0.1887 - LRFinder: val_loss: 12.1687 - lr = 0.17214618 \n",
      "241/390 [=================>............] - ETA: 26s - loss: 3.3630 - acc: 0.1888 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "242/390 [=================>............] - ETA: 26s - loss: 3.3621 - acc: 0.1892 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "243/390 [=================>............] - ETA: 26s - loss: 3.3616 - acc: 0.1895 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "244/390 [=================>............] - ETA: 26s - loss: 3.3635 - acc: 0.1895 - LRFinder: val_loss: 11.8694 - lr = 0.17940978 \n",
      "245/390 [=================>............] - ETA: 25s - loss: 3.3636 - acc: 0.1898 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "246/390 [=================>............] - ETA: 25s - loss: 3.3633 - acc: 0.1901 - LRFinder: val_loss: 12.0265 - lr = 0.18697987 \n",
      "247/390 [==================>...........] - ETA: 25s - loss: 3.3644 - acc: 0.1903 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "248/390 [==================>...........] - ETA: 25s - loss: 3.3641 - acc: 0.1906 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "249/390 [==================>...........] - ETA: 25s - loss: 3.3634 - acc: 0.1909 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "250/390 [==================>...........] - ETA: 25s - loss: 3.3635 - acc: 0.1909 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "251/390 [==================>...........] - ETA: 24s - loss: 3.3641 - acc: 0.1906 - LRFinder: val_loss: 11.7697 - lr = 0.19486937 \n",
      "252/390 [==================>...........] - ETA: 24s - loss: 3.3631 - acc: 0.1908 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "253/390 [==================>...........] - ETA: 24s - loss: 3.3623 - acc: 0.1912 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "254/390 [==================>...........] - ETA: 24s - loss: 3.3631 - acc: 0.1913 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "255/390 [==================>...........] - ETA: 24s - loss: 3.3637 - acc: 0.1912 - LRFinder: val_loss: 12.2821 - lr = 0.20309176 \n",
      "256/390 [==================>...........] - ETA: 23s - loss: 3.3641 - acc: 0.1913 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "257/390 [==================>...........] - ETA: 23s - loss: 3.3639 - acc: 0.1912 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "258/390 [==================>...........] - ETA: 23s - loss: 3.3636 - acc: 0.1915 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "259/390 [==================>...........] - ETA: 23s - loss: 3.3626 - acc: 0.1917 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "260/390 [===================>..........] - ETA: 23s - loss: 3.3622 - acc: 0.1920 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "261/390 [===================>..........] - ETA: 23s - loss: 3.3617 - acc: 0.1922 - LRFinder: val_loss: 12.1110 - lr = 0.21166108 \n",
      "262/390 [===================>..........] - ETA: 22s - loss: 3.3610 - acc: 0.1924 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "263/390 [===================>..........] - ETA: 22s - loss: 3.3611 - acc: 0.1925 - LRFinder: val_loss: 12.2721 - lr = 0.22059199 \n",
      "264/390 [===================>..........] - ETA: 22s - loss: 3.3605 - acc: 0.1927 - LRFinder: val_loss: 12.1421 - lr = 0.22989973 \n",
      "265/390 [===================>..........] - ETA: 22s - loss: 3.3604 - acc: 0.1929 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "266/390 [===================>..........] - ETA: 22s - loss: 3.3599 - acc: 0.1934 - LRFinder: val_loss: 12.0544 - lr = 0.23960021 \n",
      "267/390 [===================>..........] - ETA: 21s - loss: 3.3591 - acc: 0.1937 - LRFinder: val_loss: 10.4070 - lr = 0.24970999 \n",
      "268/390 [===================>..........] - ETA: 21s - loss: 3.3579 - acc: 0.1939 - LRFinder: val_loss: 10.2373 - lr = 0.26024635 \n",
      "269/390 [===================>..........] - ETA: 21s - loss: 3.3568 - acc: 0.1943 - LRFinder: val_loss: 10.9938 - lr = 0.27122726 \n",
      "270/390 [===================>..........] - ETA: 21s - loss: 3.3561 - acc: 0.1946 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "271/390 [===================>..........] - ETA: 21s - loss: 3.3551 - acc: 0.1949 - LRFinder: val_loss: 12.1169 - lr = 0.28267153 \n",
      "272/390 [===================>..........] - ETA: 21s - loss: 3.3538 - acc: 0.1953 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "273/390 [====================>.........] - ETA: 20s - loss: 3.3532 - acc: 0.1957 - LRFinder: val_loss: 8.3845 - lr = 0.29459869 \n",
      "274/390 [====================>.........] - ETA: 20s - loss: 3.3531 - acc: 0.1958 - LRFinder: val_loss: 8.6026 - lr = 0.30702910 \n",
      "275/390 [====================>.........] - ETA: 20s - loss: 3.3540 - acc: 0.1960 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "276/390 [====================>.........] - ETA: 20s - loss: 3.3535 - acc: 0.1964 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "277/390 [====================>.........] - ETA: 20s - loss: 3.3537 - acc: 0.1965 - LRFinder: val_loss: 11.5438 - lr = 0.31998399 \n",
      "278/390 [====================>.........] - ETA: 19s - loss: 3.3538 - acc: 0.1968 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "279/390 [====================>.........] - ETA: 19s - loss: 3.3539 - acc: 0.1967 - LRFinder: val_loss: 11.7732 - lr = 0.33348551 \n",
      "280/390 [====================>.........] - ETA: 19s - loss: 3.3545 - acc: 0.1965 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "281/390 [====================>.........] - ETA: 19s - loss: 3.3547 - acc: 0.1964 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "282/390 [====================>.........] - ETA: 19s - loss: 3.3550 - acc: 0.1965 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "283/390 [====================>.........] - ETA: 19s - loss: 3.3550 - acc: 0.1967 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "284/390 [====================>.........] - ETA: 18s - loss: 3.3551 - acc: 0.1969 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "285/390 [====================>.........] - ETA: 18s - loss: 3.3544 - acc: 0.1970 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "286/390 [=====================>........] - ETA: 18s - loss: 3.3539 - acc: 0.1972 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "287/390 [=====================>........] - ETA: 18s - loss: 3.3534 - acc: 0.1975 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "288/390 [=====================>........] - ETA: 18s - loss: 3.3542 - acc: 0.1977 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "289/390 [=====================>........] - ETA: 17s - loss: 3.3543 - acc: 0.1978 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "290/390 [=====================>........] - ETA: 17s - loss: 3.3546 - acc: 0.1978 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "291/390 [=====================>........] - ETA: 17s - loss: 3.3547 - acc: 0.1980 - LRFinder: val_loss: 12.3862 - lr = 0.34755672 \n",
      "292/390 [=====================>........] - ETA: 17s - loss: 3.3541 - acc: 0.1980 - LRFinder: val_loss: 9.9605 - lr = 0.36222164 \n",
      "293/390 [=====================>........] - ETA: 17s - loss: 3.3539 - acc: 0.1980 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "294/390 [=====================>........] - ETA: 17s - loss: 3.3541 - acc: 0.1979 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "295/390 [=====================>........] - ETA: 16s - loss: 3.3533 - acc: 0.1979 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "296/390 [=====================>........] - ETA: 16s - loss: 3.3528 - acc: 0.1983 - LRFinder: val_loss: 10.0384 - lr = 0.37750534 \n",
      "297/390 [=====================>........] - ETA: 16s - loss: 3.3531 - acc: 0.1983 - LRFinder: val_loss: 8.7299 - lr = 0.39343393 \n",
      "298/390 [=====================>........] - ETA: 16s - loss: 3.3527 - acc: 0.1984 - LRFinder: val_loss: 10.7886 - lr = 0.41003462 \n",
      "299/390 [======================>.......] - ETA: 16s - loss: 3.3523 - acc: 0.1986 - LRFinder: val_loss: 11.5041 - lr = 0.42733577 \n",
      "300/390 [======================>.......] - ETA: 15s - loss: 3.3521 - acc: 0.1988 - LRFinder: val_loss: 10.2220 - lr = 0.44536693 \n",
      "301/390 [======================>.......] - ETA: 15s - loss: 3.3520 - acc: 0.1991 - LRFinder: val_loss: 9.4322 - lr = 0.46415889 \n",
      "302/390 [======================>.......] - ETA: 15s - loss: 3.3519 - acc: 0.1991 - LRFinder: val_loss: 8.7115 - lr = 0.48374378 \n",
      "303/390 [======================>.......] - ETA: 15s - loss: 3.3513 - acc: 0.1993 - LRFinder: val_loss: 11.6501 - lr = 0.50415505 \n",
      "304/390 [======================>.......] - ETA: 15s - loss: 3.3512 - acc: 0.1994 - LRFinder: val_loss: 8.4785 - lr = 0.52542754 \n",
      "305/390 [======================>.......] - ETA: 15s - loss: 3.3505 - acc: 0.1993 - LRFinder: val_loss: 10.0935 - lr = 0.54759760 \n",
      "306/390 [======================>.......] - ETA: 14s - loss: 3.3510 - acc: 0.1993 - LRFinder: val_loss: 12.2962 - lr = 0.57070312 \n",
      "307/390 [======================>.......] - ETA: 14s - loss: 3.3506 - acc: 0.1995 - LRFinder: val_loss: 6.9921 - lr = 0.59478354 \n",
      "308/390 [======================>.......] - ETA: 14s - loss: 3.3494 - acc: 0.1999 - LRFinder: val_loss: 10.1811 - lr = 0.61988005 \n",
      "309/390 [======================>.......] - ETA: 14s - loss: 3.3489 - acc: 0.1998 - LRFinder: val_loss: 8.6980 - lr = 0.64603552 \n",
      "310/390 [======================>.......] - ETA: 14s - loss: 3.3485 - acc: 0.1999 - LRFinder: val_loss: 11.2468 - lr = 0.67329461 \n",
      "311/390 [======================>.......] - ETA: 13s - loss: 3.3475 - acc: 0.2001 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "312/390 [=======================>......] - ETA: 13s - loss: 3.3463 - acc: 0.2003 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "313/390 [=======================>......] - ETA: 13s - loss: 3.3461 - acc: 0.2005 - LRFinder: val_loss: 10.3160 - lr = 0.70170384 \n",
      "314/390 [=======================>......] - ETA: 13s - loss: 3.3453 - acc: 0.2008 - LRFinder: val_loss: 7.6603 - lr = 0.73131179 \n",
      "315/390 [=======================>......] - ETA: 13s - loss: 3.3445 - acc: 0.2008 - LRFinder: val_loss: 7.4844 - lr = 0.76216903 \n",
      "316/390 [=======================>......] - ETA: 13s - loss: 3.3440 - acc: 0.2008 - LRFinder: val_loss: 10.7516 - lr = 0.79432824 \n",
      "317/390 [=======================>......] - ETA: 12s - loss: 3.3433 - acc: 0.2009 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "318/390 [=======================>......] - ETA: 12s - loss: 3.3428 - acc: 0.2011 - LRFinder: val_loss: 11.9539 - lr = 0.82784438 \n",
      "319/390 [=======================>......] - ETA: 12s - loss: 3.3423 - acc: 0.2012 - LRFinder: val_loss: 6.7773 - lr = 0.86277474 \n",
      "320/390 [=======================>......] - ETA: 12s - loss: 3.3412 - acc: 0.2014 - LRFinder: val_loss: 6.6260 - lr = 0.89917896 \n",
      "321/390 [=======================>......] - ETA: 12s - loss: 3.3401 - acc: 0.2016 - LRFinder: val_loss: 6.5177 - lr = 0.93711926 \n",
      "322/390 [=======================>......] - ETA: 12s - loss: 3.3394 - acc: 0.2016 - LRFinder: val_loss: 9.0739 - lr = 0.97666039 \n",
      "323/390 [=======================>......] - ETA: 11s - loss: 3.3391 - acc: 0.2016 - LRFinder: val_loss: 9.9486 - lr = 1.01786993 \n",
      "324/390 [=======================>......] - ETA: 11s - loss: 3.3388 - acc: 0.2015 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "325/390 [========================>.....] - ETA: 11s - loss: 3.3383 - acc: 0.2019 - LRFinder: val_loss: 8.9604 - lr = 1.06081832 \n",
      "326/390 [========================>.....] - ETA: 11s - loss: 3.3388 - acc: 0.2019 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "327/390 [========================>.....] - ETA: 11s - loss: 3.3391 - acc: 0.2018 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "328/390 [========================>.....] - ETA: 10s - loss: 3.3394 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "329/390 [========================>.....] - ETA: 10s - loss: 3.3397 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "330/390 [========================>.....] - ETA: 10s - loss: 3.3403 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "331/390 [========================>.....] - ETA: 10s - loss: 3.3403 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "332/390 [========================>.....] - ETA: 10s - loss: 3.3400 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "333/390 [========================>.....] - ETA: 10s - loss: 3.3396 - acc: 0.2016 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "334/390 [========================>.....] - ETA: 9s - loss: 3.3389 - acc: 0.2017  - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "335/390 [========================>.....] - ETA: 9s - loss: 3.3380 - acc: 0.2017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "336/390 [========================>.....] - ETA: 9s - loss: 3.3371 - acc: 0.2020 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "337/390 [========================>.....] - ETA: 9s - loss: 3.3359 - acc: 0.2021 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "338/390 [=========================>....] - ETA: 9s - loss: 3.3355 - acc: 0.2021 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "339/390 [=========================>....] - ETA: 8s - loss: 3.3354 - acc: 0.2021 - LRFinder: val_loss: 12.4526 - lr = 1.10557886 \n",
      "340/390 [=========================>....] - ETA: 8s - loss: 3.3343 - acc: 0.2021 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "341/390 [=========================>....] - ETA: 8s - loss: 3.3336 - acc: 0.2021 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "342/390 [=========================>....] - ETA: 8s - loss: 3.3329 - acc: 0.2022 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "343/390 [=========================>....] - ETA: 8s - loss: 3.3323 - acc: 0.2022 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "344/390 [=========================>....] - ETA: 8s - loss: 3.3317 - acc: 0.2023 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "345/390 [=========================>....] - ETA: 7s - loss: 3.3308 - acc: 0.2024 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "346/390 [=========================>....] - ETA: 7s - loss: 3.3303 - acc: 0.2021 - LRFinder: val_loss: 12.0052 - lr = 1.15222809 \n",
      "347/390 [=========================>....] - ETA: 7s - loss: 3.3294 - acc: 0.2021 - LRFinder: val_loss: 9.6613 - lr = 1.20084564 \n",
      "348/390 [=========================>....] - ETA: 7s - loss: 3.3282 - acc: 0.2023 - LRFinder: val_loss: 8.2181 - lr = 1.25151451 \n",
      "349/390 [=========================>....] - ETA: 7s - loss: 3.3273 - acc: 0.2024 - LRFinder: val_loss: 12.4344 - lr = 1.30432141 \n",
      "350/390 [=========================>....] - ETA: 7s - loss: 3.3265 - acc: 0.2025 - LRFinder: val_loss: 12.2902 - lr = 1.35935641 \n",
      "351/390 [==========================>...] - ETA: 6s - loss: 3.3258 - acc: 0.2026 - LRFinder: val_loss: 11.6542 - lr = 1.41671357 \n",
      "352/390 [==========================>...] - ETA: 6s - loss: 3.3247 - acc: 0.2027 - LRFinder: val_loss: 12.1519 - lr = 1.47649092 \n",
      "353/390 [==========================>...] - ETA: 6s - loss: 3.3233 - acc: 0.2028 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "354/390 [==========================>...] - ETA: 6s - loss: 3.3226 - acc: 0.2028 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "355/390 [==========================>...] - ETA: 6s - loss: 3.3217 - acc: 0.2028 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "356/390 [==========================>...] - ETA: 5s - loss: 3.3207 - acc: 0.2028 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "357/390 [==========================>...] - ETA: 5s - loss: 3.3201 - acc: 0.2029 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "358/390 [==========================>...] - ETA: 5s - loss: 3.3192 - acc: 0.2030 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "359/390 [==========================>...] - ETA: 5s - loss: 3.3186 - acc: 0.2030 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "360/390 [==========================>...] - ETA: 5s - loss: 3.3177 - acc: 0.2031 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "361/390 [==========================>...] - ETA: 5s - loss: 3.3167 - acc: 0.2032 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "362/390 [==========================>...] - ETA: 4s - loss: 3.3155 - acc: 0.2034 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "363/390 [==========================>...] - ETA: 4s - loss: 3.3146 - acc: 0.2035 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "364/390 [===========================>..] - ETA: 4s - loss: 3.3140 - acc: 0.2034 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "365/390 [===========================>..] - ETA: 4s - loss: 3.3130 - acc: 0.2035 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "366/390 [===========================>..] - ETA: 4s - loss: 3.3118 - acc: 0.2036 - LRFinder: val_loss: 12.3869 - lr = 1.53879056 \n",
      "367/390 [===========================>..] - ETA: 4s - loss: 3.3104 - acc: 0.2037 - LRFinder: val_loss: 11.9330 - lr = 1.60371887 \n",
      "368/390 [===========================>..] - ETA: 3s - loss: 3.3090 - acc: 0.2037 - LRFinder: val_loss: 12.5937 - lr = 1.67138677 \n",
      "369/390 [===========================>..] - ETA: 3s - loss: 3.3080 - acc: 0.2039 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "370/390 [===========================>..] - ETA: 3s - loss: 3.3070 - acc: 0.2040 - LRFinder: val_loss: 11.9522 - lr = 1.74190981 \n",
      "371/390 [===========================>..] - ETA: 3s - loss: 3.3060 - acc: 0.2041 - LRFinder: val_loss: 11.3678 - lr = 1.81540863 \n",
      "372/390 [===========================>..] - ETA: 3s - loss: 3.3047 - acc: 0.2043 - LRFinder: val_loss: 10.6739 - lr = 1.89200859 \n",
      "373/390 [===========================>..] - ETA: 2s - loss: 3.3039 - acc: 0.2043 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "374/390 [===========================>..] - ETA: 2s - loss: 3.3026 - acc: 0.2044 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "375/390 [===========================>..] - ETA: 2s - loss: 3.3014 - acc: 0.2047 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "376/390 [===========================>..] - ETA: 2s - loss: 3.3004 - acc: 0.2048 - LRFinder: val_loss: 12.2157 - lr = 1.97184063 \n",
      "377/390 [============================>.] - ETA: 2s - loss: 3.2993 - acc: 0.2049 - LRFinder: val_loss: 10.7332 - lr = 2.05504117 \n",
      "378/390 [============================>.] - ETA: 2s - loss: 3.2982 - acc: 0.2050 - LRFinder: val_loss: 9.9910 - lr = 2.14175221 \n",
      "379/390 [============================>.] - ETA: 1s - loss: 3.2969 - acc: 0.2049 - LRFinder: val_loss: 10.6347 - lr = 2.23212210 \n",
      "380/390 [============================>.] - ETA: 1s - loss: 3.2960 - acc: 0.2048 - LRFinder: val_loss: 9.1889 - lr = 2.32630515 \n",
      "381/390 [============================>.] - ETA: 1s - loss: 3.2948 - acc: 0.2049 - LRFinder: val_loss: 9.6960 - lr = 2.42446210 \n",
      "382/390 [============================>.] - ETA: 1s - loss: 3.2938 - acc: 0.2049 - LRFinder: val_loss: 11.7687 - lr = 2.52676070 \n",
      "383/390 [============================>.] - ETA: 1s - loss: 3.2920 - acc: 0.2052 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "384/390 [============================>.] - ETA: 1s - loss: 3.2908 - acc: 0.2052 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (3.1612)\n",
      "385/390 [============================>.] - ETA: 0s - loss: 3.2896 - acc: 0.2052 - LRFinder: val_loss: 10.4164 - lr = 2.63337587 \n",
      "386/390 [============================>.] - ETA: 0s - loss: 3.2883 - acc: 0.2053 - LRFinder: val_loss: 5.4142 - lr = 2.74448949 \n",
      "387/390 [============================>.] - ETA: 0s - loss: 3.2873 - acc: 0.2055 - LRFinder: val_loss: 5.4653 - lr = 2.86029140 \n",
      "388/390 [============================>.] - ETA: 0s - loss: 3.2859 - acc: 0.2056 - LRFinder: val_loss: 6.8301 - lr = 2.98097965 \n",
      "389/390 [============================>.] - ETA: 0s - loss: 3.2846 - acc: 0.2057 - LRFinder: val_loss: 5.8822 - lr = 3.10676021 \n",
      " - LRFinder: val_loss: 5.3651 - lr = 3.23784802 \n",
      "390/390 [==============================] - 68s 175ms/step - loss: 3.2835 - acc: 0.2057\n",
      "\tLR Finder : Saved the losses and learning rate values in path : {/content/lr}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdc979def0>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding good learning rate using LRFinder (https://github.com/prateekgulati/keras-one-cycle/blob/master/README.md). Re-run the blocks where we create the resnet18 model. This ensure that the model is not trained and re-initialized model is used below One-Cycle code is executed.\n",
    "\n",
    "from clr import LRFinder\n",
    "\n",
    "'''lr_callback = LRFinder(num_samples = X_train.shape[0] , batch_size = 128, minimum_lr = 1e-5, maximum_lr = 100, validation_data = (X_test, Y_test), \n",
    "                       lr_scale='exp', validation_sample_rate=5,\n",
    "                       save_dir='/content/lr')'''\n",
    "\n",
    "\n",
    "lr_callback = LRFinder(num_samples = X_train.shape[0] , batch_size = 128, minimum_lr = 1e-5, maximum_lr = 100, validation_data = (X_test, Y_test), lr_scale='exp', save_dir='/content/lr')\n",
    "\n",
    "train_gen = CIFAR10Sequence(X_train, Y_train, batch_size = 128, augmentations=AUGMENTATIONS_TRAIN, pre_process = eraser )\n",
    "\n",
    "# Ensure that number of epochs = 1 when calling fit()\n",
    "model.fit_generator(train_gen,samples_per_epoch = X_train.shape[0], nb_epoch = 1, verbose=1, callbacks=[lr_callback] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "id": "1lEybxEJwXhH",
    "outputId": "7f2055e7-444d-4d30-b5f2-8e86b57e49c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAESCAYAAAAYMKWkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lr_callback.plot_schedule(clip_beginning=30)\n",
    "\n",
    "lr_callback.plot_schedule(clip_beginning=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pXUPw3JFr9MW"
   },
   "source": [
    "### Inferred learning rate value from above plot \n",
    "\n",
    "#### learning rate value from X-axis is after -2  (The values are in log 10 scale (since exp was used for lr_scale))\n",
    "\n",
    "#### Actual learning maximum learning rate is 10 ^ (x) which is 3*10^(-2) i.e.  ~ 3e-2\n",
    "\n",
    "#### Use  3e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwjmkzzYt_Si"
   },
   "outputs": [],
   "source": [
    "# Re-initialize the model for training with the above learning rate. Re-run the blocks where we create the resnet18 model. This ensure that the model is not trained when LRFinder/One-Cycle code is executed.\n",
    "\n",
    "model_f = model\n",
    "\n",
    "sgd = optimizers.SGD(lr= 3e-2, momentum=0.9, nesterov=False)\n",
    "model_f.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8wWdAPrkEpc"
   },
   "source": [
    "### Training with OneCycleLR aka  \"SUPER CONVERGENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKLA-bdCr95h"
   },
   "outputs": [],
   "source": [
    "# Define OneCycleLR\n",
    "\n",
    "from clr import OneCycleLR\n",
    "\n",
    "lr_manager = OneCycleLR(samples = X_train.shape[0], epochs = 300, max_lr = 3e-2, verbose=True, batch_size = 128, end_percentage=0.1, scale_percentage=None,\n",
    "                        maximum_momentum=0.9, minimum_momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RuTsStv47fU0",
    "outputId": "8720de0c-c553-4247-b31b-6c91eab2062c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive into colab. This is to save snapshots of the model during training\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive/\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6NCH-ue9rLK"
   },
   "outputs": [],
   "source": [
    "# Path to save the snapshots of the model\n",
    "\n",
    "filepath=\"/content/gdrive/My Drive/Best_model_resnet18_f.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK_PbIFk9rT_"
   },
   "outputs": [],
   "source": [
    "# create a checkpoint to save the model when accuracy improves\n",
    "\n",
    "from keras.callbacks import *\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_thDZfEK-BJW"
   },
   "outputs": [],
   "source": [
    "# Early stopping created to monitor validation accuracy and stop training once validation accuracy reaches 90%\n",
    "\n",
    "class EarlyStoppingByValAcc(Callback):\n",
    "  def __init__(self, monitor='val_acc', value=0.85, verbose=0):\n",
    "    super(Callback, self).__init__()\n",
    "    self.monitor = monitor\n",
    "    self.value = value\n",
    "    self.verbose = verbose\n",
    "    self.epoch_threshold = 1000\n",
    "               \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    current = logs.get(self.monitor)\n",
    "    if current is None:\n",
    "      warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "    if current > self.value and epoch < self.epoch_threshold:\n",
    "      if self.verbose > 0:\n",
    "        print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "      self.model.stop_training = True\n",
    "      \n",
    "es = EarlyStoppingByValAcc(monitor='val_acc', value=0.90, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJ5izAo--BYN"
   },
   "outputs": [],
   "source": [
    "# callback list for OneCycleLR, perform early stopping and saving the model when accuracy improves\n",
    "\n",
    "callbacks_list = [lr_manager, es, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ptxAJPlW3BdC",
    "outputId": "8e0b1630-19da-4b22-fc0a-b59f577ff6fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<__main__...., validation_data=(array([[[..., verbose=1, workers=2, use_multiprocessing=True, callbacks=[<clr.OneC..., steps_per_epoch=390, epochs=300)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  4/390 [..............................] - ETA: 6:12 - loss: 3.6620 - acc: 0.1113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.270334). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 90ms/step - loss: 3.0555 - acc: 0.3001 - val_loss: 2.8918 - val_acc: 0.3505\n",
      " - lr: 0.00320 - momentum: 0.90 \n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.35050, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 2/300\n",
      "  1/390 [..............................] - ETA: 40s - loss: 2.9181 - acc: 0.4062\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 2.8101 - acc: 0.3874 - val_loss: 2.8806 - val_acc: 0.3793\n",
      " - lr: 0.00340 - momentum: 0.90 \n",
      "\n",
      "Epoch 00002: val_acc improved from 0.35050 to 0.37930, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 3/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.6907 - acc: 0.4365 - val_loss: 2.7940 - val_acc: 0.4140\n",
      " - lr: 0.00360 - momentum: 0.90 \n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37930 to 0.41400, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 4/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.6010 - acc: 0.4705 - val_loss: 2.8258 - val_acc: 0.4105\n",
      " - lr: 0.00380 - momentum: 0.90 \n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.41400\n",
      "Epoch 5/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.5410 - acc: 0.4916 - val_loss: 2.6749 - val_acc: 0.4624\n",
      " - lr: 0.00399 - momentum: 0.90 \n",
      "\n",
      "Epoch 00005: val_acc improved from 0.41400 to 0.46240, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 6/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.4871 - acc: 0.5080 - val_loss: 3.1818 - val_acc: 0.3817\n",
      " - lr: 0.00419 - momentum: 0.90 \n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.46240\n",
      "Epoch 7/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.4450 - acc: 0.5234 - val_loss: 2.5915 - val_acc: 0.4815\n",
      " - lr: 0.00439 - momentum: 0.90 \n",
      "\n",
      "Epoch 00007: val_acc improved from 0.46240 to 0.48150, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 8/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.4041 - acc: 0.5378 - val_loss: 2.8398 - val_acc: 0.4526\n",
      " - lr: 0.00459 - momentum: 0.90 \n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.48150\n",
      "Epoch 9/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.3727 - acc: 0.5428 - val_loss: 2.3229 - val_acc: 0.5545\n",
      " - lr: 0.00479 - momentum: 0.90 \n",
      "\n",
      "Epoch 00009: val_acc improved from 0.48150 to 0.55450, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 10/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.3321 - acc: 0.5569 - val_loss: 2.4543 - val_acc: 0.5281\n",
      " - lr: 0.00499 - momentum: 0.90 \n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.55450\n",
      "Epoch 11/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.3005 - acc: 0.5650 - val_loss: 2.2504 - val_acc: 0.5890\n",
      " - lr: 0.00519 - momentum: 0.90 \n",
      "\n",
      "Epoch 00011: val_acc improved from 0.55450 to 0.58900, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 12/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.2707 - acc: 0.5719 - val_loss: 2.8834 - val_acc: 0.4597\n",
      " - lr: 0.00539 - momentum: 0.90 \n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.58900\n",
      "Epoch 13/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.2426 - acc: 0.5808 - val_loss: 2.7402 - val_acc: 0.4636\n",
      " - lr: 0.00559 - momentum: 0.90 \n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.58900\n",
      "Epoch 14/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.2159 - acc: 0.5860 - val_loss: 2.4734 - val_acc: 0.5208\n",
      " - lr: 0.00579 - momentum: 0.90 \n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58900\n",
      "Epoch 15/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.1764 - acc: 0.5960 - val_loss: 2.2943 - val_acc: 0.5675\n",
      " - lr: 0.00598 - momentum: 0.90 \n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58900\n",
      "Epoch 16/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.1509 - acc: 0.6048 - val_loss: 2.9008 - val_acc: 0.4302\n",
      " - lr: 0.00618 - momentum: 0.90 \n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58900\n",
      "Epoch 17/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.1209 - acc: 0.6090 - val_loss: 2.9936 - val_acc: 0.4516\n",
      " - lr: 0.00638 - momentum: 0.90 \n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58900\n",
      "Epoch 18/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.0885 - acc: 0.6207 - val_loss: 2.3423 - val_acc: 0.5578\n",
      " - lr: 0.00658 - momentum: 0.90 \n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.58900\n",
      "Epoch 19/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.0644 - acc: 0.6231 - val_loss: 2.2285 - val_acc: 0.5871\n",
      " - lr: 0.00678 - momentum: 0.90 \n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.58900\n",
      "Epoch 20/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.0363 - acc: 0.6335 - val_loss: 2.2437 - val_acc: 0.5806\n",
      " - lr: 0.00698 - momentum: 0.90 \n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.58900\n",
      "Epoch 21/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 2.0076 - acc: 0.6359 - val_loss: 2.5436 - val_acc: 0.5188\n",
      " - lr: 0.00718 - momentum: 0.90 \n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.58900\n",
      "Epoch 22/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.9859 - acc: 0.6415 - val_loss: 2.0598 - val_acc: 0.6056\n",
      " - lr: 0.00738 - momentum: 0.90 \n",
      "\n",
      "Epoch 00022: val_acc improved from 0.58900 to 0.60560, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 23/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.9619 - acc: 0.6474 - val_loss: 2.2051 - val_acc: 0.6117\n",
      " - lr: 0.00758 - momentum: 0.90 \n",
      "\n",
      "Epoch 00023: val_acc improved from 0.60560 to 0.61170, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 24/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.9356 - acc: 0.6550 - val_loss: 2.2346 - val_acc: 0.5793\n",
      " - lr: 0.00778 - momentum: 0.90 \n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61170\n",
      "Epoch 25/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.9040 - acc: 0.6596 - val_loss: 2.0261 - val_acc: 0.6169\n",
      " - lr: 0.00797 - momentum: 0.90 \n",
      "\n",
      "Epoch 00025: val_acc improved from 0.61170 to 0.61690, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 26/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.8851 - acc: 0.6634 - val_loss: 1.9735 - val_acc: 0.6327\n",
      " - lr: 0.00817 - momentum: 0.90 \n",
      "\n",
      "Epoch 00026: val_acc improved from 0.61690 to 0.63270, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 27/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.8567 - acc: 0.6691 - val_loss: 2.0518 - val_acc: 0.6174\n",
      " - lr: 0.00837 - momentum: 0.90 \n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.63270\n",
      "Epoch 28/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.8254 - acc: 0.6780 - val_loss: 1.9685 - val_acc: 0.6370\n",
      " - lr: 0.00857 - momentum: 0.90 \n",
      "\n",
      "Epoch 00028: val_acc improved from 0.63270 to 0.63700, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 29/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.8052 - acc: 0.6803 - val_loss: 1.9146 - val_acc: 0.6541\n",
      " - lr: 0.00877 - momentum: 0.90 \n",
      "\n",
      "Epoch 00029: val_acc improved from 0.63700 to 0.65410, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 30/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.7773 - acc: 0.6862 - val_loss: 1.8740 - val_acc: 0.6549\n",
      " - lr: 0.00897 - momentum: 0.90 \n",
      "\n",
      "Epoch 00030: val_acc improved from 0.65410 to 0.65490, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 31/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.7571 - acc: 0.6902 - val_loss: 2.2137 - val_acc: 0.5782\n",
      " - lr: 0.00917 - momentum: 0.90 \n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.65490\n",
      "Epoch 32/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.7345 - acc: 0.6946 - val_loss: 2.0516 - val_acc: 0.6131\n",
      " - lr: 0.00937 - momentum: 0.90 \n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.65490\n",
      "Epoch 33/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.7015 - acc: 0.7021 - val_loss: 2.2960 - val_acc: 0.5784\n",
      " - lr: 0.00957 - momentum: 0.90 \n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.65490\n",
      "Epoch 34/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.6807 - acc: 0.7062 - val_loss: 2.2591 - val_acc: 0.5827\n",
      " - lr: 0.00977 - momentum: 0.90 \n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.65490\n",
      "Epoch 35/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.6535 - acc: 0.7105 - val_loss: 1.7792 - val_acc: 0.6867\n",
      " - lr: 0.00997 - momentum: 0.90 \n",
      "\n",
      "Epoch 00035: val_acc improved from 0.65490 to 0.68670, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 36/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.6306 - acc: 0.7155 - val_loss: 1.7316 - val_acc: 0.6931\n",
      " - lr: 0.01016 - momentum: 0.90 \n",
      "\n",
      "Epoch 00036: val_acc improved from 0.68670 to 0.69310, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 37/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.6023 - acc: 0.7234 - val_loss: 1.9511 - val_acc: 0.6319\n",
      " - lr: 0.01036 - momentum: 0.90 \n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.69310\n",
      "Epoch 38/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.5813 - acc: 0.7244 - val_loss: 1.9188 - val_acc: 0.6289\n",
      " - lr: 0.01056 - momentum: 0.90 \n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.69310\n",
      "Epoch 39/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.5547 - acc: 0.7314 - val_loss: 2.2079 - val_acc: 0.5778\n",
      " - lr: 0.01076 - momentum: 0.90 \n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.69310\n",
      "Epoch 40/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.5420 - acc: 0.7310 - val_loss: 1.7741 - val_acc: 0.6554\n",
      " - lr: 0.01096 - momentum: 0.90 \n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.69310\n",
      "Epoch 41/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.5164 - acc: 0.7355 - val_loss: 2.5699 - val_acc: 0.5605\n",
      " - lr: 0.01116 - momentum: 0.90 \n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.69310\n",
      "Epoch 42/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.4913 - acc: 0.7404 - val_loss: 1.7480 - val_acc: 0.6745\n",
      " - lr: 0.01136 - momentum: 0.90 \n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.69310\n",
      "Epoch 43/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.4756 - acc: 0.7431 - val_loss: 2.0099 - val_acc: 0.6019\n",
      " - lr: 0.01156 - momentum: 0.90 \n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.69310\n",
      "Epoch 44/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.4502 - acc: 0.7465 - val_loss: 1.8104 - val_acc: 0.6366\n",
      " - lr: 0.01176 - momentum: 0.90 \n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.69310\n",
      "Epoch 45/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.4349 - acc: 0.7513 - val_loss: 1.5640 - val_acc: 0.7143\n",
      " - lr: 0.01196 - momentum: 0.90 \n",
      "\n",
      "Epoch 00045: val_acc improved from 0.69310 to 0.71430, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 46/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.4132 - acc: 0.7528 - val_loss: 1.6317 - val_acc: 0.6963\n",
      " - lr: 0.01215 - momentum: 0.90 \n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.71430\n",
      "Epoch 47/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.3983 - acc: 0.7555 - val_loss: 1.5981 - val_acc: 0.7011\n",
      " - lr: 0.01235 - momentum: 0.90 \n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.71430\n",
      "Epoch 48/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.3693 - acc: 0.7616 - val_loss: 1.5127 - val_acc: 0.7335\n",
      " - lr: 0.01255 - momentum: 0.90 \n",
      "\n",
      "Epoch 00048: val_acc improved from 0.71430 to 0.73350, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 49/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.3547 - acc: 0.7624 - val_loss: 1.8465 - val_acc: 0.6100\n",
      " - lr: 0.01275 - momentum: 0.90 \n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.73350\n",
      "Epoch 50/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.3360 - acc: 0.7647 - val_loss: 1.7144 - val_acc: 0.6632\n",
      " - lr: 0.01295 - momentum: 0.90 \n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.73350\n",
      "Epoch 51/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.3162 - acc: 0.7690 - val_loss: 1.5489 - val_acc: 0.7091\n",
      " - lr: 0.01315 - momentum: 0.90 \n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.73350\n",
      "Epoch 52/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2983 - acc: 0.7725 - val_loss: 1.8196 - val_acc: 0.6588\n",
      " - lr: 0.01335 - momentum: 0.90 \n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.73350\n",
      "Epoch 53/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2722 - acc: 0.7775 - val_loss: 1.7220 - val_acc: 0.6788\n",
      " - lr: 0.01355 - momentum: 0.90 \n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.73350\n",
      "Epoch 54/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2626 - acc: 0.7769 - val_loss: 1.2892 - val_acc: 0.7682\n",
      " - lr: 0.01375 - momentum: 0.90 \n",
      "\n",
      "Epoch 00054: val_acc improved from 0.73350 to 0.76820, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 55/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2498 - acc: 0.7796 - val_loss: 1.5353 - val_acc: 0.7017\n",
      " - lr: 0.01395 - momentum: 0.90 \n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.76820\n",
      "Epoch 56/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2279 - acc: 0.7842 - val_loss: 1.8650 - val_acc: 0.6120\n",
      " - lr: 0.01414 - momentum: 0.90 \n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.76820\n",
      "Epoch 57/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.2123 - acc: 0.7857 - val_loss: 1.2806 - val_acc: 0.7715\n",
      " - lr: 0.01434 - momentum: 0.90 \n",
      "\n",
      "Epoch 00057: val_acc improved from 0.76820 to 0.77150, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 58/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1953 - acc: 0.7887 - val_loss: 1.7574 - val_acc: 0.6650\n",
      " - lr: 0.01454 - momentum: 0.90 \n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.77150\n",
      "Epoch 59/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1712 - acc: 0.7917 - val_loss: 1.5536 - val_acc: 0.6924\n",
      " - lr: 0.01474 - momentum: 0.90 \n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.77150\n",
      "Epoch 60/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1671 - acc: 0.7902 - val_loss: 2.9775 - val_acc: 0.4568\n",
      " - lr: 0.01494 - momentum: 0.90 \n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.77150\n",
      "Epoch 61/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1506 - acc: 0.7936 - val_loss: 1.2138 - val_acc: 0.7780\n",
      " - lr: 0.01514 - momentum: 0.90 \n",
      "\n",
      "Epoch 00061: val_acc improved from 0.77150 to 0.77800, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 62/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1316 - acc: 0.7978 - val_loss: 1.3006 - val_acc: 0.7598\n",
      " - lr: 0.01534 - momentum: 0.90 \n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.77800\n",
      "Epoch 63/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1196 - acc: 0.7979 - val_loss: 1.5418 - val_acc: 0.6516\n",
      " - lr: 0.01554 - momentum: 0.90 \n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.77800\n",
      "Epoch 64/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1044 - acc: 0.8008 - val_loss: 1.4429 - val_acc: 0.7223\n",
      " - lr: 0.01574 - momentum: 0.90 \n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.77800\n",
      "Epoch 65/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0943 - acc: 0.7993 - val_loss: 1.4275 - val_acc: 0.7264\n",
      " - lr: 0.01594 - momentum: 0.90 \n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.77800\n",
      "Epoch 66/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0782 - acc: 0.8055 - val_loss: 1.5018 - val_acc: 0.6836\n",
      " - lr: 0.01613 - momentum: 0.90 \n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.77800\n",
      "Epoch 67/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0723 - acc: 0.8029 - val_loss: 1.1195 - val_acc: 0.7910\n",
      " - lr: 0.01633 - momentum: 0.90 \n",
      "\n",
      "Epoch 00067: val_acc improved from 0.77800 to 0.79100, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 68/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0540 - acc: 0.8066 - val_loss: 1.5465 - val_acc: 0.6840\n",
      " - lr: 0.01653 - momentum: 0.90 \n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.79100\n",
      "Epoch 69/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0386 - acc: 0.8097 - val_loss: 1.4821 - val_acc: 0.7023\n",
      " - lr: 0.01673 - momentum: 0.90 \n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.79100\n",
      "Epoch 70/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0251 - acc: 0.8123 - val_loss: 1.1768 - val_acc: 0.7772\n",
      " - lr: 0.01693 - momentum: 0.90 \n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.79100\n",
      "Epoch 71/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 1.0156 - acc: 0.8122 - val_loss: 1.5199 - val_acc: 0.6990\n",
      " - lr: 0.01713 - momentum: 0.90 \n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.79100\n",
      "Epoch 72/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9976 - acc: 0.8180 - val_loss: 1.8251 - val_acc: 0.6093\n",
      " - lr: 0.01733 - momentum: 0.90 \n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.79100\n",
      "Epoch 73/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9974 - acc: 0.8148 - val_loss: 1.2073 - val_acc: 0.7691\n",
      " - lr: 0.01753 - momentum: 0.90 \n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.79100\n",
      "Epoch 74/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9775 - acc: 0.8189 - val_loss: 1.2756 - val_acc: 0.7387\n",
      " - lr: 0.01773 - momentum: 0.90 \n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.79100\n",
      "Epoch 75/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9735 - acc: 0.8158 - val_loss: 1.4318 - val_acc: 0.7018\n",
      " - lr: 0.01793 - momentum: 0.90 \n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.79100\n",
      "Epoch 76/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9637 - acc: 0.8181 - val_loss: 1.4411 - val_acc: 0.7241\n",
      " - lr: 0.01812 - momentum: 0.90 \n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.79100\n",
      "Epoch 77/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9526 - acc: 0.8203 - val_loss: 1.4390 - val_acc: 0.7057\n",
      " - lr: 0.01832 - momentum: 0.90 \n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.79100\n",
      "Epoch 78/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9397 - acc: 0.8207 - val_loss: 1.2913 - val_acc: 0.7396\n",
      " - lr: 0.01852 - momentum: 0.90 \n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.79100\n",
      "Epoch 79/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9365 - acc: 0.8226 - val_loss: 1.1529 - val_acc: 0.7727\n",
      " - lr: 0.01872 - momentum: 0.90 \n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.79100\n",
      "Epoch 80/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9198 - acc: 0.8237 - val_loss: 1.1488 - val_acc: 0.7552\n",
      " - lr: 0.01892 - momentum: 0.90 \n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.79100\n",
      "Epoch 81/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.9109 - acc: 0.8269 - val_loss: 1.2824 - val_acc: 0.7281\n",
      " - lr: 0.01912 - momentum: 0.90 \n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.79100\n",
      "Epoch 82/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8986 - acc: 0.8266 - val_loss: 1.0319 - val_acc: 0.7925\n",
      " - lr: 0.01932 - momentum: 0.90 \n",
      "\n",
      "Epoch 00082: val_acc improved from 0.79100 to 0.79250, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 83/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8953 - acc: 0.8285 - val_loss: 0.9003 - val_acc: 0.8307\n",
      " - lr: 0.01952 - momentum: 0.90 \n",
      "\n",
      "Epoch 00083: val_acc improved from 0.79250 to 0.83070, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 84/300\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.8816 - acc: 0.8297 - val_loss: 1.0968 - val_acc: 0.7783\n",
      " - lr: 0.01972 - momentum: 0.90 \n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.83070\n",
      "Epoch 85/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8817 - acc: 0.8276 - val_loss: 1.1451 - val_acc: 0.7584\n",
      " - lr: 0.01992 - momentum: 0.90 \n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.83070\n",
      "Epoch 86/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8712 - acc: 0.8308 - val_loss: 1.1530 - val_acc: 0.7602\n",
      " - lr: 0.02011 - momentum: 0.90 \n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.83070\n",
      "Epoch 87/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8578 - acc: 0.8329 - val_loss: 1.1258 - val_acc: 0.7640\n",
      " - lr: 0.02031 - momentum: 0.90 \n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.83070\n",
      "Epoch 88/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8472 - acc: 0.8338 - val_loss: 0.9590 - val_acc: 0.8125\n",
      " - lr: 0.02051 - momentum: 0.90 \n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.83070\n",
      "Epoch 89/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8425 - acc: 0.8344 - val_loss: 1.4283 - val_acc: 0.6980\n",
      " - lr: 0.02071 - momentum: 0.90 \n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.83070\n",
      "Epoch 90/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8389 - acc: 0.8333 - val_loss: 1.2164 - val_acc: 0.7328\n",
      " - lr: 0.02091 - momentum: 0.90 \n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.83070\n",
      "Epoch 91/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8283 - acc: 0.8373 - val_loss: 1.8365 - val_acc: 0.6137\n",
      " - lr: 0.02111 - momentum: 0.90 \n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.83070\n",
      "Epoch 92/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8298 - acc: 0.8341 - val_loss: 1.6686 - val_acc: 0.6233\n",
      " - lr: 0.02131 - momentum: 0.90 \n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.83070\n",
      "Epoch 93/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8245 - acc: 0.8355 - val_loss: 0.9745 - val_acc: 0.7931\n",
      " - lr: 0.02151 - momentum: 0.90 \n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.83070\n",
      "Epoch 94/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8062 - acc: 0.8389 - val_loss: 1.5015 - val_acc: 0.6904\n",
      " - lr: 0.02171 - momentum: 0.90 \n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.83070\n",
      "Epoch 95/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8089 - acc: 0.8382 - val_loss: 1.1903 - val_acc: 0.7313\n",
      " - lr: 0.02191 - momentum: 0.90 \n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.83070\n",
      "Epoch 96/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7960 - acc: 0.8411 - val_loss: 1.0691 - val_acc: 0.7769\n",
      " - lr: 0.02211 - momentum: 0.90 \n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.83070\n",
      "Epoch 97/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7966 - acc: 0.8395 - val_loss: 1.2897 - val_acc: 0.7322\n",
      " - lr: 0.02230 - momentum: 0.90 \n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.83070\n",
      "Epoch 98/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7920 - acc: 0.8404 - val_loss: 1.3876 - val_acc: 0.6899\n",
      " - lr: 0.02250 - momentum: 0.90 \n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.83070\n",
      "Epoch 99/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7852 - acc: 0.8399 - val_loss: 1.0498 - val_acc: 0.7797\n",
      " - lr: 0.02270 - momentum: 0.90 \n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.83070\n",
      "Epoch 100/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7765 - acc: 0.8432 - val_loss: 1.2415 - val_acc: 0.7313\n",
      " - lr: 0.02290 - momentum: 0.90 \n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.83070\n",
      "Epoch 101/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7746 - acc: 0.8431 - val_loss: 1.1247 - val_acc: 0.7551\n",
      " - lr: 0.02310 - momentum: 0.90 \n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.83070\n",
      "Epoch 102/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7734 - acc: 0.8414 - val_loss: 0.9642 - val_acc: 0.7968\n",
      " - lr: 0.02330 - momentum: 0.90 \n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.83070\n",
      "Epoch 103/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7603 - acc: 0.8456 - val_loss: 1.0749 - val_acc: 0.7603\n",
      " - lr: 0.02350 - momentum: 0.90 \n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.83070\n",
      "Epoch 104/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7645 - acc: 0.8426 - val_loss: 1.1338 - val_acc: 0.7491\n",
      " - lr: 0.02370 - momentum: 0.90 \n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.83070\n",
      "Epoch 105/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7573 - acc: 0.8466 - val_loss: 0.9685 - val_acc: 0.7900\n",
      " - lr: 0.02390 - momentum: 0.90 \n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.83070\n",
      "Epoch 106/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7571 - acc: 0.8442 - val_loss: 1.0087 - val_acc: 0.7723\n",
      " - lr: 0.02410 - momentum: 0.90 \n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.83070\n",
      "Epoch 107/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7580 - acc: 0.8439 - val_loss: 1.0107 - val_acc: 0.7795\n",
      " - lr: 0.02429 - momentum: 0.90 \n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.83070\n",
      "Epoch 108/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7407 - acc: 0.8480 - val_loss: 1.2608 - val_acc: 0.7324\n",
      " - lr: 0.02449 - momentum: 0.90 \n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.83070\n",
      "Epoch 109/300\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.7442 - acc: 0.8480 - val_loss: 1.3328 - val_acc: 0.7058\n",
      " - lr: 0.02469 - momentum: 0.90 \n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.83070\n",
      "Epoch 110/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.7380 - acc: 0.8468 - val_loss: 1.0207 - val_acc: 0.7841\n",
      " - lr: 0.02489 - momentum: 0.90 \n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.83070\n",
      "Epoch 111/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7317 - acc: 0.8499 - val_loss: 1.1328 - val_acc: 0.7618\n",
      " - lr: 0.02509 - momentum: 0.90 \n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.83070\n",
      "Epoch 112/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7353 - acc: 0.8473 - val_loss: 1.5296 - val_acc: 0.6978\n",
      " - lr: 0.02529 - momentum: 0.90 \n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.83070\n",
      "Epoch 113/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7327 - acc: 0.8474 - val_loss: 1.0041 - val_acc: 0.7861\n",
      " - lr: 0.02549 - momentum: 0.90 \n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.83070\n",
      "Epoch 114/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7241 - acc: 0.8513 - val_loss: 1.1902 - val_acc: 0.7523\n",
      " - lr: 0.02569 - momentum: 0.90 \n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.83070\n",
      "Epoch 115/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7229 - acc: 0.8491 - val_loss: 1.0636 - val_acc: 0.7492\n",
      " - lr: 0.02589 - momentum: 0.90 \n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.83070\n",
      "Epoch 116/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7231 - acc: 0.8486 - val_loss: 1.4466 - val_acc: 0.7063\n",
      " - lr: 0.02609 - momentum: 0.90 \n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.83070\n",
      "Epoch 117/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7215 - acc: 0.8488 - val_loss: 1.0905 - val_acc: 0.7497\n",
      " - lr: 0.02628 - momentum: 0.90 \n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.83070\n",
      "Epoch 118/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7144 - acc: 0.8526 - val_loss: 1.2209 - val_acc: 0.7470\n",
      " - lr: 0.02648 - momentum: 0.90 \n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.83070\n",
      "Epoch 119/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7172 - acc: 0.8493 - val_loss: 0.7990 - val_acc: 0.8333\n",
      " - lr: 0.02668 - momentum: 0.90 \n",
      "\n",
      "Epoch 00119: val_acc improved from 0.83070 to 0.83330, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 120/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7109 - acc: 0.8520 - val_loss: 0.8123 - val_acc: 0.8330\n",
      " - lr: 0.02688 - momentum: 0.90 \n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.83330\n",
      "Epoch 121/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7122 - acc: 0.8516 - val_loss: 1.0177 - val_acc: 0.7956\n",
      " - lr: 0.02708 - momentum: 0.90 \n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.83330\n",
      "Epoch 122/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7056 - acc: 0.8558 - val_loss: 1.5423 - val_acc: 0.6844\n",
      " - lr: 0.02728 - momentum: 0.90 \n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.83330\n",
      "Epoch 123/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7093 - acc: 0.8535 - val_loss: 0.9427 - val_acc: 0.7894\n",
      " - lr: 0.02748 - momentum: 0.90 \n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.83330\n",
      "Epoch 124/300\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.7112 - acc: 0.8507 - val_loss: 0.8389 - val_acc: 0.8266\n",
      " - lr: 0.02768 - momentum: 0.90 \n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.83330\n",
      "Epoch 125/300\n",
      "390/390 [==============================] - 34s 86ms/step - loss: 0.7010 - acc: 0.8533 - val_loss: 1.4055 - val_acc: 0.6953\n",
      " - lr: 0.02788 - momentum: 0.90 \n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.83330\n",
      "Epoch 126/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6990 - acc: 0.8557 - val_loss: 0.9379 - val_acc: 0.8012\n",
      " - lr: 0.02808 - momentum: 0.90 \n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.83330\n",
      "Epoch 127/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6952 - acc: 0.8567 - val_loss: 1.1887 - val_acc: 0.7466\n",
      " - lr: 0.02827 - momentum: 0.90 \n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.83330\n",
      "Epoch 128/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6974 - acc: 0.8549 - val_loss: 0.8050 - val_acc: 0.8362\n",
      " - lr: 0.02847 - momentum: 0.90 \n",
      "\n",
      "Epoch 00128: val_acc improved from 0.83330 to 0.83620, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 129/300\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.6957 - acc: 0.8559 - val_loss: 0.9743 - val_acc: 0.7773\n",
      " - lr: 0.02867 - momentum: 0.90 \n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.83620\n",
      "Epoch 130/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6965 - acc: 0.8531 - val_loss: 1.2746 - val_acc: 0.7078\n",
      " - lr: 0.02887 - momentum: 0.90 \n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.83620\n",
      "Epoch 131/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6934 - acc: 0.8546 - val_loss: 1.2285 - val_acc: 0.7384\n",
      " - lr: 0.02907 - momentum: 0.90 \n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.83620\n",
      "Epoch 132/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6922 - acc: 0.8554 - val_loss: 1.0943 - val_acc: 0.7459\n",
      " - lr: 0.02927 - momentum: 0.90 \n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.83620\n",
      "Epoch 133/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6969 - acc: 0.8536 - val_loss: 1.2717 - val_acc: 0.7154\n",
      " - lr: 0.02947 - momentum: 0.90 \n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.83620\n",
      "Epoch 134/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6926 - acc: 0.8545 - val_loss: 0.9838 - val_acc: 0.7994\n",
      " - lr: 0.02967 - momentum: 0.90 \n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.83620\n",
      "Epoch 135/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6899 - acc: 0.8559 - val_loss: 1.3403 - val_acc: 0.7070\n",
      " - lr: 0.02987 - momentum: 0.90 \n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.83620\n",
      "Epoch 136/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6896 - acc: 0.8559 - val_loss: 0.9627 - val_acc: 0.7955\n",
      " - lr: 0.02993 - momentum: 0.90 \n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.83620\n",
      "Epoch 137/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6911 - acc: 0.8561 - val_loss: 0.9953 - val_acc: 0.7806\n",
      " - lr: 0.02974 - momentum: 0.90 \n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.83620\n",
      "Epoch 138/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6741 - acc: 0.8607 - val_loss: 0.8989 - val_acc: 0.8229\n",
      " - lr: 0.02954 - momentum: 0.90 \n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.83620\n",
      "Epoch 139/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6804 - acc: 0.8609 - val_loss: 0.7890 - val_acc: 0.8384\n",
      " - lr: 0.02934 - momentum: 0.90 \n",
      "\n",
      "Epoch 00139: val_acc improved from 0.83620 to 0.83840, saving model to /content/gdrive/My Drive/Best_model_resnet18_f.hdf5\n",
      "Epoch 140/300\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.6726 - acc: 0.8616 - val_loss: 1.1400 - val_acc: 0.7462\n",
      " - lr: 0.02914 - momentum: 0.90 \n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.83840\n",
      "Epoch 141/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6721 - acc: 0.8629 - val_loss: 1.1227 - val_acc: 0.7581\n",
      " - lr: 0.02894 - momentum: 0.90 \n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.83840\n",
      "Epoch 142/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6687 - acc: 0.8615 - val_loss: 1.4490 - val_acc: 0.6995\n",
      " - lr: 0.02874 - momentum: 0.90 \n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.83840\n",
      "Epoch 143/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6694 - acc: 0.8630 - val_loss: 0.9239 - val_acc: 0.8043\n",
      " - lr: 0.02854 - momentum: 0.90 \n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.83840\n",
      "Epoch 144/300\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.6684 - acc: 0.8624 - val_loss: 1.1193 - val_acc: 0.7424\n",
      " - lr: 0.02834 - momentum: 0.90 \n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.83840\n",
      "Epoch 145/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6553 - acc: 0.8660 - val_loss: 1.1904 - val_acc: 0.7389\n",
      " - lr: 0.02814 - momentum: 0.90 \n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.83840\n",
      "Epoch 146/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6585 - acc: 0.8666 - val_loss: 1.0647 - val_acc: 0.7792\n",
      " - lr: 0.02794 - momentum: 0.90 \n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.83840\n",
      "Epoch 147/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6437 - acc: 0.8717 - val_loss: 1.6542 - val_acc: 0.6614\n",
      " - lr: 0.02774 - momentum: 0.90 \n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.83840\n",
      "Epoch 148/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6575 - acc: 0.8652 - val_loss: 0.9290 - val_acc: 0.8122\n",
      " - lr: 0.02755 - momentum: 0.90 \n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.83840\n",
      "Epoch 149/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6448 - acc: 0.8690 - val_loss: 0.9160 - val_acc: 0.8112\n",
      " - lr: 0.02735 - momentum: 0.90 \n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.83840\n",
      "Epoch 150/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6370 - acc: 0.8715 - val_loss: 0.9825 - val_acc: 0.8014\n",
      " - lr: 0.02715 - momentum: 0.90 \n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.83840\n",
      "Epoch 151/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6413 - acc: 0.8721 - val_loss: 1.2842 - val_acc: 0.7532\n",
      " - lr: 0.02695 - momentum: 0.90 \n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.83840\n",
      "Epoch 152/300\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6355 - acc: 0.8715 - val_loss: 0.8983 - val_acc: 0.8071\n",
      " - lr: 0.02675 - momentum: 0.90 \n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.83840\n",
      "Epoch 153/300\n",
      "331/390 [========================>.....] - ETA: 4s - loss: 0.6278 - acc: 0.8740Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "# Train the model using fit_generator function. Also calculate and display total time taken for training. Along with this plot summarize history for accuracy and loss. Display best validatino accuracy.\n",
    "# Training with OneCycleLR\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_gen = CIFAR10Sequence(X_train, Y_train, batch_size = 128, augmentations=AUGMENTATIONS_TRAIN, pre_process = eraser)\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model_info = model_f.fit_generator(train_gen, samples_per_epoch = X_train.shape[0], nb_epoch = 300, validation_data = (X_test, Y_test), verbose=1, workers=2, use_multiprocessing=True, callbacks=callbacks_list)\n",
    "\n",
    "end = time.time()\n",
    "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "\n",
    "print (\"Top accuracy on test data is: %0.2f\"%accuracy(X_test, Y_test, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "2aafZkuCWHjD",
    "outputId": "9fa32c2b-4e6e-4dbb-b955-b94e0b72fdbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:251: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if weight_names:\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model to obtain the accuracy on the test dataset of CIFAR-10\n",
    "\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('/content/gdrive/My Drive/Best_model_resnet18_f.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qePV_EF8W4gH",
    "outputId": "2ff56949-7159-46b1-c036-388522b6cc12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 90.36\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test dataset of CIFAR-10\n",
    "\n",
    "print (\"Accuracy on test data is: %0.2f\"%accuracy(X_test, Y_test, saved_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "id": "VBjyXk36UZhX",
    "outputId": "6b0bfd7e-d131-4272-b7df-035819d1befc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAESCAYAAAAWtRmOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of Learning Rate Vs Training Iterations\n",
    "\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR\")\n",
    "plt.plot(lr_manager.history['lr'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "id": "lIuXxWiMWTmt",
    "outputId": "fefea9d2-c67b-45c1-9fc2-836e04646c47"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAESCAYAAADwnNLKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of momentum Vs Training Iterations\n",
    "\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Momentum')\n",
    "plt.title(\"CLR\")\n",
    "plt.plot(lr_manager.history['momentum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References & Attributions:**\n",
    "\n",
    "*   Keras (https://keras.io/)\n",
    "\n",
    "*   Tensorflow 2.1 (https://www.tensorflow.org/api_docs/python/)\n",
    "\n",
    "\n",
    "*Disclaimer: The contents of this notebook are used for educational purposes i.e. for learning and research.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment13.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
